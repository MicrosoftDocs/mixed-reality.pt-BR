---
title: Olho-olhar
description: O HoloLens 2 permite um novo nível de contexto e compreensão humana dentro da experiência do Holographic, fornecendo aos desenvolvedores a capacidade de usar informações sobre o que os usuários estão olhando.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Acompanhamento de olho, realidade misturada, entrada, olho-olhar, olho olhar
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387600"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="d4e99-104">Olho-olhar no HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="d4e99-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="d4e99-105">O HoloLens 2 permite um novo nível de contexto e compreensão humana dentro da experiência do Holographic, fornecendo aos desenvolvedores a capacidade de usar informações sobre o que os usuários estão olhando.</span><span class="sxs-lookup"><span data-stu-id="d4e99-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="d4e99-106">Esta página informa aos desenvolvedores como eles podem se beneficiar do controle de olho para vários casos de uso, bem como o que procurar ao projetar interfaces de usuário baseadas em olhar.</span><span class="sxs-lookup"><span data-stu-id="d4e99-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="d4e99-107">Suporte a dispositivos</span><span class="sxs-lookup"><span data-stu-id="d4e99-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="d4e99-108"><strong>Recurso</strong></span><span class="sxs-lookup"><span data-stu-id="d4e99-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="d4e99-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1ª geração)</strong></a></span><span class="sxs-lookup"><span data-stu-id="d4e99-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="d4e99-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="d4e99-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="d4e99-111"><a href="immersive-headset-hardware-details.md"><strong>Headsets imersivos</strong></a></span><span class="sxs-lookup"><span data-stu-id="d4e99-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="d4e99-112">Olho-olhar</span><span class="sxs-lookup"><span data-stu-id="d4e99-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="d4e99-113">❌</span><span class="sxs-lookup"><span data-stu-id="d4e99-113">❌</span></span></td>
     <td><span data-ttu-id="d4e99-114">✔️</span><span class="sxs-lookup"><span data-stu-id="d4e99-114">✔️</span></span></td>
     <td><span data-ttu-id="d4e99-115">❌</span><span class="sxs-lookup"><span data-stu-id="d4e99-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="d4e99-116">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="d4e99-116">Use cases</span></span>
<span data-ttu-id="d4e99-117">O acompanhamento ocular permite que os aplicativos acompanhem para que local o usuário está olhando em tempo real.</span><span class="sxs-lookup"><span data-stu-id="d4e99-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="d4e99-118">Os casos de uso a seguir descrevem algumas interações que são possíveis com o acompanhamento de olho na realidade misturada.</span><span class="sxs-lookup"><span data-stu-id="d4e99-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="d4e99-119">Tenha em mente que o [Kit de ferramentas de realidade misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) é útil para fornecer vários exemplos interessantes e eficientes para usar o acompanhamento de olho, como seleções de destino com suporte rápido e sem esforço, bem como percorrer automaticamente o texto com base em o que o usuário examina.</span><span class="sxs-lookup"><span data-stu-id="d4e99-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="d4e99-120">Intenção do usuário</span><span class="sxs-lookup"><span data-stu-id="d4e99-120">User intent</span></span>    
<span data-ttu-id="d4e99-121">As informações sobre onde e o que um usuário observa fornecem um **contexto poderoso para outras entradas**, como voz, mãos e controladores.</span><span class="sxs-lookup"><span data-stu-id="d4e99-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="d4e99-122">Isso pode ser usado para várias tarefas.</span><span class="sxs-lookup"><span data-stu-id="d4e99-122">This can be used for various tasks.</span></span>
<span data-ttu-id="d4e99-123">Por exemplo, isso pode variar de um direcionamento rápido  e sem esforço na cena simplesmente observando um holograma e dizendo "Select" (também consulte [Head-olhar e commit](gaze-and-commit.md)) ou dizendo "Put this..." e, em seguida, procurando onde o usuário deseja colocar o holograma e digo "... lá ".</span><span class="sxs-lookup"><span data-stu-id="d4e99-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="d4e99-124">Exemplos para esse caso podem ser encontrados em [Kit de Ferramentas de Realidade Misturada – Seleção de alvo com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Kit de Ferramentas de Realidade Misturada – Posicionamento de alvo com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="d4e99-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="d4e99-125">Além disso, um exemplo de intenção de usuário pode incluir o uso de informações sobre o que os usuários examinam para aprimorar o envolvimento com os agentes virtuais e os hologramas interativos.</span><span class="sxs-lookup"><span data-stu-id="d4e99-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="d4e99-126">Por exemplo, os agentes virtuais podem adaptar as opções disponíveis e seu comportamento com base no conteúdo exibido atualmente.</span><span class="sxs-lookup"><span data-stu-id="d4e99-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="d4e99-127">Ações implícitas</span><span class="sxs-lookup"><span data-stu-id="d4e99-127">Implicit actions</span></span>
<span data-ttu-id="d4e99-128">A categoria de ações implícitas está intimamente relacionada à intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="d4e99-129">A ideia é que os hologramas ou os elementos da interface do usuário reagem de uma maneira um pouco instinctual que talvez não pareçam que o usuário esteja interagindo com o sistema, mas que o sistema e o usuário estejam em sincronia. Um exemplo é a **rolagem automática baseada em olhar de olho** em que o usuário lê o texto enquanto o texto continua a rolar ou fluir em sincronia com o olhar do usuário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with with the user's gaze.</span></span> <span data-ttu-id="d4e99-130">Um aspecto fundamental disso é que a velocidade de rolagem se adapta à velocidade de leitura do usuário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="d4e99-131">Outro exemplo é o **zoom e a panorâmica com suporte,** em que o usuário pode se sentir como mergulhar exatamente em relação ao que ele está focalizado.</span><span class="sxs-lookup"><span data-stu-id="d4e99-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused o.</span></span> <span data-ttu-id="d4e99-132">O disparo de zoom e controle da velocidade de zoom pode ser controlado por entrada de voz ou por mão, o que é importante para fornecer ao usuário a sensação de controle, evitando que seja sobrecarregado.</span><span class="sxs-lookup"><span data-stu-id="d4e99-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="d4e99-133">Falaremos sobre essas diretrizes de design mais detalhadamente abaixo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="d4e99-134">Uma vez ampliado, o usuário pode seguir, por exemplo, o curso de uma rua para explorar sua vizinhança simplesmente usando seus olhos olhars.</span><span class="sxs-lookup"><span data-stu-id="d4e99-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="d4e99-135">Exemplos de demonstração para esses tipos de interações podem ser encontrados na amostra do [Kit de Ferramentas de Realidade Misturada – Navegação com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="d4e99-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="d4e99-136">Casos de uso adicionais para _ações implícitas_ podem incluir:</span><span class="sxs-lookup"><span data-stu-id="d4e99-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="d4e99-137">**Notificações inteligentes:** Já ficou incomodado com notificações aparecendo exatamente no local em que você está focado?</span><span class="sxs-lookup"><span data-stu-id="d4e99-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="d4e99-138">Levando em conta o que um usuário está prestando a atenção, você pode melhorar a experiência com notificações de compensação de onde o usuário está nuvens no momento.</span><span class="sxs-lookup"><span data-stu-id="d4e99-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="d4e99-139">Isso limita distrações e os descarta automaticamente quando o usuário termina de ler.</span><span class="sxs-lookup"><span data-stu-id="d4e99-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="d4e99-140">**Hologramas atentos:** Hologramas que reagem sutilmente ao serem gazeddos.</span><span class="sxs-lookup"><span data-stu-id="d4e99-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="d4e99-141">Isso pode variar desde elementos de interface do usuário ligeiramente brilhantes até uma flor de intensão lentamente até um animal virtual começando a olhar de volta ao usuário ou tentando evitar o olhar de olho do usuário depois de uma estrela prolongada.</span><span class="sxs-lookup"><span data-stu-id="d4e99-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="d4e99-142">Essa interação pode fornecer uma noção interessante de conectividade e satisfação em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="d4e99-143">Acompanhamento de atenção</span><span class="sxs-lookup"><span data-stu-id="d4e99-143">Attention tracking</span></span>   
<span data-ttu-id="d4e99-144">As informações sobre onde ou o que os usuários examinam é uma ferramenta extremamente poderosa para avaliar a usabilidade de designs e identificar problemas em fluxos de trabalho eficientes.</span><span class="sxs-lookup"><span data-stu-id="d4e99-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="d4e99-145">A visualização e a análise de controle de olho são uma prática comum em várias áreas de aplicativo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="d4e99-146">Com o HoloLens 2, fornecemos uma nova dimensão para essa compreensão, pois os hologramas de 3D podem ser colocados em contextos reais e avaliados de acordo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="d4e99-147">O [Kit de ferramentas de realidade misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fornece exemplos básicos para registrar e carregar dados de acompanhamento de olho e como visualizá-los.</span><span class="sxs-lookup"><span data-stu-id="d4e99-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="d4e99-148">Outros aplicativos nessa área podem incluir:</span><span class="sxs-lookup"><span data-stu-id="d4e99-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="d4e99-149">**Visualização de olhar de olho remoto:** Visualize o que os colaboradores remotos estão vendo para garantir se as instruções foram compreendidas e seguidas corretamente.</span><span class="sxs-lookup"><span data-stu-id="d4e99-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="d4e99-150">**Estudos de pesquisa de usuário:** O acompanhamento de atenção pode ser usado para explorar o modo como o principiante e os usuários especialistas analisam visualmente o conteúdo ou como sua coordenação de olhos para tarefas complexas, como para a análise de dados médicos ou de máquinas operacionais.</span><span class="sxs-lookup"><span data-stu-id="d4e99-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="d4e99-151">**Simulações de treinamento e monitoramento de desempenho:** Pratique e otimize a execução de tarefas identificando gargalos com mais eficiência no fluxo de execução.</span><span class="sxs-lookup"><span data-stu-id="d4e99-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="d4e99-152">**Avaliações de design, anúncio e pesquisa de marketing:** O acompanhamento de olho é uma ferramenta comum para pesquisa de mercado ao avaliar designs de sites e produtos.</span><span class="sxs-lookup"><span data-stu-id="d4e99-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluateing website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="d4e99-153">Casos de uso adicionais</span><span class="sxs-lookup"><span data-stu-id="d4e99-153">Additional use cases</span></span>
- <span data-ttu-id="d4e99-154">**Jogos:** Você já quis ter superpoderes?</span><span class="sxs-lookup"><span data-stu-id="d4e99-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="d4e99-155">Esta é a sua chance!</span><span class="sxs-lookup"><span data-stu-id="d4e99-155">Here's your chance!</span></span> <span data-ttu-id="d4e99-156">Você pode levitater os hologramas por estrelas.</span><span class="sxs-lookup"><span data-stu-id="d4e99-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="d4e99-157">Lance raios laser de seus olhos.</span><span class="sxs-lookup"><span data-stu-id="d4e99-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="d4e99-158">Transforme inimigos em pedra ou congele-os.</span><span class="sxs-lookup"><span data-stu-id="d4e99-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="d4e99-159">Use sua visão de raios X para explorar prédios.</span><span class="sxs-lookup"><span data-stu-id="d4e99-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="d4e99-160">O limite é sua imaginação.</span><span class="sxs-lookup"><span data-stu-id="d4e99-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="d4e99-161">**Avatars expressivos:** Controle de olho ajuda em avatars 3D mais expressivos usando a data de acompanhamento de olho dinâmico para animar os olhos do avatar que indicam o que o usuário está olhando.</span><span class="sxs-lookup"><span data-stu-id="d4e99-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live-eye tracking date to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="d4e99-162">Ele também adiciona mais expressividade adicionando piscadinhas.</span><span class="sxs-lookup"><span data-stu-id="d4e99-162">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="d4e99-163">**Entrada de texto:** O controle de olho pode ser usado como uma alternativa para a entrada de texto de baixo esforço, especialmente quando a fala ou as mãos são inconvenientes de usar.</span><span class="sxs-lookup"><span data-stu-id="d4e99-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="d4e99-164">API de acompanhamento ocular</span><span class="sxs-lookup"><span data-stu-id="d4e99-164">Eye tracking API</span></span>
<span data-ttu-id="d4e99-165">Antes de entrar em detalhes sobre as diretrizes de design específicas para a interação olhar, queremos destacar rapidamente os recursos que a API do rastreador ocular 2 do HoloLens fornece aos desenvolvedores.</span><span class="sxs-lookup"><span data-stu-id="d4e99-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="d4e99-166">Ele fornece uma única origem de olho-olhar--olhar e direção – fornecendo dados em aproximadamente _30 fps_.</span><span class="sxs-lookup"><span data-stu-id="d4e99-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 FPS_.</span></span> 

<span data-ttu-id="d4e99-167">O olhar de olho previsto está dentro da CA.</span><span class="sxs-lookup"><span data-stu-id="d4e99-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="d4e99-168">1,0-1,5 graus no ângulo visual em torno do destino real.</span><span class="sxs-lookup"><span data-stu-id="d4e99-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="d4e99-169">Como pequenas imprecisões são esperadas, você deve planejar alguma margem em torno desse valor de limite inferior.</span><span class="sxs-lookup"><span data-stu-id="d4e99-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="d4e99-170">Falaremos sobre isso mais abaixo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-170">We will discuss this more below.</span></span> <span data-ttu-id="d4e99-171">Para que o acompanhamento ocular funcione com precisão, cada usuário deve passar por uma calibração de usuário de acompanhamento ocular.</span><span class="sxs-lookup"><span data-stu-id="d4e99-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="d4e99-172">![Tamanho ideal do alvo em uma distância de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="d4e99-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="d4e99-173">*Tamanho de destino ideal em uma distância de 2 medidores*</span><span class="sxs-lookup"><span data-stu-id="d4e99-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="d4e99-174">A [API de acompanhamento de olho](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) pode ser acessada por meio de: ' Windows. percepção. People. EyesPose '.</span><span class="sxs-lookup"><span data-stu-id="d4e99-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="d4e99-175">Diretrizes de design de olhar de olho</span><span class="sxs-lookup"><span data-stu-id="d4e99-175">Eye-gaze design guidelines</span></span>
<span data-ttu-id="d4e99-176">A criação de uma interação que aproveita o direcionamento ocular com movimentação rápida pode ser um desafio.</span><span class="sxs-lookup"><span data-stu-id="d4e99-176">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="d4e99-177">Nesta seção, resumimos as principais vantagens e desafios a serem levados em conta ao projetar seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-177">In this section, we summarize the key advantages and challenges to take into account when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="d4e99-178">Benefícios da entrada olhar</span><span class="sxs-lookup"><span data-stu-id="d4e99-178">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="d4e99-179">**Apontar com alta velocidade.**</span><span class="sxs-lookup"><span data-stu-id="d4e99-179">**High speed pointing.**</span></span> <span data-ttu-id="d4e99-180">O músculo ocular é o músculo de reação mais rápida em nosso corpo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-180">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="d4e99-181">**Pouco esforço.**</span><span class="sxs-lookup"><span data-stu-id="d4e99-181">**Low effort.**</span></span> <span data-ttu-id="d4e99-182">Quase nenhum movimento físico é necessário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-182">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="d4e99-183">**Capacidade de ser implícito.**</span><span class="sxs-lookup"><span data-stu-id="d4e99-183">**Implicitness.**</span></span> <span data-ttu-id="d4e99-184">Geralmente descritas pelos usuários como "leitura mental", as informações sobre os movimentos de um usuário permitem que o sistema saiba qual alvo o usuário planeja participar.</span><span class="sxs-lookup"><span data-stu-id="d4e99-184">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="d4e99-185">**Canal de entrada alternativo.**</span><span class="sxs-lookup"><span data-stu-id="d4e99-185">**Alternative input channel.**</span></span> <span data-ttu-id="d4e99-186">O olho-olhar pode fornecer uma poderosa entrada de suporte para a mão e entrada de voz em anos de experiência de usuários com base em sua coordenação de olhos.</span><span class="sxs-lookup"><span data-stu-id="d4e99-186">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="d4e99-187">**Atenção visual.**</span><span class="sxs-lookup"><span data-stu-id="d4e99-187">**Visual attention.**</span></span> <span data-ttu-id="d4e99-188">Outro benefício importante é a possibilidade de inferir o que um usuário está prestando a atenção.</span><span class="sxs-lookup"><span data-stu-id="d4e99-188">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="d4e99-189">Isso pode ajudar em várias áreas de aplicativos que vão desde a avaliação de diferentes designs para auxiliar em interfaces de usuário mais inteligentes e indicações sociais aprimoradas para comunicação remota.</span><span class="sxs-lookup"><span data-stu-id="d4e99-189">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="d4e99-190">Resumindo, usar olhar como uma entrada oferece um sinal contextual rápido e sem esforço.</span><span class="sxs-lookup"><span data-stu-id="d4e99-190">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="d4e99-191">Isso é particularmente poderoso quando combinado com outras entradas, como *voz* e entrada *manual* , para confirmar a intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-191">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="d4e99-192">Desafios de olhar de olho como uma entrada</span><span class="sxs-lookup"><span data-stu-id="d4e99-192">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="d4e99-193">Com muita potência, vem muito de responsabilidade.</span><span class="sxs-lookup"><span data-stu-id="d4e99-193">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="d4e99-194">Embora os olhos olhar possam ser usados para criar experiências de usuário satisfatórias que o faz sentir como um Superhero, também é importante saber o que não é bom para se considerar apropriadamente.</span><span class="sxs-lookup"><span data-stu-id="d4e99-194">While eye-gaze can be used to create satisfying user experiences thata makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="d4e99-195">O seguinte discute alguns *desafios* a serem levados em conta e como solucioná-los ao trabalhar com a entrada de olhar de olho:</span><span class="sxs-lookup"><span data-stu-id="d4e99-195">The following discusses some *challenges* to take into account as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="d4e99-196">**Seu olho-olhar é "Always on"** No momento em que você abre suas tampas de olho, seus olhos começam a fixatingr sobre as coisas no ambiente.</span><span class="sxs-lookup"><span data-stu-id="d4e99-196">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="d4e99-197">Reagir a todas as aparências que você fizer e emitir ações acidentalmente, pois você examinou algo por muito tempo resultaria em uma experiência que não satisfaça.</span><span class="sxs-lookup"><span data-stu-id="d4e99-197">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="d4e99-198">É por isso que recomendamos combinar olhars de olho com um *comando de voz*, um *gesto de mão*, um clique de *botão* ou uma duração estendida para disparar a seleção de um destino.</span><span class="sxs-lookup"><span data-stu-id="d4e99-198">This is why we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="d4e99-199">Essa solução também permite um modo no qual o usuário pode procurar livremente sem ser sobrecarregado por disparar involuntariamente algo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-199">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="d4e99-200">Esse problema também deve ser levado em conta durante o design de comentários visuais e auditivos ao simplesmente olhar para um alvo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-200">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="d4e99-201">Não sobrecarregue o usuário com efeitos de desencaixe imediatos ou sons de foco.</span><span class="sxs-lookup"><span data-stu-id="d4e99-201">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="d4e99-202">A sutileza é fundamental.</span><span class="sxs-lookup"><span data-stu-id="d4e99-202">Subtlety is key.</span></span> <span data-ttu-id="d4e99-203">Abordaremos algumas melhores práticas para isso mais adiante quando falarmos a respeito de recomendações sobre design.</span><span class="sxs-lookup"><span data-stu-id="d4e99-203">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="d4e99-204">**Observação vs. controle** Imagine que você deseja endireitar precisamente uma fotografia em sua parede.</span><span class="sxs-lookup"><span data-stu-id="d4e99-204">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="d4e99-205">Você olha para as bordas da fotografia e em volta dela para ver se ela fica bem alinhada.</span><span class="sxs-lookup"><span data-stu-id="d4e99-205">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="d4e99-206">Agora imagine como você faria isso quando quiser usar seu olho-olhar como uma entrada para mover a imagem.</span><span class="sxs-lookup"><span data-stu-id="d4e99-206">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="d4e99-207">Difícil, não é mesmo?</span><span class="sxs-lookup"><span data-stu-id="d4e99-207">Difficult, isn't it?</span></span> <span data-ttu-id="d4e99-208">Isso descreve a função dupla de olhar quando é necessário para entrada e controle.</span><span class="sxs-lookup"><span data-stu-id="d4e99-208">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="d4e99-209">**Sair antes de clicar:** Para seleções de destino rápido, a pesquisa mostrou que o olhar de olho do usuário pode passar antes de concluir um clique manual (por exemplo, um airtap).</span><span class="sxs-lookup"><span data-stu-id="d4e99-209">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="d4e99-210">Portanto, atenção especial deve ser paga para sincronizar o sinal de olhar rápido com entrada de controle mais lenta (por exemplo, voz, mãos, controlador).</span><span class="sxs-lookup"><span data-stu-id="d4e99-210">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="d4e99-211">**Alvos pequenos:** Você sabe a sensação quando tenta ler um texto que é um pouco pequeno demais para leitura confortável?</span><span class="sxs-lookup"><span data-stu-id="d4e99-211">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortable?</span></span> <span data-ttu-id="d4e99-212">Essa sensação de sobrecarregar seus olhos pode fazer com que você fique cansado e desgastado porque tenta reajustar os olhos para se concentrar melhor.</span><span class="sxs-lookup"><span data-stu-id="d4e99-212">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="d4e99-213">Essa é uma sensação que você pode invocar em seus usuários ao forçá-los a selecionar destinos que são muito pequenos em seu aplicativo usando o direcionamento de olho.</span><span class="sxs-lookup"><span data-stu-id="d4e99-213">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="d4e99-214">Para o design, visando criar uma experiência agradável e confortável para seus usuários, recomendamos que os alvos tenham um ângulo visual de, pelo menos, 2°, preferencialmente maior.</span><span class="sxs-lookup"><span data-stu-id="d4e99-214">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="d4e99-215">**Olhos irregulares – movimentos olhars** Nossos olhos realizam movimentos rápidos do fixação da para o fixação da.</span><span class="sxs-lookup"><span data-stu-id="d4e99-215">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="d4e99-216">Se você examinar os caminhos de exame dos movimentos oculares registrados, poderá ver que eles parecem irregulares.</span><span class="sxs-lookup"><span data-stu-id="d4e99-216">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="d4e99-217">Seus olhos se movem rapidamente e em saltos espontâneos comparado ao *foco com a cabeça* ou aos *movimentos com as mãos*.</span><span class="sxs-lookup"><span data-stu-id="d4e99-217">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="d4e99-218">**Confiabilidade de acompanhamento:** A precisão do acompanhamento ocular pode diminuir um pouco sob iluminação em constante mudança, pois o olho se ajusta às novas condições.</span><span class="sxs-lookup"><span data-stu-id="d4e99-218">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="d4e99-219">Embora isso não deva afetar necessariamente o design do aplicativo, já que a precisão deve estar dentro da limitação de 2 °, talvez seja necessário que o usuário execute outra calibragem.</span><span class="sxs-lookup"><span data-stu-id="d4e99-219">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to run another calibration.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="d4e99-220">Recomendações sobre design</span><span class="sxs-lookup"><span data-stu-id="d4e99-220">Design recommendations</span></span>
<span data-ttu-id="d4e99-221">Veja a seguir uma lista de recomendações de design específicas com base nas vantagens e nos desafios descritos para a entrada de olhar de olho:</span><span class="sxs-lookup"><span data-stu-id="d4e99-221">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="d4e99-222">**Olho-olhar! = Head-olhar:**</span><span class="sxs-lookup"><span data-stu-id="d4e99-222">**Eye-gaze != Head-gaze:**</span></span>
    - <span data-ttu-id="d4e99-223">**Considere se movimentos oculares rápidos, ainda que irregulares, se ajustam à sua tarefa de entrada:** Embora nossos movimentos de olho rápidos e irregulares sejam ótimos na seleção rápida de destinos em nosso FoV (campo de exibição), ele é menos aplicável para tarefas que exigem trajetórias de entrada suaves (por exemplo, desenho ou enfocar anotações).</span><span class="sxs-lookup"><span data-stu-id="d4e99-223">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view (FoV), it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="d4e99-224">Nesse caso, apontar com a mão ou a cabeça deve ser preferencial.</span><span class="sxs-lookup"><span data-stu-id="d4e99-224">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="d4e99-225">**Evite anexar algo diretamente ao olhar de olho do usuário (por exemplo, um controle deslizante ou cursor).**</span><span class="sxs-lookup"><span data-stu-id="d4e99-225">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="d4e99-226">No caso de um cursor, isso pode resultar no efeito de "cursor fleeing" devido a pequenos deslocamentos no sinal olhar de olho projetado.</span><span class="sxs-lookup"><span data-stu-id="d4e99-226">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="d4e99-227">No caso de um controle deslizante, ele pode entrar em conflito com a função dupla de controlar o controle deslizante com seus olhos, enquanto também deseja verificar se o objeto está no local correto.</span><span class="sxs-lookup"><span data-stu-id="d4e99-227">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="d4e99-228">Resumindo, os usuários poderiam se tornar sobrecarregados e distraídoss, especialmente se o sinal for impreciso para esse usuário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-228">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="d4e99-229">**Combine olho-olhar com outras entradas:** A integração do controle de olho com outras entradas, como gestos à mão, comandos de voz ou prensas de botão, atende a várias vantagens:</span><span class="sxs-lookup"><span data-stu-id="d4e99-229">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="d4e99-230">**Permitir a observação livre:** Considerando que a função principal de nossos olhos é observar nosso ambiente, é muito importante que os usuários sejam configurados sem disparar nenhum comentário ou ação (Visual, auditoria, etc.).</span><span class="sxs-lookup"><span data-stu-id="d4e99-230">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="d4e99-231">Combinar o controle de olho com outro controle de entrada permite a transição tranqüila entre a observação de acompanhamento de olho e os modos de controle de entrada.</span><span class="sxs-lookup"><span data-stu-id="d4e99-231">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="d4e99-232">**Provedor de contexto avançado:** Usar informações sobre onde e o que o usuário está olhando ao longo de um comando de voz ou executar um gesto de mão permite canalizar diretamente a entrada no campo de exibição.</span><span class="sxs-lookup"><span data-stu-id="d4e99-232">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="d4e99-233">Por exemplo: “Coloque isso lá” para selecionar rápida e fluentemente um holograma e posicioná-lo na cena apenas olhando um alvo e o destino.</span><span class="sxs-lookup"><span data-stu-id="d4e99-233">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="d4e99-234">**Necessidade de sincronizar entradas multimodais (problema de “sair antes de clicar”):** Combinar movimentos de olhos rápidos com entradas adicionais mais complexas, como comandos de voz longos ou gestos de mão, tem o risco de continuar o olhar antes de concluir o comando de entrada adicional.</span><span class="sxs-lookup"><span data-stu-id="d4e99-234">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="d4e99-235">Portanto, se você criar seus próprios controles de entrada (por exemplo, gestos com as mãos personalizados), lembre-se de registrar a ocorrência dessa entrada ou sua duração aproximada para correlacioná-la ao que um usuário tinha se fixado no passado.</span><span class="sxs-lookup"><span data-stu-id="d4e99-235">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="d4e99-236">**Comentários sutis para a entrada de acompanhamento ocular:** É útil fornecer comentários quando um destino é examinado para indicar que o sistema está funcionando conforme o esperado, mas deve ser mantido sutil.</span><span class="sxs-lookup"><span data-stu-id="d4e99-236">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended, but should be kept subtle.</span></span> <span data-ttu-id="d4e99-237">Isso pode incluir a mistura lenta, a entrada e a saída dos destaques visuais ou a execução de outros comportamentos de destino sutis, como movimentos lentos, como o aumento ligeiramente do destino, para indicar que o sistema detectou corretamente que o usuário está olhando para um destino sem interromper desnecessariamente o fluxo de trabalho atual do usuário.</span><span class="sxs-lookup"><span data-stu-id="d4e99-237">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="d4e99-238">**Evitar a imposição de movimentos oculares artificiais como entrada:** Não force os usuários a executar movimentos de olho específicos (gestos de olhar) para disparar ações em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="d4e99-238">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="d4e99-239">**Levar em conta as imprecisões:** Distinguemos dois tipos de impedições que são perceptíveis para os usuários: deslocamento e Tremulação.</span><span class="sxs-lookup"><span data-stu-id="d4e99-239">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="d4e99-240">A maneira mais fácil de resolver um deslocamento é fornecer destinos suficientemente grandes para interagir com o.</span><span class="sxs-lookup"><span data-stu-id="d4e99-240">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="d4e99-241">É recomendável que você use um ângulo visual maior que 2 ° como referência.</span><span class="sxs-lookup"><span data-stu-id="d4e99-241">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="d4e99-242">Por exemplo, sua miniatura é de cerca de 2 ° no ângulo visual quando você amplia seu braço.</span><span class="sxs-lookup"><span data-stu-id="d4e99-242">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="d4e99-243">Isso resulta nas seguintes diretrizes:</span><span class="sxs-lookup"><span data-stu-id="d4e99-243">This leads to the following guidance:</span></span>
    - <span data-ttu-id="d4e99-244">Não force os usuários a selecionar pequenos destinos.</span><span class="sxs-lookup"><span data-stu-id="d4e99-244">Do not force users to select tiny targets.</span></span> <span data-ttu-id="d4e99-245">A pesquisa mostrou que se os destinos são suficientemente grandes e que o sistema foi projetado bem, os usuários descrevem suas interações como sem esforço e mágico.</span><span class="sxs-lookup"><span data-stu-id="d4e99-245">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="d4e99-246">Se os alvos ficarem muito pequenos, os usuários descreverão a experiência como cansativa e frustrante.</span><span class="sxs-lookup"><span data-stu-id="d4e99-246">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="d4e99-247">Consulte também</span><span class="sxs-lookup"><span data-stu-id="d4e99-247">See also</span></span>
* [<span data-ttu-id="d4e99-248">Focar com a cabeça e confirmar</span><span class="sxs-lookup"><span data-stu-id="d4e99-248">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="d4e99-249">Cabeça e olho-olhar no DirectX</span><span class="sxs-lookup"><span data-stu-id="d4e99-249">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="d4e99-250">Olho-olhar no Unity (Kit de ferramentas de realidade misturada)</span><span class="sxs-lookup"><span data-stu-id="d4e99-250">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="d4e99-251">Gestos de mão</span><span class="sxs-lookup"><span data-stu-id="d4e99-251">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="d4e99-252">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="d4e99-252">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="d4e99-253">Controladores de movimentos</span><span class="sxs-lookup"><span data-stu-id="d4e99-253">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="d4e99-254">Conforto</span><span class="sxs-lookup"><span data-stu-id="d4e99-254">Comfort</span></span>](comfort.md)
