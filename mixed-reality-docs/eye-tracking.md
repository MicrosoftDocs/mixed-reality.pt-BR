---
title: Acompanhamento ocular
description: Acompanhamento ocular
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Acompanhamento ocular, realidade misturada, entrada, foco com o olhar
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: pt-BR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453697"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="14708-104">Acompanhamento ocular no HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="14708-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="14708-105">O HoloLens 2 permite um nível totalmente novo de contexto e entendimento humano dentro da experiência holográfica, fornecendo aos desenvolvedores a incrível capacidade de usar as informações sobre o que os usuários estão vendo.</span><span class="sxs-lookup"><span data-stu-id="14708-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="14708-106">Esta página fornece uma visão geral de como os desenvolvedores podem se beneficiar do acompanhamento ocular para vários casos de uso e as considerações mais importantes durante a criação de interfaces do usuário baseadas no foco com o olhar.</span><span class="sxs-lookup"><span data-stu-id="14708-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="14708-107">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="14708-107">Use cases</span></span>
<span data-ttu-id="14708-108">O acompanhamento ocular permite que os aplicativos acompanhem para que local o usuário está olhando em tempo real.</span><span class="sxs-lookup"><span data-stu-id="14708-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="14708-109">Esta seção descreve alguns dos possíveis casos de uso e novas interações que se tornam possíveis com o acompanhamento ocular na realidade misturada.</span><span class="sxs-lookup"><span data-stu-id="14708-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="14708-110">Antes de começar, a seguir, mencionaremos o [Kit de Ferramentas de Realidade Misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) várias vezes, pois ele fornece vários exemplos interessantes e avançados para uso do acompanhamento ocular, como seleções rápidas e fáceis de alvo com suporte ocular e rolagem automática pelo texto com base no local para o qual o usuário olha.</span><span class="sxs-lookup"><span data-stu-id="14708-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="14708-111">Intenção do usuário</span><span class="sxs-lookup"><span data-stu-id="14708-111">User intent</span></span>    
<span data-ttu-id="14708-112">As informações sobre o local para o qual um usuário olha fornecem um **contexto avançado para outras entradas**, como voz, mãos e controles.</span><span class="sxs-lookup"><span data-stu-id="14708-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="14708-113">Isso pode ser usado para várias tarefas.</span><span class="sxs-lookup"><span data-stu-id="14708-113">This can be used for various tasks.</span></span>
<span data-ttu-id="14708-114">Por exemplo, isso pode variar do **direcionamento** de forma rápida e fácil pela cena simplesmente observando um holograma e falando "selecionar" (confira também [Foco com a cabeça e confirmação](gaze-and-commit.md)) ou falando "coloque isto..." e, em seguida, procurando o local em que você deseja colocar o holograma e dizendo "...lá".</span><span class="sxs-lookup"><span data-stu-id="14708-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="14708-115">Exemplos para esse caso podem ser encontrados em [Kit de Ferramentas de Realidade Misturada – Seleção de alvo com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Kit de Ferramentas de Realidade Misturada – Posicionamento de alvo com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="14708-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="14708-116">Outro exemplo de intenção do usuário pode incluir o uso de informações sobre para o que os usuários olham a fim de melhorar o envolvimento com agentes virtuais personificados e hologramas interativos.</span><span class="sxs-lookup"><span data-stu-id="14708-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="14708-117">Por exemplo, os agentes virtuais poderão adaptar as opções disponíveis e seu comportamento com base no conteúdo atualmente exibido.</span><span class="sxs-lookup"><span data-stu-id="14708-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="14708-118">Ações implícitas</span><span class="sxs-lookup"><span data-stu-id="14708-118">Implicit actions</span></span>
<span data-ttu-id="14708-119">A categoria de ações implícitas está intimamente relacionada à intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="14708-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="14708-120">A ideia é que os hologramas ou os elementos de interface do usuário reagem de forma um tanto instintiva que pode até mesmo parecer que você não está interagindo com o sistema, mas, pelo contrário, o sistema e o usuário estão em sincronia. Por exemplo, um exemplo extremamente bem-sucedido é a **rolagem automática baseada no foco com o olhar**.</span><span class="sxs-lookup"><span data-stu-id="14708-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="14708-121">A ideia é simples assim: O usuário lê um texto e pode simplesmente continuar lendo.</span><span class="sxs-lookup"><span data-stu-id="14708-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="14708-122">O texto gradualmente se move para cima para manter os usuários em seus fluxos de leitura.</span><span class="sxs-lookup"><span data-stu-id="14708-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="14708-123">Um aspecto importante é que a velocidade da rolagem se adapta à velocidade de leitura do usuário.</span><span class="sxs-lookup"><span data-stu-id="14708-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="14708-124">Outro exemplo é o **zoom e a panorâmica com suporte ocular** para os quais o usuário pode parecer estar mergulhando exatamente no que está focando.</span><span class="sxs-lookup"><span data-stu-id="14708-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="14708-125">O gatilho do zoom e o controle da velocidade de zoom podem ser obtidos por meio da entrada de voz ou de mão, que é importante para fornecer a sensação de controle e evitar sobrecarregar o usuário (falaremos sobre essas diretrizes de design mais detalhadamente abaixo).</span><span class="sxs-lookup"><span data-stu-id="14708-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="14708-126">Depois de ampliar, o usuário pode seguir suavemente, por exemplo, o curso de uma rua para explorar a vizinhança simplesmente usando o foco com o olhar.</span><span class="sxs-lookup"><span data-stu-id="14708-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="14708-127">Exemplos de demonstração para esses tipos de interações podem ser encontrados na amostra do [Kit de Ferramentas de Realidade Misturada – Navegação com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="14708-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="14708-128">Casos de uso adicionais para _ações implícitas_ podem incluir:</span><span class="sxs-lookup"><span data-stu-id="14708-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="14708-129">**Notificações inteligentes:** Já ficou incomodado com notificações aparecendo exatamente no local em que você está focado?</span><span class="sxs-lookup"><span data-stu-id="14708-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="14708-130">Levando em conta o local em que um usuário está concentrado no momento, você pode torná-lo melhor.</span><span class="sxs-lookup"><span data-stu-id="14708-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="14708-131">Mostre o deslocamento de notificações para o local em que o usuário está olhando no momento a fim de limitar distrações e ignorá-las automaticamente após o término da leitura.</span><span class="sxs-lookup"><span data-stu-id="14708-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="14708-132">**Hologramas atentos:** Hologramas que reagem de forma sutil quando são observados.</span><span class="sxs-lookup"><span data-stu-id="14708-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="14708-133">Isso pode variar de elementos de interface do usuário ligeiramente brilhantes, uma flor desabrochando lentamente a um animal de estimação virtual começando a olhar para você novamente ou tentando evitar seu foco com o olhar após um olhar prolongado.</span><span class="sxs-lookup"><span data-stu-id="14708-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="14708-134">Isso pode fornecer um senso interessante de conectividade e satisfação em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="14708-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="14708-135">Acompanhamento de atenção</span><span class="sxs-lookup"><span data-stu-id="14708-135">Attention tracking</span></span>   
<span data-ttu-id="14708-136">As informações sobre o local para o qual os usuários olham são uma ferramenta imensamente avançada para avaliar a usabilidade dos designs e identificar problemas em fluxos de trabalho eficientes.</span><span class="sxs-lookup"><span data-stu-id="14708-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="14708-137">Por enquanto, a visualização e a análise de acompanhamento ocular já é uma prática comum em várias áreas do aplicativo.</span><span class="sxs-lookup"><span data-stu-id="14708-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="14708-138">Com o HoloLens 2, fornecemos uma nova dimensão para essa compreensão, já que os hologramas 3D podem ser colocados em contextos do mundo real e avaliados juntos.</span><span class="sxs-lookup"><span data-stu-id="14708-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="14708-139">O [Kit de Ferramentas de Realidade Misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fornece exemplos básicos para log e carregamento de dados de acompanhamento ocular e de como visualizá-los.</span><span class="sxs-lookup"><span data-stu-id="14708-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="14708-140">Outros aplicativos nessa área podem incluir:</span><span class="sxs-lookup"><span data-stu-id="14708-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="14708-141">**Visualização de foco com o olhar remoto:** A visualização do que os colaboradores remotos estão olhando, por exemplo, verifica se as instruções foram compreendidas e seguidas corretamente.</span><span class="sxs-lookup"><span data-stu-id="14708-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="14708-142">**Estudos de pesquisa de usuário:** O acompanhamento de atenção pode ser usado para explorar a maneira com os usuários iniciantes vs. experientes analisam visualmente o conteúdo ou sua coordenação mão-olho em tarefas complexas (por exemplo, para análise de dados médicos ou durante a operação de máquinas).</span><span class="sxs-lookup"><span data-stu-id="14708-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="14708-143">**Simulações de treinamento e monitoramento de desempenho:** Pratique e otimize a execução de tarefas identificando gargalos com mais eficiência no fluxo de execução.</span><span class="sxs-lookup"><span data-stu-id="14708-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="14708-144">**Avaliações de design, anúncio e pesquisa de marketing:** O acompanhamento ocular é uma ferramenta comum para a pesquisa de mercado avaliar os designs de sites e produtos.</span><span class="sxs-lookup"><span data-stu-id="14708-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="14708-145">Casos de uso adicionais</span><span class="sxs-lookup"><span data-stu-id="14708-145">Additional use cases</span></span>
- <span data-ttu-id="14708-146">**Jogos:** Você já quis ter superpoderes?</span><span class="sxs-lookup"><span data-stu-id="14708-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="14708-147">Esta é a sua chance!</span><span class="sxs-lookup"><span data-stu-id="14708-147">Here's your chance!</span></span> <span data-ttu-id="14708-148">Faça hologramas levitarem apenas por meio de seu olhar.</span><span class="sxs-lookup"><span data-stu-id="14708-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="14708-149">Lance raios laser de seus olhos.</span><span class="sxs-lookup"><span data-stu-id="14708-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="14708-150">Transforme inimigos em pedras ou congele-os.</span><span class="sxs-lookup"><span data-stu-id="14708-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="14708-151">Use sua visão de raios X para explorar prédios.</span><span class="sxs-lookup"><span data-stu-id="14708-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="14708-152">O limite é sua imaginação.</span><span class="sxs-lookup"><span data-stu-id="14708-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="14708-153">**Avatars expressivos:** O acompanhamento ocular auxilia na exibição de avatars 3D mais expressivos usando a data de acompanhamento ocular em tempo real para animar os olhos do avatar a fim de indicar para o que o usuário está olhando.</span><span class="sxs-lookup"><span data-stu-id="14708-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="14708-154">Ele também adiciona mais expressividade adicionando piscadinhas.</span><span class="sxs-lookup"><span data-stu-id="14708-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="14708-155">**Entrada de texto:** O acompanhamento ocular pode ser usado como uma alternativa interessante para a entrada de texto de baixo esforço, especialmente quando a fala ou as mãos são inconvenientes de serem usadas.</span><span class="sxs-lookup"><span data-stu-id="14708-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="14708-156">API de acompanhamento ocular</span><span class="sxs-lookup"><span data-stu-id="14708-156">Eye tracking API</span></span>
<span data-ttu-id="14708-157">Antes de entrar em detalhes sobre as diretrizes de design específicas para a interação de foco com o olhar, queremos brevemente nos voltar para as funcionalidades oferecidas pelo HoloLens 2 Eye Tracker.</span><span class="sxs-lookup"><span data-stu-id="14708-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="14708-158">A [API de acompanhamento ocular](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) pode ser acessada por meio de: `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="14708-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="14708-159">Ela fornece um raio de foco com o olhar único (origem e direção do foco) para desenvolvedores.</span><span class="sxs-lookup"><span data-stu-id="14708-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="14708-160">O rastreador ocular fornece dados sobre _30 FPS_.</span><span class="sxs-lookup"><span data-stu-id="14708-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="14708-161">O foco com o olhar está dentro de aproximadamente</span><span class="sxs-lookup"><span data-stu-id="14708-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="14708-162">1,0 – 1,5 grau no ângulo visual em torno do alvo real focado.</span><span class="sxs-lookup"><span data-stu-id="14708-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="14708-163">Como pequenas imprecisões são esperadas, você deve planejar alguma margem em torno desse valor de limite inferior.</span><span class="sxs-lookup"><span data-stu-id="14708-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="14708-164">Falaremos sobre isso mais abaixo.</span><span class="sxs-lookup"><span data-stu-id="14708-164">We will discuss this more below.</span></span> <span data-ttu-id="14708-165">Para que o acompanhamento ocular funcione com precisão, cada usuário deve passar por uma calibração de usuário de acompanhamento ocular.</span><span class="sxs-lookup"><span data-stu-id="14708-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="14708-166">![Tamanho ideal do alvo em uma distância de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="14708-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="14708-167">*Tamanho ideal do alvo em uma distância de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="14708-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="14708-168">Diretrizes de design de foco com o olhar</span><span class="sxs-lookup"><span data-stu-id="14708-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="14708-169">A criação de uma interação que aproveita o direcionamento ocular com movimentação rápida pode ser um desafio.</span><span class="sxs-lookup"><span data-stu-id="14708-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="14708-170">Nesta seção, resumimos as principais vantagens e os desafios a serem considerados ao projetar seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="14708-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="14708-171">Benefícios da entrada do foco com o olhar</span><span class="sxs-lookup"><span data-stu-id="14708-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="14708-172">**Apontar com alta velocidade.**</span><span class="sxs-lookup"><span data-stu-id="14708-172">**High speed pointing.**</span></span> <span data-ttu-id="14708-173">O músculo ocular é o músculo de reação mais rápida em nosso corpo.</span><span class="sxs-lookup"><span data-stu-id="14708-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="14708-174">**Pouco esforço.**</span><span class="sxs-lookup"><span data-stu-id="14708-174">**Low effort.**</span></span> <span data-ttu-id="14708-175">Quase nenhum movimento físico é necessário.</span><span class="sxs-lookup"><span data-stu-id="14708-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="14708-176">**Capacidade de ser implícito.**</span><span class="sxs-lookup"><span data-stu-id="14708-176">**Implicitness.**</span></span> <span data-ttu-id="14708-177">Geralmente descrito pelos usuários como "leitura da mente", as informações sobre os movimentos oculares de um usuário permitem que o sistema saiba com qual alvo o usuário pretende interagir.</span><span class="sxs-lookup"><span data-stu-id="14708-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="14708-178">**Canal de entrada alternativo.**</span><span class="sxs-lookup"><span data-stu-id="14708-178">**Alternative input channel.**</span></span> <span data-ttu-id="14708-179">O foco com o olhar pode fornecer uma entrada de suporte eficiente para a entrada de mãos e voz baseada em vários anos de experiência dos usuários com base em sua coordenação mão-olho.</span><span class="sxs-lookup"><span data-stu-id="14708-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="14708-180">**Atenção visual.**</span><span class="sxs-lookup"><span data-stu-id="14708-180">**Visual attention.**</span></span> <span data-ttu-id="14708-181">Outro importante benefício é a possibilidade de inferir o que um usuário está prestando atenção.</span><span class="sxs-lookup"><span data-stu-id="14708-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="14708-182">Isso pode ajudar em várias áreas do aplicativo, que vão da avaliação mais efetiva de diferentes designs ao auxílio na criação de interfaces do usuário mais inteligentes e indicações sociais aprimoradas para comunicação remota.</span><span class="sxs-lookup"><span data-stu-id="14708-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="14708-183">Em resumo, o uso do foco com o olhar como uma entrada potencialmente oferece um sinal contextual rápido e fácil – isso é especialmente eficiente em combinação com outras entradas, como a entrada de *voz* e *manual* para confirmar a intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="14708-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="14708-184">Desafios do foco com o olhar como entrada</span><span class="sxs-lookup"><span data-stu-id="14708-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="14708-185">Muito poder pressupõe muita responsabilidade: Embora o foco com o olhar possa ser usado para criar experiências mágicas para o usuário, parecidas com as de um super-herói, também é importante saber suas desvantagens para considerá-lo adequadamente.</span><span class="sxs-lookup"><span data-stu-id="14708-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="14708-186">A seguir, abordaremos alguns *desafios* que devem ser levados em conta e como resolvê-los ao trabalhar com a entrada de foco com o olhar:</span><span class="sxs-lookup"><span data-stu-id="14708-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="14708-187">**Seu foco com o olhar está "sempre ativado"** No momento em que você abre os olhos, eles começam a se fixar nas coisas do ambiente.</span><span class="sxs-lookup"><span data-stu-id="14708-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="14708-188">Uma reação a cada olhar seu e a emissão de ações potencialmente feitas de maneira acidental por olhar para algo por muito tempo resultará em uma experiência terrível.</span><span class="sxs-lookup"><span data-stu-id="14708-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="14708-189">É por isso que recomendamos a combinação do foco com o olhar com um *comando de voz*, um *gesto com as mãos*, um *clique de botão* ou uma espera estendida para disparar a seleção de um alvo.</span><span class="sxs-lookup"><span data-stu-id="14708-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="14708-190">Essa solução também permite um modo no qual o usuário possa olhar livremente em volta sem a sensação desesperadora de disparar algo involuntariamente.</span><span class="sxs-lookup"><span data-stu-id="14708-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="14708-191">Esse problema também deve ser levado em conta durante o design de comentários visuais e auditivos ao simplesmente olhar para um alvo.</span><span class="sxs-lookup"><span data-stu-id="14708-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="14708-192">Não sobrecarregue o usuário com efeitos de desencaixe imediatos ou sons de foco.</span><span class="sxs-lookup"><span data-stu-id="14708-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="14708-193">O segredo é empregar a sutileza.</span><span class="sxs-lookup"><span data-stu-id="14708-193">Subtlety is key!</span></span> <span data-ttu-id="14708-194">Abordaremos algumas melhores práticas para isso mais adiante quando falarmos a respeito de recomendações sobre design.</span><span class="sxs-lookup"><span data-stu-id="14708-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="14708-195">**Observação vs. controle** Imagine que você deseje alinhar com precisão uma fotografia em seu mural.</span><span class="sxs-lookup"><span data-stu-id="14708-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="14708-196">Você olha para as bordas da fotografia e em volta dela para ver se ela fica bem alinhada.</span><span class="sxs-lookup"><span data-stu-id="14708-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="14708-197">Agora imagine como você fará isso quando, ao mesmo tempo, você deseja usar seu foco com o olhar como entrada para mover a imagem.</span><span class="sxs-lookup"><span data-stu-id="14708-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="14708-198">Difícil, não é mesmo?</span><span class="sxs-lookup"><span data-stu-id="14708-198">Difficult, isn't it?</span></span> <span data-ttu-id="14708-199">Isso descreve a função dupla do foco com o olhar quando ele é necessário tanto para a entrada quanto para o controle.</span><span class="sxs-lookup"><span data-stu-id="14708-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="14708-200">**Sair antes de clicar:** Para seleções de alvo rápidas, as pesquisas mostram que o foco com o olhar de um usuário pode passar para outra coisa antes de concluir um clique manual (por exemplo, um gesto de fechar e abrir dedos indicador e polegar).</span><span class="sxs-lookup"><span data-stu-id="14708-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="14708-201">Portanto, atenção especial deve ser dada à sincronização do sinal de foco com o olhar rápido com uma entrada de controle mais lenta (por exemplo, voz, mãos, controle).</span><span class="sxs-lookup"><span data-stu-id="14708-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="14708-202">**Alvos pequenos:** Você já teve a sensação de tentar ler um texto que é muito pequeno para uma leitura confortável?</span><span class="sxs-lookup"><span data-stu-id="14708-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="14708-203">Essa sensação de sobrecarregar os olhos que faz com que você se sinta exausto porque tenta reajustar seus olhos para focar melhor?</span><span class="sxs-lookup"><span data-stu-id="14708-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="14708-204">Essa é uma sensação que você poderá invocar nos usuários quando forçá-los a selecionar alvos muito pequenos no aplicativo usando o direcionamento ocular.</span><span class="sxs-lookup"><span data-stu-id="14708-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="14708-205">Para o design, visando criar uma experiência agradável e confortável para seus usuários, recomendamos que os alvos tenham um ângulo visual de, pelo menos, 2°, preferencialmente maior.</span><span class="sxs-lookup"><span data-stu-id="14708-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="14708-206">**Movimentos irregulares do foco com o olhar** Nossos olhos fazem movimentações rápidas de fixação em fixação.</span><span class="sxs-lookup"><span data-stu-id="14708-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="14708-207">Se você examinar os caminhos de exame dos movimentos oculares registrados, poderá ver que eles parecem irregulares.</span><span class="sxs-lookup"><span data-stu-id="14708-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="14708-208">Seus olhos se movem rapidamente e em saltos espontâneos comparado ao *foco com a cabeça* ou aos *movimentos com as mãos*.</span><span class="sxs-lookup"><span data-stu-id="14708-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="14708-209">**Confiabilidade de acompanhamento:** A precisão do acompanhamento ocular pode diminuir um pouco sob iluminação em constante mudança, pois o olho se ajusta às novas condições.</span><span class="sxs-lookup"><span data-stu-id="14708-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="14708-210">Embora isso necessariamente não deva afetar o design do aplicativo, pois a precisão deve estar dentro da limitação mencionada acima de 2°.</span><span class="sxs-lookup"><span data-stu-id="14708-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="14708-211">Isso pode significar que o usuário precise executar outra calibragem.</span><span class="sxs-lookup"><span data-stu-id="14708-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="14708-212">Recomendações sobre design</span><span class="sxs-lookup"><span data-stu-id="14708-212">Design recommendations</span></span>
<span data-ttu-id="14708-213">A seguir, listamos recomendações sobre design específicas de acordo com as vantagens e os desafios descritos sobre a entrada de foco com o olhar:</span><span class="sxs-lookup"><span data-stu-id="14708-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="14708-214">**Foco com o olhar! = foco com a cabeça:**</span><span class="sxs-lookup"><span data-stu-id="14708-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="14708-215">**Considere se movimentos oculares rápidos, ainda que irregulares, se ajustam à sua tarefa de entrada:** Embora nossos movimentos oculares rápidos e irregulares sejam ótimos para selecionar alvos rapidamente em nosso campo de visão, eles são menos aplicáveis a tarefas que exigem trajetórias de entrada suave (por exemplo, para desenhar ou circular anotações).</span><span class="sxs-lookup"><span data-stu-id="14708-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="14708-216">Nesse caso, apontar com a mão ou a cabeça deve ser preferencial.</span><span class="sxs-lookup"><span data-stu-id="14708-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="14708-217">**Evite anexar algo diretamente ao foco com o olhar do usuário (por exemplo, um controle deslizante ou um cursor).**</span><span class="sxs-lookup"><span data-stu-id="14708-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="14708-218">No caso de um cursor, isso poderá resultar no efeito de “um cursor fugindo” devido a leves deslocamentos no sinal de foco com o olhar projetado.</span><span class="sxs-lookup"><span data-stu-id="14708-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="14708-219">No caso de um controle deslizante, ele entra em conflito com a função dupla de controlar o controle deslizante com seus olhos, embora também deseje verificar se o objeto está na localização correta.</span><span class="sxs-lookup"><span data-stu-id="14708-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="14708-220">Em resumo, os usuários poderão se sentir sobrecarregados e distraídos, especialmente se o sinal for impreciso para esse usuário.</span><span class="sxs-lookup"><span data-stu-id="14708-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="14708-221">**Combinar o foco com o olhar com outras entradas:** A integração do acompanhamento ocular a outras entradas, como gestos com as mãos, comandos de voz ou pressionamentos de botão, traz várias vantagens:</span><span class="sxs-lookup"><span data-stu-id="14708-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="14708-222">**Permitir a observação livre:** Considerando que a função principal de nossos olhos seja observar o ambiente, é importante permitir que os usuários olhem em volta sem disparar nenhum comentário (visual, auditivo ou outro) nem ação.</span><span class="sxs-lookup"><span data-stu-id="14708-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="14708-223">A combinação do ET com outro controle de entrada permite fazer a transição suave entre a observação do ET e os modos de controle de entrada.</span><span class="sxs-lookup"><span data-stu-id="14708-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="14708-224">**Provedor de contexto avançado:** O uso das informações sobre o ponto para o qual o usuário está olhando, ao mesmo tempo em que ele emite um comando de voz ou executa um gesto com as mãos, permite uma canalização fácil da entrada no campo de visão.</span><span class="sxs-lookup"><span data-stu-id="14708-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="14708-225">Os exemplos incluem: “Coloque isso lá” para selecionar rápida e fluentemente um holograma e posicioná-lo na cena apenas olhando um alvo e o destino.</span><span class="sxs-lookup"><span data-stu-id="14708-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="14708-226">**Necessidade de sincronizar entradas multimodais (problema de “sair antes de clicar”):** A combinação de movimentos oculares rápidos com entradas adicionais mais complexas (por exemplo, comandos de voz longos ou gestos com as mãos) traz o risco de prosseguirmos com o foco com o olhar antes de concluirmos o comando de entrada adicional.</span><span class="sxs-lookup"><span data-stu-id="14708-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="14708-227">Portanto, se você criar seus próprios controles de entrada (por exemplo, gestos com as mãos personalizados), lembre-se de registrar a ocorrência dessa entrada ou sua duração aproximada para correlacioná-la ao que um usuário tinha se fixado no passado.</span><span class="sxs-lookup"><span data-stu-id="14708-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="14708-228">**Comentários sutis para a entrada de acompanhamento ocular:** É útil fornecer comentários se um alvo é observado (para indicar que o sistema está funcionando conforme o esperado), mas isso deve ser sutil.</span><span class="sxs-lookup"><span data-stu-id="14708-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="14708-229">Isso pode incluir a mistura/o desaparecimento lentos de destaques visuais ou a execução de outros comportamentos sutis de alvo, como movimentos lentos (por exemplo, um pequeno aumento do alvo) para indicar que o sistema detectou corretamente que o usuário está olhando para um alvo, no entanto, sem desnecessariamente interromper o fluxo de trabalho atual do usuário.</span><span class="sxs-lookup"><span data-stu-id="14708-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="14708-230">**Evitar a imposição de movimentos oculares artificiais como entrada:** Não force os usuários a realizarem movimentos oculares específicos (gestos com o olhar) para disparar ações em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="14708-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="14708-231">**Levar em conta as imprecisões:** Fazemos distinção de dois tipos de imprecisões que são perceptíveis aos usuários: Deslocamento e tremulação.</span><span class="sxs-lookup"><span data-stu-id="14708-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="14708-232">A maneira mais fácil de lidar com os deslocamentos é fornecer alvos grandes o suficiente para interação [ângulo visual de > 2° – como referência: sua miniatura tem um ângulo visual de aproximadamente 2° quando você estende o braço (1)].</span><span class="sxs-lookup"><span data-stu-id="14708-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="14708-233">Isso resulta nas seguintes diretrizes:</span><span class="sxs-lookup"><span data-stu-id="14708-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="14708-234">Não force os usuários a selecionar alvos minúsculos: As pesquisas mostram que, se os alvos forem suficientemente grandes (e o sistema for muito bem projetado), os usuários descreverão a interação como mágica e sem esforço.</span><span class="sxs-lookup"><span data-stu-id="14708-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="14708-235">Se os alvos ficarem muito pequenos, os usuários descreverão a experiência como cansativa e frustrante.</span><span class="sxs-lookup"><span data-stu-id="14708-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="14708-236">Consulte também</span><span class="sxs-lookup"><span data-stu-id="14708-236">See also</span></span>
* [<span data-ttu-id="14708-237">Focar com a cabeça e confirmar</span><span class="sxs-lookup"><span data-stu-id="14708-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="14708-238">Olhar fixo com cabeça e olhos no DirectX</span><span class="sxs-lookup"><span data-stu-id="14708-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="14708-239">Foco com o olhar no Unity (Kit de Ferramentas de Realidade Misturada)</span><span class="sxs-lookup"><span data-stu-id="14708-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="14708-240">Gestos de mão</span><span class="sxs-lookup"><span data-stu-id="14708-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="14708-241">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="14708-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="14708-242">Controladores de movimentos</span><span class="sxs-lookup"><span data-stu-id="14708-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="14708-243">Conforto</span><span class="sxs-lookup"><span data-stu-id="14708-243">Comfort</span></span>](comfort.md)
