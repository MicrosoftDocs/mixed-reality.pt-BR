---
title: Acompanhamento a olho nu
description: Acompanhamento a olho nu
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Acompanhamento de olhos, misturadas realidade, entrada, olhar olho
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: 60060386305eabfac2758a2c861a43c36286b151
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 05/31/2019
ms.locfileid: "66453697"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="4889c-104">Acompanhamento em HoloLens 2 a olho nu</span><span class="sxs-lookup"><span data-stu-id="4889c-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="4889c-105">HoloLens 2 permite um nível totalmente novo de contexto e o entendimento humanos dentro a experiência holográfica, fornecendo aos desenvolvedores com a incrível capacidade de uso das informações sobre o que os usuários estão vendo.</span><span class="sxs-lookup"><span data-stu-id="4889c-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="4889c-106">Esta página fornece uma visão geral de como os desenvolvedores podem se beneficiar de acompanhamento de olho para vários casos de uso e o que procurar durante a criação de interfaces do usuário com base em olhar olho.</span><span class="sxs-lookup"><span data-stu-id="4889c-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="4889c-107">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="4889c-107">Use cases</span></span>
<span data-ttu-id="4889c-108">Acompanhamento a olho nu permite que os aplicativos controlar onde o usuário está procurando em tempo real.</span><span class="sxs-lookup"><span data-stu-id="4889c-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="4889c-109">Esta seção descreve algumas das possíveis casos de uso e novas interações que se tornam possíveis com os olhos de acompanhamento na realidade mista.</span><span class="sxs-lookup"><span data-stu-id="4889c-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="4889c-110">Antes de começar, no seguinte mencionaremos a [Kit de ferramentas de realidade misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) várias vezes, pois ele fornece vários exemplos de interessantes e potente para usar o rastreamento de olho como destino com suporte de olho rápido e fácil as seleções e automaticamente rolar por texto com base em onde o usuário levar analisando.</span><span class="sxs-lookup"><span data-stu-id="4889c-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="4889c-111">Intenção do usuário</span><span class="sxs-lookup"><span data-stu-id="4889c-111">User intent</span></span>    
<span data-ttu-id="4889c-112">Informações sobre onde um usuário examina fornecem um poderoso **contexto para outras entradas**, como voz, mãos e controladores.</span><span class="sxs-lookup"><span data-stu-id="4889c-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="4889c-113">Isso pode ser usado para várias tarefas.</span><span class="sxs-lookup"><span data-stu-id="4889c-113">This can be used for various tasks.</span></span>
<span data-ttu-id="4889c-114">Por exemplo, isso pode variar de forma rápida e facilmente **direcionamento** entre a cena simplesmente observando um holograma e dizendo "selecionar" (Consulte também [olhar Head e confirmação](gaze-and-commit.md)) ou dizendo "colocar isso...", em seguida, procurando para onde deseja colocar o holograma e dizer "... There".</span><span class="sxs-lookup"><span data-stu-id="4889c-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="4889c-115">Exemplos para isso podem ser encontrados em [Toolkit de realidade misturada - seleção de destino com suporte de olho](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Kit de ferramentas realidade misturada - posicionamento de destino com suporte de olho](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="4889c-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="4889c-116">Um exemplo adicional de intenção do usuário pode incluir usando informações sobre o que os usuários se examinar para melhorar o engajamento com agentes virtuais embodied e hologramas interativas.</span><span class="sxs-lookup"><span data-stu-id="4889c-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="4889c-117">Por exemplo, agentes virtuais poderão adaptar as opções disponíveis e seu comportamento com base em atualmente exibido o conteúdo.</span><span class="sxs-lookup"><span data-stu-id="4889c-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="4889c-118">Ações implícitas</span><span class="sxs-lookup"><span data-stu-id="4889c-118">Implicit actions</span></span>
<span data-ttu-id="4889c-119">A categoria de ações implícitas está intimamente relacionado à intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="4889c-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="4889c-120">A ideia é hologramas ou elementos de interface do usuário reagem de forma um pouco instinctual pode não até mesmo parecer que você está interagindo com o sistema em todos os, mas em vez disso, o sistema e o usuário estão em sincronia. Por exemplo, é um exemplo bastante bem-sucedida **rolagem automática com base em olhar olho**.</span><span class="sxs-lookup"><span data-stu-id="4889c-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="4889c-121">A ideia é simple: O usuário lê um texto e pode apenas continue lendo.</span><span class="sxs-lookup"><span data-stu-id="4889c-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="4889c-122">O texto gradualmente move para manter os usuários em seu fluxo de leitura.</span><span class="sxs-lookup"><span data-stu-id="4889c-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="4889c-123">Um aspecto importante é que a velocidade de rolagem se adapta à velocidade de leitura do usuário.</span><span class="sxs-lookup"><span data-stu-id="4889c-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="4889c-124">Outro exemplo é **suporte de olho zoom e panorâmica** para que o usuário pode parecer mergulhar exatamente em direção a que ele tem se concentrado em.</span><span class="sxs-lookup"><span data-stu-id="4889c-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="4889c-125">Disparando o zoom e controlar a velocidade de zoom podem ser controlados por meio de voz ou entregar a entrada que é importante sobre como fornecer a sensação de controle e evitar sobrecarregar o usuário (falaremos sobre essas diretrizes de design em mais detalhes abaixo).</span><span class="sxs-lookup"><span data-stu-id="4889c-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="4889c-126">Depois de ampliar, o usuário pode perfeitamente seguir, por exemplo, o curso de uma rua para explorar seu ambiente usando simplesmente olhar seus olhos.</span><span class="sxs-lookup"><span data-stu-id="4889c-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="4889c-127">Exemplos de demonstração para esses tipos de interações podem ser encontrados na [Toolkit de realidade mista - navegação com suporte de olho](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) exemplo.</span><span class="sxs-lookup"><span data-stu-id="4889c-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="4889c-128">Casos para usar o adicionais _implícitas ações_ podem incluir:</span><span class="sxs-lookup"><span data-stu-id="4889c-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="4889c-129">**Notificações inteligentes:** Nunca obter incomodar com notificações pop-up de direita onde você foram concentrando-se?</span><span class="sxs-lookup"><span data-stu-id="4889c-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="4889c-130">Levando em conta em que um usuário no momento, está prestando atenção à, você pode torná-lo melhor!</span><span class="sxs-lookup"><span data-stu-id="4889c-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="4889c-131">Mostre notificações de deslocamento a partir de onde o usuário atualmente está procurando para limitar distrações e ignorá-las de uma vez automaticamente terminar de ler.</span><span class="sxs-lookup"><span data-stu-id="4889c-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="4889c-132">**Hologramas atenciosos:** Hologramas que sutilmente reagem quando está sendo analisado.</span><span class="sxs-lookup"><span data-stu-id="4889c-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="4889c-133">Isso pode variar de elementos de interface do usuário ligeiramente brilhantes, uma flor blooming lentamente a uma inicialização animais de estimação virtual examinar novamente a você ou tentando evitar seu foco de olho após um olhando prolongado.</span><span class="sxs-lookup"><span data-stu-id="4889c-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="4889c-134">Isso pode fornecer um senso interessante de conectividade e a satisfação em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="4889c-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="4889c-135">Acompanhamento de atenção</span><span class="sxs-lookup"><span data-stu-id="4889c-135">Attention tracking</span></span>   
<span data-ttu-id="4889c-136">Informações sobre onde os usuários procuram no são uma ferramenta e poderosa para avaliar a usabilidade dos designs e para identificar problemas em fluxos de trabalho eficientes.</span><span class="sxs-lookup"><span data-stu-id="4889c-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="4889c-137">Agora, a visualização e análise de acompanhamento a olho nu já é uma prática comum em várias áreas do aplicativo.</span><span class="sxs-lookup"><span data-stu-id="4889c-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="4889c-138">Com o HoloLens 2, fornecemos uma nova dimensão para essa compreensão conforme hologramas 3D podem ser colocadas em contextos do mundo real e avaliadas junto com o.</span><span class="sxs-lookup"><span data-stu-id="4889c-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="4889c-139">O [Kit de ferramentas de realidade misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fornece exemplos básicos para registro em log e carregar dados de acompanhamento a olho nu e como visualizá-las.</span><span class="sxs-lookup"><span data-stu-id="4889c-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="4889c-140">Outros aplicativos nessa área podem incluir:</span><span class="sxs-lookup"><span data-stu-id="4889c-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="4889c-141">**Visualização de olhar olho remoto:** Visualizar o que os colaboradores remotos estão vendo, por exemplo, verifique se as instruções são compreendidas e seguidas corretamente.</span><span class="sxs-lookup"><span data-stu-id="4889c-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="4889c-142">**Estudos de pesquisa de usuário:** Atenção de controle pode ser usada para explorar a maneira de iniciante versus usuários especialistas analisar visualmente o conteúdo ou a sua coordenação mão de olho em tarefas complexas (por exemplo, para análise de dados médicos ou enquanto estiver operando máquinas).</span><span class="sxs-lookup"><span data-stu-id="4889c-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="4889c-143">**Simulações de treinamento e monitoramento de desempenho:** Pratique e otimizar a execução de tarefas, identificando gargalos com mais eficiência no fluxo de execução.</span><span class="sxs-lookup"><span data-stu-id="4889c-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="4889c-144">**As avaliações, o anúncio e a pesquisa de marketing de design:** Acompanhamento a olho nu é uma ferramenta comum para pesquisa de mercado avaliar os designs de site e o produto.</span><span class="sxs-lookup"><span data-stu-id="4889c-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="4889c-145">Casos de uso adicionais</span><span class="sxs-lookup"><span data-stu-id="4889c-145">Additional use cases</span></span>
- <span data-ttu-id="4889c-146">**Jogos:** Você já quis ter superpoderes?</span><span class="sxs-lookup"><span data-stu-id="4889c-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="4889c-147">Esta é sua chance!</span><span class="sxs-lookup"><span data-stu-id="4889c-147">Here's your chance!</span></span> <span data-ttu-id="4889c-148">Levitate hologramas por olhando-los.</span><span class="sxs-lookup"><span data-stu-id="4889c-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="4889c-149">Envie a laser emissões de seus olhos.</span><span class="sxs-lookup"><span data-stu-id="4889c-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="4889c-150">Transformar inimigos em pedra ou congele!</span><span class="sxs-lookup"><span data-stu-id="4889c-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="4889c-151">Use sua visão de raios-x para explorar os prédios.</span><span class="sxs-lookup"><span data-stu-id="4889c-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="4889c-152">O limite é de sua imaginação!</span><span class="sxs-lookup"><span data-stu-id="4889c-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="4889c-153">**Avatares expressivas:** Acompanhamento a olho nu auxilia na mais expressivos avatares 3D usando Data do rastreamento de olho em tempo real para animar os olhos do avatar para indicar o que o usuário atualmente está procurando.</span><span class="sxs-lookup"><span data-stu-id="4889c-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="4889c-154">Ele também adiciona mais expressividade adicionando winks e pisca.</span><span class="sxs-lookup"><span data-stu-id="4889c-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="4889c-155">**Entrada de texto:** Acompanhamento a olho nu pode ser usado como uma alternativa interessante para entrada de texto de baixo esforço, especialmente quando se fala ou mãos são inconvenientes para uso.</span><span class="sxs-lookup"><span data-stu-id="4889c-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="4889c-156">API de acompanhamento de olhos</span><span class="sxs-lookup"><span data-stu-id="4889c-156">Eye tracking API</span></span>
<span data-ttu-id="4889c-157">Antes de entrar em detalhes sobre as diretrizes de design específicas para interação de olho olhar, queremos brevemente apontar para os recursos que o rastreador de olho HoloLens 2 está fornecendo.</span><span class="sxs-lookup"><span data-stu-id="4889c-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="4889c-158">O [olho que acompanha a API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) pode ser acessado por meio de: `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="4889c-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="4889c-159">Ele fornece um raio de olhar olho único (origem olhar e direção) para desenvolvedores.</span><span class="sxs-lookup"><span data-stu-id="4889c-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="4889c-160">O rastreador de olho fornece dados sobre _30 FPS_.</span><span class="sxs-lookup"><span data-stu-id="4889c-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="4889c-161">Olhar o olho previsto está dentro de autoridade de certificação.</span><span class="sxs-lookup"><span data-stu-id="4889c-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="4889c-162">1.0-1,5 graus ângulo visual em torno de real procurados no destino.</span><span class="sxs-lookup"><span data-stu-id="4889c-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="4889c-163">Como pequenas imprecisions forem esperados, você deve planejar alguma margem em torno desse valor de limite inferior.</span><span class="sxs-lookup"><span data-stu-id="4889c-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="4889c-164">Falaremos sobre isso mais abaixo.</span><span class="sxs-lookup"><span data-stu-id="4889c-164">We will discuss this more below.</span></span> <span data-ttu-id="4889c-165">Para acompanhamento a olho nu para trabalhar com precisão, cada usuário é necessário para percorrer uma calibração de usuário de acompanhamento a olho nu.</span><span class="sxs-lookup"><span data-stu-id="4889c-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="4889c-166">![Tamanho de destino ideal a distância do medidor 2](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="4889c-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="4889c-167">*Tamanho de destino ideal a distância do medidor 2*</span><span class="sxs-lookup"><span data-stu-id="4889c-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="4889c-168">Diretrizes de design de olhar olho</span><span class="sxs-lookup"><span data-stu-id="4889c-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="4889c-169">Criar uma interação que tira proveito do direcionamento de olho movimentação rápida pode ser um desafio.</span><span class="sxs-lookup"><span data-stu-id="4889c-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="4889c-170">Nesta seção, resumimos os desafios a serem considerados ao projetar seu aplicativo e as principais vantagens.</span><span class="sxs-lookup"><span data-stu-id="4889c-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="4889c-171">Benefícios de olho olhar entrada</span><span class="sxs-lookup"><span data-stu-id="4889c-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="4889c-172">**Apontando de alta velocidade.**</span><span class="sxs-lookup"><span data-stu-id="4889c-172">**High speed pointing.**</span></span> <span data-ttu-id="4889c-173">O músculo olhos é o mais rápido reacting músculo no nosso corpo.</span><span class="sxs-lookup"><span data-stu-id="4889c-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="4889c-174">**Pouco esforço.**</span><span class="sxs-lookup"><span data-stu-id="4889c-174">**Low effort.**</span></span> <span data-ttu-id="4889c-175">Quase nenhum movimentos físicos são necessários.</span><span class="sxs-lookup"><span data-stu-id="4889c-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="4889c-176">**Implicitness.**</span><span class="sxs-lookup"><span data-stu-id="4889c-176">**Implicitness.**</span></span> <span data-ttu-id="4889c-177">Geralmente descrita por usuários como "Lembre-se de leitura", informações sobre os movimentos de olho de um usuário permite que o sistema sabe que se envolver com os planos de usuário de destino.</span><span class="sxs-lookup"><span data-stu-id="4889c-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="4889c-178">**Canal de entrada alternativo.**</span><span class="sxs-lookup"><span data-stu-id="4889c-178">**Alternative input channel.**</span></span> <span data-ttu-id="4889c-179">Olhar olho pode fornecer uma entrada de suporte eficiente para mão e voz entrada criando em anos de experiência dos usuários com base em sua coordenação de olho-de-mão.</span><span class="sxs-lookup"><span data-stu-id="4889c-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="4889c-180">**Atenção Visual.**</span><span class="sxs-lookup"><span data-stu-id="4889c-180">**Visual attention.**</span></span> <span data-ttu-id="4889c-181">Outro importante benefício é a possibilidade de inferir o que um usuário é prestar atenção.</span><span class="sxs-lookup"><span data-stu-id="4889c-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="4889c-182">Isso pode ajudar em várias áreas do aplicativo, variando de mais efetivamente avaliando designs diferentes para ajudar a Interfaces de usuário mais inteligentes e aprimorado indicações sociais para comunicação remota.</span><span class="sxs-lookup"><span data-stu-id="4889c-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="4889c-183">Em resumo, usando olhar olho como uma entrada potencialmente oferece um sinal contextual rápido e fácil – isso é especialmente eficiente em combinação com outras entradas, como *voz* e *manual* a entrada para Confirme se a intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="4889c-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="4889c-184">Desafios de olho olhares como uma entrada</span><span class="sxs-lookup"><span data-stu-id="4889c-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="4889c-185">Com muita energia, vem muita responsabilidade: Ao olhar olho pode ser usado para criar experiências de usuário mágico pareçam uma super-herói, também é importante saber o que isso não é bom na conta para este adequadamente.</span><span class="sxs-lookup"><span data-stu-id="4889c-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="4889c-186">A seguir, discutiremos alguns *desafios* levar em conta e como resolvê-los ao trabalhar com olhos olhar entrada:</span><span class="sxs-lookup"><span data-stu-id="4889c-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="4889c-187">**Seu foco de olho é "sempre ativado"** no momento em que você abrir tampas seus olhos, seus olhos iniciar fixating coisas em seu ambiente.</span><span class="sxs-lookup"><span data-stu-id="4889c-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="4889c-188">Reagindo a cada procure a marca e ações de emissão potencialmente acidentalmente, porque você observou algo por muito tempo resultaria em uma experiência terrível!</span><span class="sxs-lookup"><span data-stu-id="4889c-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="4889c-189">Isso é por isso, recomendamos a combinação de olho olhar com um *comando de voz*, *entregar gesto*, *clique de botão* ou duração estendida para disparar a seleção de um destino.</span><span class="sxs-lookup"><span data-stu-id="4889c-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="4889c-190">Essa solução também permite que um modo no qual o usuário pode livremente olhar em volta sem a incrível sensação de disparo involuntariamente algo.</span><span class="sxs-lookup"><span data-stu-id="4889c-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="4889c-191">Esse problema também deve ser levado em conta durante a criação de comentários visuais e auditivos ao examinar apenas um destino.</span><span class="sxs-lookup"><span data-stu-id="4889c-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="4889c-192">Não sobrecarregar o usuário com efeitos de pop-out imediatos ou passe o mouse sons.</span><span class="sxs-lookup"><span data-stu-id="4889c-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="4889c-193">Sutileza é a chave!</span><span class="sxs-lookup"><span data-stu-id="4889c-193">Subtlety is key!</span></span> <span data-ttu-id="4889c-194">Vamos discutir algumas práticas recomendadas para a seguir quando falamos sobre recomendações de design.</span><span class="sxs-lookup"><span data-stu-id="4889c-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="4889c-195">**Observação versus controle** Imagine que você deseja alinhar precisamente uma fotografia no seu mural.</span><span class="sxs-lookup"><span data-stu-id="4889c-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="4889c-196">Examinar suas bordas e seu entorno para ver se ele se alinhe bem.</span><span class="sxs-lookup"><span data-stu-id="4889c-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="4889c-197">Agora imagine como você faria isso quando ao mesmo tempo que você deseja usar seu foco de olho como uma entrada para mover a imagem.</span><span class="sxs-lookup"><span data-stu-id="4889c-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="4889c-198">Difícil, não é mesmo?</span><span class="sxs-lookup"><span data-stu-id="4889c-198">Difficult, isn't it?</span></span> <span data-ttu-id="4889c-199">Isso descreve a função dupla de olhar de olho quando for necessário tanto para entrada e controle.</span><span class="sxs-lookup"><span data-stu-id="4889c-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="4889c-200">**Sair antes de clique:** Para seleções de destino rápida pesquisa mostrou que olhar de olho de um usuário pode passar antes de concluir um manual clique (por exemplo, um airtap).</span><span class="sxs-lookup"><span data-stu-id="4889c-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="4889c-201">Portanto, atenção especial deve ser dada para sincronizar o sinal de olhar olho rápido com a entrada de controle mais lenta (por exemplo, voz, mãos, controlador).</span><span class="sxs-lookup"><span data-stu-id="4889c-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="4889c-202">**Destinos pequeno:** Você sabe a sensação ao tentar ler o texto que é apenas um pouco muito pequeno para ler confortavelmente?</span><span class="sxs-lookup"><span data-stu-id="4889c-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="4889c-203">Essa sensação de sobrecarregar os olhos que fazem com que você se sinta cansados e gasta out porque tentar reajustar seus olhos para focar melhor?</span><span class="sxs-lookup"><span data-stu-id="4889c-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="4889c-204">Isso é uma sensação que você pode invocar seus usuários quando forçá-los para selecionar destinos muito pequenos em seu aplicativo usando o direcionamento de olho.</span><span class="sxs-lookup"><span data-stu-id="4889c-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="4889c-205">Para o seu design, para criar uma experiência agradável e à vontade para seus usuários, é recomendável que os destinos devem ser pelo menos 2° em ângulo visual, preferencialmente maior.</span><span class="sxs-lookup"><span data-stu-id="4889c-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="4889c-206">**Irregular movimentos de olhar olho** olhos realizar movimentações rápidas de fixação para fixação da.</span><span class="sxs-lookup"><span data-stu-id="4889c-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="4889c-207">Se você examinar os caminhos de varredura de movimentações de olho gravados, você pode ver que eles parecem irregulares.</span><span class="sxs-lookup"><span data-stu-id="4889c-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="4889c-208">Seus olhos mover rapidamente e em saltos espontâneas em comparação com *olhar principal* ou *entregar movimentos*.</span><span class="sxs-lookup"><span data-stu-id="4889c-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="4889c-209">**Confiabilidade de rastreamento:** Precisão de acompanhamento a olho nu pode diminuir um pouco na luz e alterado conforme seus olhos ajustar para as novas condições.</span><span class="sxs-lookup"><span data-stu-id="4889c-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="4889c-210">Embora isso necessariamente não deve afetar o design de aplicativo, como a precisão deve estar dentro a limitação mencionada acima de 2°.</span><span class="sxs-lookup"><span data-stu-id="4889c-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="4889c-211">Pode significar que o usuário tem que executar calibragem do outro.</span><span class="sxs-lookup"><span data-stu-id="4889c-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="4889c-212">Recomendações de design</span><span class="sxs-lookup"><span data-stu-id="4889c-212">Design recommendations</span></span>
<span data-ttu-id="4889c-213">A seguir, listamos as recomendações de design específicas com base nas vantagens descritas e desafios para olho mantenha o foco de entrada:</span><span class="sxs-lookup"><span data-stu-id="4889c-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="4889c-214">**Olhar olho! = olhar Head:**</span><span class="sxs-lookup"><span data-stu-id="4889c-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="4889c-215">**Considere se rápido ainda movimentos de olho desbalanceadas ajustar sua tarefa de entrada:** Embora nosso movimentos de olho rápida e irregulares são ótimos selecionar rapidamente os destinos em nosso campo de visão, é menos aplicável para tarefas que exigem smooth trajetórias de entrada (por exemplo, para desenhar ou encircling anotações).</span><span class="sxs-lookup"><span data-stu-id="4889c-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="4889c-216">Nesse caso, manualmente ou head apontando deve ser preferencial.</span><span class="sxs-lookup"><span data-stu-id="4889c-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="4889c-217">**Evite anexando algo diretamente ao olhar de olho do usuário (por exemplo, um controle deslizante ou cursor).**</span><span class="sxs-lookup"><span data-stu-id="4889c-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="4889c-218">No caso de um cursor, isso pode resultar no efeito "fleeing cursor" devido à pequenas deslocamentos no sinal de olhar olho projetado.</span><span class="sxs-lookup"><span data-stu-id="4889c-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="4889c-219">No caso de um controle deslizante, ele entra em conflito com a função dupla de controlar o controle deslizante com seus olhos, apesar de desejarem também verificar se o objeto está no local correto.</span><span class="sxs-lookup"><span data-stu-id="4889c-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="4889c-220">Em resumo, os usuários podem se sentir sobrecarregado e distraído, especialmente se o sinal é impreciso para esse usuário.</span><span class="sxs-lookup"><span data-stu-id="4889c-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="4889c-221">**Combine olho olhar com outras entradas:** A integração do controle de olho com outras entradas, como gestos de mão, comandos de voz ou pressionamentos de botão, tem várias vantagens:</span><span class="sxs-lookup"><span data-stu-id="4889c-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="4889c-222">**Permitir a Observação gratuitamente:** Considerando que a função principal da seus olhos é observar o nosso ambiente, é importante permitir que usuários olhar em volta sem disparar qualquer (visuais, auditivas,...) comentários ou ações.</span><span class="sxs-lookup"><span data-stu-id="4889c-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="4889c-223">Combinar ET com outro controle de entrada permite fazer a transição suave entre os modos de controle de entrada e de Observação ET.</span><span class="sxs-lookup"><span data-stu-id="4889c-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="4889c-224">**Provedor de contexto avançados:** Usando informações sobre onde o usuário está observando ao mesmo tempo em que dizer a um comando de voz ou executar um gesto de mão permite facilmente canalização de entrada entre o campo de visualização.</span><span class="sxs-lookup"><span data-stu-id="4889c-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="4889c-225">Os exemplos incluem: "Put que lá" em rapidamente fluentemente e selecione posicionar um holograma entre a cena examinando simplesmente um alvo e de destino.</span><span class="sxs-lookup"><span data-stu-id="4889c-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="4889c-226">**Necessidade de sincronizar entradas multimodais (problema de "deixe antes de clicar em"):** Combinação de movimentações de olho rápida com mais complexas entradas adicionais (por exemplo, comandos de voz longo ou gestos de mão) guarda o risco de avançarmos com seu foco de olho antes de concluir o comando de entrada adicional.</span><span class="sxs-lookup"><span data-stu-id="4889c-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="4889c-227">Portanto, se você criar seus próprios controles de entrada (por exemplo, gestos de mão personalizado), certifique-se fazer logon do início desta duração aproximada ou de entrada para correlacioná-los com o que um usuário tinha concentrada no passado.</span><span class="sxs-lookup"><span data-stu-id="4889c-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="4889c-228">**Comentários sutis para entrada de acompanhamento a olho nu:** É útil fornecer comentários, se um destino examinou (para indicar que o sistema está funcionando conforme o esperado), mas deve ser mantido sutil.</span><span class="sxs-lookup"><span data-stu-id="4889c-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="4889c-229">Isso pode incluir combinação lentamente de entrada/saída destaques do visual ou executar outros comportamentos de destino sutis, como movimentos lenta (por exemplo, aumentando ligeiramente o destino) para indicar que o sistema detectou corretamente que o usuário está observando um destino, no entanto, sem interromper o fluxo de trabalho atual do usuário desnecessariamente.</span><span class="sxs-lookup"><span data-stu-id="4889c-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="4889c-230">**Evite a imposição de movimentações de olho artificial como entrada:** Não force os usuários realizem movimentos de olho específico (gestos de olhar) para disparar ações em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="4889c-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="4889c-231">**Conta para imprecisions:** Fazemos distinção dois tipos de imprecisions que são perceptíveis aos usuários: Deslocamento e variação.</span><span class="sxs-lookup"><span data-stu-id="4889c-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="4889c-232">A maneira mais fácil para os deslocamentos de endereço é fornecer destinos grandes o suficiente para interagir com (> 2° em ângulo visual – como referência: sua miniatura é aproximadamente 2° em ângulo visual quando você se estendem o arm (1)).</span><span class="sxs-lookup"><span data-stu-id="4889c-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="4889c-233">Isso leva as seguintes diretrizes:</span><span class="sxs-lookup"><span data-stu-id="4889c-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="4889c-234">Não force os usuários para selecionar destinos pequenos: Pesquisas mostram que, se os destinos são suficientemente grandes (e o sistema é muito bem projetado), os usuários descrevem a interação como mágica e sem nenhum esforço.</span><span class="sxs-lookup"><span data-stu-id="4889c-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="4889c-235">Se os destinos de se tornar muito pequenos, os usuários descrevem a experiência como fatiguing e frustrante.</span><span class="sxs-lookup"><span data-stu-id="4889c-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="4889c-236">Consulte também</span><span class="sxs-lookup"><span data-stu-id="4889c-236">See also</span></span>
* [<span data-ttu-id="4889c-237">Focar com a cabeça e confirmar</span><span class="sxs-lookup"><span data-stu-id="4889c-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="4889c-238">Olhar fixo com cabeça e olhos no DirectX</span><span class="sxs-lookup"><span data-stu-id="4889c-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="4889c-239">Olhar de olho no Unity (Toolkit de realidade mista)</span><span class="sxs-lookup"><span data-stu-id="4889c-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="4889c-240">Gestos de mão</span><span class="sxs-lookup"><span data-stu-id="4889c-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="4889c-241">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="4889c-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="4889c-242">Controladores de movimentos</span><span class="sxs-lookup"><span data-stu-id="4889c-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="4889c-243">Conforto</span><span class="sxs-lookup"><span data-stu-id="4889c-243">Comfort</span></span>](comfort.md)
