---
title: Foco com a cabeça e confirmação
description: Visão geral do modelo de entrada de foco com a cabeça e confirmação
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Realidade Misturada, foco, direcionamento do foco, interação, design
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: pt-BR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692307"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="89a3f-104">Foco com a cabeça e confirmação</span><span class="sxs-lookup"><span data-stu-id="89a3f-104">Head-gaze and commit</span></span>
<span data-ttu-id="89a3f-105">O foco com a cabeça e confirmação é um modelo de entrada que envolve o direcionamento do foco para um objeto com a cabeça apontando para a frente (direção da cabeça) e, em seguida, a execução de uma ação baseada nela com uma entrada secundária, como o gesto com a mão de fechar e abrir dedos indicador e polegar ou o comando de voz “Selecionar”.</span><span class="sxs-lookup"><span data-stu-id="89a3f-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="89a3f-106">Ele é considerado um modelo de entrada "distante" com manipulação indireta, ou seja, é mais adequado para interagir com o conteúdo que está além do alcance dos braços.</span><span class="sxs-lookup"><span data-stu-id="89a3f-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="89a3f-107">Suporte a dispositivos</span><span class="sxs-lookup"><span data-stu-id="89a3f-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="89a3f-108"><strong>Modelo de entrada</strong></span><span class="sxs-lookup"><span data-stu-id="89a3f-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="89a3f-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1ª geração)</strong></a></span><span class="sxs-lookup"><span data-stu-id="89a3f-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="89a3f-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="89a3f-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="89a3f-111"><a href="immersive-headset-hardware-details.md"><strong>Headsets imersivos</strong></a></span><span class="sxs-lookup"><span data-stu-id="89a3f-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="89a3f-112">Foco com a cabeça e confirmação</span><span class="sxs-lookup"><span data-stu-id="89a3f-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="89a3f-113">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="89a3f-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="89a3f-114">✔️ Recomendado (terceira opção – <a href="interaction-fundamentals.md">confira as outras opções</a>)</span><span class="sxs-lookup"><span data-stu-id="89a3f-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="89a3f-115">➕ Opção alternativa</span><span class="sxs-lookup"><span data-stu-id="89a3f-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="89a3f-116">Foco com a cabeça</span><span class="sxs-lookup"><span data-stu-id="89a3f-116">Head-gaze</span></span>
<span data-ttu-id="89a3f-117">Os headsets de realidade misturada usam a posição e a orientação da cabeça do usuário para determinar seu vetor de direção da cabeça.</span><span class="sxs-lookup"><span data-stu-id="89a3f-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="89a3f-118">Você pode considerar isso como um laser que aponta para a frente, diretamente entre os olhos do usuário.</span><span class="sxs-lookup"><span data-stu-id="89a3f-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="89a3f-119">Essa é uma aproximação bastante grosseira da direção para a qual o usuário está olhando.</span><span class="sxs-lookup"><span data-stu-id="89a3f-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="89a3f-120">Seu aplicativo pode interseccionar esse raio com objetos virtuais ou do mundo real e desenhar um cursor nessa localização para informar o usuário do que ele está direcionando o foco.</span><span class="sxs-lookup"><span data-stu-id="89a3f-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="89a3f-121">Além do foco com a cabeça, alguns headsets de realidade misturada, como o HoloLens 2, incluem sistemas de acompanhamento ocular que produzem um vetor de foco com o olhar.</span><span class="sxs-lookup"><span data-stu-id="89a3f-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="89a3f-122">Isso fornece uma medida refinada da direção para a qual o usuário está olhando.</span><span class="sxs-lookup"><span data-stu-id="89a3f-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="89a3f-123">É possível criar interações de foco e confirmação usando o foco com o olhar, mas isso vem com um conjunto muito diferente de restrições de design, que será abordado separadamente no [artigo sobre acompanhamento ocular](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="89a3f-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="89a3f-124">Confirmação</span><span class="sxs-lookup"><span data-stu-id="89a3f-124">Commit</span></span>
<span data-ttu-id="89a3f-125">Depois de direcionar o foco para um objeto ou um elemento de interface do usuário, o usuário pode interagir com ele ou "clicar" nele usando uma entrada secundária.</span><span class="sxs-lookup"><span data-stu-id="89a3f-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="89a3f-126">Isso é conhecido como a etapa de confirmação do modelo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="89a3f-127">Os seguintes métodos de confirmação são compatíveis:</span><span class="sxs-lookup"><span data-stu-id="89a3f-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="89a3f-128">Gesto de fechar e abrir dedos indicador e polegar</span><span class="sxs-lookup"><span data-stu-id="89a3f-128">Air Tap gesture</span></span>
- <span data-ttu-id="89a3f-129">Emitir o comando de voz "Selecionar" ou um dos comandos de voz direcionados</span><span class="sxs-lookup"><span data-stu-id="89a3f-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="89a3f-130">Pressionar o único botão em um [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="89a3f-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="89a3f-131">Pressionar o botão 'A' em um gamepad Xbox</span><span class="sxs-lookup"><span data-stu-id="89a3f-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="89a3f-132">Pressionar o botão 'A' em um Controle Adaptável Xbox</span><span class="sxs-lookup"><span data-stu-id="89a3f-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="89a3f-133">Foco com a cabeça e gesto de fechar e abrir dedos indicador e polegar</span><span class="sxs-lookup"><span data-stu-id="89a3f-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="89a3f-134">Fechar e abrir dedos indicador e polegar é um gesto de tocar feito com a mão levantada.</span><span class="sxs-lookup"><span data-stu-id="89a3f-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="89a3f-135">Para fazer um gesto de fechar e abrir dedos indicador e polegar, levante o dedo indicador apontando-o para cima e, em seguida, faça um gesto de pinçagem com o polegar e levante o dedo indicador novamente para soltá-lo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="89a3f-136">No HoloLens 1, o gesto de fechar e abrir dedos indicador e polegar é a entrada secundária mais comum.</span><span class="sxs-lookup"><span data-stu-id="89a3f-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Dedo apontado para cima e, em seguida, um movimento de toque ou clique](images/readyandpress.jpg)<br>

<span data-ttu-id="89a3f-138">O gesto de fechar e abrir dedos indicador e polegar também está disponível no HoloLens 2 e foi suavizado comparado à versão original.</span><span class="sxs-lookup"><span data-stu-id="89a3f-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="89a3f-139">Agora quase todos os tipos de gestos de pinçagem são compatíveis, desde que a mão esteja levantada e parada.</span><span class="sxs-lookup"><span data-stu-id="89a3f-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="89a3f-140">Isso facilita muito para os usuários aprenderem e fazerem o gesto.</span><span class="sxs-lookup"><span data-stu-id="89a3f-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="89a3f-141">Esse novo gesto de fechar e abrir dedos indicador e polegar substitui o antigo por meio da mesma API e, portanto, os aplicativos existentes obterão o novo comportamento automaticamente após a recompilação para o HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="89a3f-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="89a3f-142">Foco com a cabeça e comando de voz "Selecionar"</span><span class="sxs-lookup"><span data-stu-id="89a3f-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="89a3f-143">Os comandos de voz são um dos principais métodos de interação de Realidade Misturada.</span><span class="sxs-lookup"><span data-stu-id="89a3f-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="89a3f-144">Eles fornecem um mecanismo muito eficiente de "mãos livres" para controlar o sistema.</span><span class="sxs-lookup"><span data-stu-id="89a3f-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="89a3f-145">Há diferentes tipos de modelos de interação de voz:</span><span class="sxs-lookup"><span data-stu-id="89a3f-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="89a3f-146">O comando genérico "Selecionar", que permite executar um acionamento ou uma confirmação por "clique" como uma entrada secundária.</span><span class="sxs-lookup"><span data-stu-id="89a3f-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="89a3f-147">Comandos de objeto, como "Fechar" ou "Aumentar", que permitem executar e confirmar uma ação como uma entrada secundária.</span><span class="sxs-lookup"><span data-stu-id="89a3f-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="89a3f-148">Comandos globais, como "Ir para o início", que não exigem um alvo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="89a3f-149">Interfaces de usuário de conversa ou entidades, como a Cortana, que têm uma funcionalidade de Idioma Natural de IA.</span><span class="sxs-lookup"><span data-stu-id="89a3f-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="89a3f-150">Comandos personalizados</span><span class="sxs-lookup"><span data-stu-id="89a3f-150">Custom commnads</span></span>

<span data-ttu-id="89a3f-151">Para encontrar mais detalhes e uma lista abrangente de comandos disponíveis e como usá-los, confira nossas diretrizes de [comandos de voz](voice-design.md).</span><span class="sxs-lookup"><span data-stu-id="89a3f-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="89a3f-152">Foco com a cabeça e HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="89a3f-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="89a3f-153">O HoloLens Clicker é o primeiro dispositivo periférico criado especificamente para o HoloLens e está incluído no HoloLens 1 Development Edition.</span><span class="sxs-lookup"><span data-stu-id="89a3f-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="89a3f-154">O HoloLens Clicker permite que um usuário faça um clique com movimentos mínimos com as mãos e uma confirmação como uma entrada secundária.</span><span class="sxs-lookup"><span data-stu-id="89a3f-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="89a3f-155">O HoloLens Clicker conecta-se ao HoloLens 1 ou 2 usando o BTLE (Bluetooth de Baixa Energia).</span><span class="sxs-lookup"><span data-stu-id="89a3f-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="89a3f-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="89a3f-157">*HoloLens Clicker*</span><span class="sxs-lookup"><span data-stu-id="89a3f-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="89a3f-158">Mais informações e instruções sobre como emparelhar o dispositivo podem ser encontradas [aqui](hardware-accessories.md#pairing-bluetooth-accessories)</span><span class="sxs-lookup"><span data-stu-id="89a3f-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="89a3f-159">Foco com a cabeça e Controle sem Fio Xbox</span><span class="sxs-lookup"><span data-stu-id="89a3f-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="89a3f-160">O Controle sem Fio Xbox permite executar um acionamento por "clique" como uma entrada secundária usando o botão A.</span><span class="sxs-lookup"><span data-stu-id="89a3f-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="89a3f-161">O dispositivo é mapeado para um conjunto padrão de ações que ajudam a navegar pelo sistema e controlá-lo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="89a3f-162">Caso você deseje personalizar o controle, use o Aplicativo de Acessórios Xbox para configurar o Controle sem Fio Xbox.</span><span class="sxs-lookup"><span data-stu-id="89a3f-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="89a3f-163">![Controle sem Fio Xbox](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="89a3f-164">*Controle sem Fio Xbox*</span><span class="sxs-lookup"><span data-stu-id="89a3f-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="89a3f-165">Como emparelhar um controle Xbox com o computador</span><span class="sxs-lookup"><span data-stu-id="89a3f-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="89a3f-166">Foco com a cabeça e Controle Adaptável Xbox</span><span class="sxs-lookup"><span data-stu-id="89a3f-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="89a3f-167">Desenvolvido principalmente para atender às necessidades de jogadores com mobilidade limitada, o Controle Adaptável Xbox é um hub unificado para dispositivos que ajuda a tornar a Realidade Misturada mais acessível.</span><span class="sxs-lookup"><span data-stu-id="89a3f-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="89a3f-168">O Controle Adaptável Xbox permite executar um acionamento por "clique" como uma entrada secundária usando o botão A.</span><span class="sxs-lookup"><span data-stu-id="89a3f-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="89a3f-169">O dispositivo é mapeado para um conjunto padrão de ações que ajudam a navegar pelo sistema e controlá-lo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="89a3f-170">Caso você deseje personalizar o controle, use o Aplicativo de Acessórios Xbox para configurar o Controle Adaptável Xbox.</span><span class="sxs-lookup"><span data-stu-id="89a3f-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="89a3f-171">![Controle Adaptável Xbox](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="89a3f-172">*Controle Adaptável Xbox*</span><span class="sxs-lookup"><span data-stu-id="89a3f-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="89a3f-173">Conecte dispositivos externos, como comutadores, botões, montagens e joysticks, para criar uma experiência personalizada de controles exclusivamente sua.</span><span class="sxs-lookup"><span data-stu-id="89a3f-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="89a3f-174">As entradas de botão, thumbstick e gatilho são controladas com dispositivos adaptativos conectados por meio de entradas de 3,5 mm e portas USB.</span><span class="sxs-lookup"><span data-stu-id="89a3f-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="89a3f-175">![Portas do Controle Adaptável Xbox](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="89a3f-176">*Portas do Controle Adaptável Xbox*</span><span class="sxs-lookup"><span data-stu-id="89a3f-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="89a3f-177">Instruções para emparelhar o dispositivo</span><span class="sxs-lookup"><span data-stu-id="89a3f-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="89a3f-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Mais informações disponíveis no site do Xbox</a></span><span class="sxs-lookup"><span data-stu-id="89a3f-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="89a3f-179">Diretrizes de design</span><span class="sxs-lookup"><span data-stu-id="89a3f-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="89a3f-180">Mais diretrizes específicas ao design de foco [em breve](index.md).</span><span class="sxs-lookup"><span data-stu-id="89a3f-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="89a3f-181">Direcionamento de foco com a cabeça</span><span class="sxs-lookup"><span data-stu-id="89a3f-181">Head-gaze targeting</span></span>
<span data-ttu-id="89a3f-182">Todas as interações baseiam-se na capacidade de um usuário direcionar seu foco para o elemento com o qual deseja interagir, independentemente da modalidade de entrada.</span><span class="sxs-lookup"><span data-stu-id="89a3f-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="89a3f-183">No Windows Mixed Reality, isso geralmente é feito com o foco do usuário.</span><span class="sxs-lookup"><span data-stu-id="89a3f-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="89a3f-184">Para permitir que um usuário trabalhe com uma experiência bem-sucedida, o entendimento calculado do sistema da intenção de um usuário e a intenção real do usuário devem estar os mais alinhados possíveis.</span><span class="sxs-lookup"><span data-stu-id="89a3f-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="89a3f-185">Na medida em que o sistema interpreta as ações pretendidas do usuário corretamente, a satisfação e o desempenho melhoram.</span><span class="sxs-lookup"><span data-stu-id="89a3f-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="89a3f-186">Dimensionamento e comentários sobre o alvo</span><span class="sxs-lookup"><span data-stu-id="89a3f-186">Target sizing and feedback</span></span>
<span data-ttu-id="89a3f-187">O vetor de foco demonstrou repetidamente ser utilizável para o direcionamento refinado, mas geralmente funciona melhor para o direcionamento bruto (adquirindo, de certa forma, alvos maiores).</span><span class="sxs-lookup"><span data-stu-id="89a3f-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="89a3f-188">Os tamanhos mínimos do alvo de 1 a 1,5 grau devem permitir ações bem-sucedidas do usuário na maioria dos cenários, embora os alvos de 3 graus normalmente permitam uma maior velocidade.</span><span class="sxs-lookup"><span data-stu-id="89a3f-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="89a3f-189">Observe que o tamanho do alvo escolhido pelo usuário é efetivamente uma área 2D até mesmo para elementos 3D – qualquer que seja a projeção que esteja voltada para eles deverá ser a área de alvo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="89a3f-190">O fornecimento de alguma indicação evidente de que um elemento está "ativo" (ao qual o usuário está direcionando o foco) é extremamente útil – isso pode incluir tratamentos como efeitos de "focalização" visíveis, destaques de áudio ou cliques ou alinhamento claro de um cursor com um elemento.</span><span class="sxs-lookup"><span data-stu-id="89a3f-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="89a3f-191">![Tamanho ideal do alvo em uma distância de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="89a3f-192">*Tamanho ideal do alvo em uma distância de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="89a3f-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="89a3f-193">![Um exemplo de realce de um objeto direcionado por foco](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="89a3f-194">*Um exemplo de realce de um objeto direcionado por foco*</span><span class="sxs-lookup"><span data-stu-id="89a3f-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="89a3f-195">Posicionamento do alvo</span><span class="sxs-lookup"><span data-stu-id="89a3f-195">Target placement</span></span>
<span data-ttu-id="89a3f-196">Em geral, os usuários não encontrarão elementos de interface do usuário posicionados muito acima ou muito abaixo de seu campo de visão, concentrando a maior parte de sua atenção nas áreas em torno de seu foco principal (em geral, aproximadamente no nível dos olhos).</span><span class="sxs-lookup"><span data-stu-id="89a3f-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="89a3f-197">O posicionamento da maioria dos alvos em uma faixa razoável em torno do nível dos olhos pode ajudar.</span><span class="sxs-lookup"><span data-stu-id="89a3f-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="89a3f-198">Dada a tendência dos usuários de se concentrarem em uma área visual relativamente pequena a qualquer momento (o cone de atenção da visão é de aproximadamente 10 graus), o agrupamento de elementos de interface do usuário na medida em que eles estejam relacionados conceitualmente pode aproveitar os comportamentos de encadeamento da atenção de item a item conforme um usuário move o foco por uma área.</span><span class="sxs-lookup"><span data-stu-id="89a3f-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="89a3f-199">Ao projetar a interface do usuário, tenha em mente a grande variação potencial no campo de visão entre o HoloLens e os headsets imersivos.</span><span class="sxs-lookup"><span data-stu-id="89a3f-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="89a3f-200">![Um exemplo de elementos de interface do usuário agrupados para um direcionamento do foco mais fácil no Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="89a3f-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="89a3f-201">*Um exemplo de elementos de interface do usuário agrupados para um direcionamento do foco mais fácil no Galaxy Explorer*</span><span class="sxs-lookup"><span data-stu-id="89a3f-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="89a3f-202">Como melhorar os comportamentos de direcionamento</span><span class="sxs-lookup"><span data-stu-id="89a3f-202">Improving targeting behaviors</span></span>
<span data-ttu-id="89a3f-203">Se a intenção do usuário de direcionar o foco para algo puder ser determinada (ou aproximada), poderá ser muito útil aceitar tentativas "quase certas" na interação como se elas tivessem sido direcionadas corretamente.</span><span class="sxs-lookup"><span data-stu-id="89a3f-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="89a3f-204">Há diversos métodos bem-sucedidos que podem ser incorporados em experiências de realidade misturada:</span><span class="sxs-lookup"><span data-stu-id="89a3f-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="89a3f-205">Estabilização do foco com a cabeça ("poços gravitacionais")</span><span class="sxs-lookup"><span data-stu-id="89a3f-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="89a3f-206">Isso deve estar ligado na maior parte do tempo ou todo o tempo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="89a3f-207">Essa técnica remove as tremulações naturais da cabeça/do pescoço que os usuários possam ter.</span><span class="sxs-lookup"><span data-stu-id="89a3f-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="89a3f-208">Além disso, o movimento devido a comportamentos de visão/fala.</span><span class="sxs-lookup"><span data-stu-id="89a3f-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="89a3f-209">Algoritmos de vínculo mais próximo</span><span class="sxs-lookup"><span data-stu-id="89a3f-209">Closest link algorithms</span></span>
<span data-ttu-id="89a3f-210">Eles funcionam melhor em áreas com conteúdo interativo esparso.</span><span class="sxs-lookup"><span data-stu-id="89a3f-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="89a3f-211">Se houver uma grande probabilidade de que você determine com o que um usuário estava tentando interagir, você poderá complementar suas habilidades de direcionamento apenas supondo algum nível de intenção.</span><span class="sxs-lookup"><span data-stu-id="89a3f-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="89a3f-212">Ações de antedatar/pós-datar</span><span class="sxs-lookup"><span data-stu-id="89a3f-212">Backdating/postdating actions</span></span>
<span data-ttu-id="89a3f-213">Esse mecanismo é útil para tarefas que exigem velocidade.</span><span class="sxs-lookup"><span data-stu-id="89a3f-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="89a3f-214">Quando um usuário se move por uma série de manobras de direcionamento/ativação com velocidade, pode ser útil supor uma intenção e permitir etapas ausentes para executar ações em alvos que o usuário tinha em foco um pouco antes ou depois do toque (50 ms antes/depois do que foi eficaz no início do teste).</span><span class="sxs-lookup"><span data-stu-id="89a3f-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="89a3f-215">Suavização</span><span class="sxs-lookup"><span data-stu-id="89a3f-215">Smoothing</span></span>
<span data-ttu-id="89a3f-216">Esse mecanismo é útil para movimentos de caminhos, reduzindo leve tremulação/tremor devido às características de movimentação natural da cabeça.</span><span class="sxs-lookup"><span data-stu-id="89a3f-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="89a3f-217">Durante a suavização em movimentos de caminhos, aplique a suavização por tamanho/distância de movimentos em vez de ao longo do tempo</span><span class="sxs-lookup"><span data-stu-id="89a3f-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="89a3f-218">Magnetismo</span><span class="sxs-lookup"><span data-stu-id="89a3f-218">Magnetism</span></span>
<span data-ttu-id="89a3f-219">Esse mecanismo pode ser considerado uma versão mais geral dos algoritmos de "Vínculo mais próximo" – desenhar um cursor em direção a um alvo ou apenas aumentar os hitboxes (seja visivelmente ou não) conforme os usuários se aproximam de prováveis alvos, usando algum conhecimento sobre o layout interativo para uma melhor abordagem da intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="89a3f-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="89a3f-220">Isso pode ser particularmente eficiente para alvos pequenos.</span><span class="sxs-lookup"><span data-stu-id="89a3f-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="89a3f-221">Adesão do foco</span><span class="sxs-lookup"><span data-stu-id="89a3f-221">Focus stickiness</span></span>
<span data-ttu-id="89a3f-222">Ao determinar a quais elementos interativos nas proximidades o foco deve ser dado, forneça um desvio para o elemento que tem o foco atualmente.</span><span class="sxs-lookup"><span data-stu-id="89a3f-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="89a3f-223">Isso ajudará a reduzir os comportamentos de alternância de foco instável durante a flutuação em um ponto médio entre dois elementos com ruído natural.</span><span class="sxs-lookup"><span data-stu-id="89a3f-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="89a3f-224">Gestos compostos</span><span class="sxs-lookup"><span data-stu-id="89a3f-224">Composite gestures</span></span>
<span data-ttu-id="89a3f-225">Os aplicativos podem reconhecer mais do que apenas toques individuais.</span><span class="sxs-lookup"><span data-stu-id="89a3f-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="89a3f-226">Pela combinação do toque, do gesto de manter e de soltar com o movimento da mão, gestos compostos mais complexos podem ser feitos.</span><span class="sxs-lookup"><span data-stu-id="89a3f-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="89a3f-227">Esses gestos compostos ou de alto nível baseiam-se nos dados de entrada espaciais de baixo nível (do fechar e abrir dedos indicador e polegar ao abrir a mão) aos quais os desenvolvedores têm acesso.</span><span class="sxs-lookup"><span data-stu-id="89a3f-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="89a3f-228">Fechar e abrir dedos indicador e polegar</span><span class="sxs-lookup"><span data-stu-id="89a3f-228">Air tap</span></span>
<span data-ttu-id="89a3f-229">O gesto de fechar e abrir dedos indicador e polegar (bem como os outros gestos abaixo) responde somente a um toque específico.</span><span class="sxs-lookup"><span data-stu-id="89a3f-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="89a3f-230">Para detectar outros toques, como menu ou segurar, o aplicativo precisa usar diretamente as interações de baixo nível descritas na seção de gestos de dois componentes principais acima.</span><span class="sxs-lookup"><span data-stu-id="89a3f-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="89a3f-231">Fechar e abrir dedos indicador e polegar e manter</span><span class="sxs-lookup"><span data-stu-id="89a3f-231">Tap and hold</span></span>
<span data-ttu-id="89a3f-232">Manter é simplesmente manter a posição do dedo para baixo no gesto de fechar e abrir dedos indicador e polegar.</span><span class="sxs-lookup"><span data-stu-id="89a3f-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="89a3f-233">A combinação dos gestos de fechar e abrir dedos indicador e polegar e manter permite uma variedade de interações mais complexas de "clicar e arrastar" quando usada em conjunto com a movimentação do braço, como pegar um objeto em vez de ativá-lo, ou interações secundárias "mousedown", como mostrar um menu de contexto.</span><span class="sxs-lookup"><span data-stu-id="89a3f-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="89a3f-234">No entanto, tenha cuidado ao projetar o uso desse gesto, pois os usuários podem estar propensos a relaxar suas posturas de mão no decorrer de qualquer gesto estendido.</span><span class="sxs-lookup"><span data-stu-id="89a3f-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="89a3f-235">Manipulação</span><span class="sxs-lookup"><span data-stu-id="89a3f-235">Manipulation</span></span>
<span data-ttu-id="89a3f-236">Os gestos de manipulação poderão ser usados para mover, redimensionar ou girar um holograma quando você desejar que o holograma responda com uma proporção 1:1 às movimentações de mão do usuário.</span><span class="sxs-lookup"><span data-stu-id="89a3f-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="89a3f-237">Um uso para essas movimentações de 1:1 é permitir que o usuário desenhe ou pinte no mundo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="89a3f-238">O direcionamento inicial de um gesto de manipulação deve ser feito pelo foco ou apontando.</span><span class="sxs-lookup"><span data-stu-id="89a3f-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="89a3f-239">Depois que o gesto de fechar e abrir dedos indicador e polegar e manter for iniciado, qualquer manipulação do objeto será tratada pelos movimentos da mão, liberando o usuário para olhar em volta durante a manipulação.</span><span class="sxs-lookup"><span data-stu-id="89a3f-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="89a3f-240">Navegação</span><span class="sxs-lookup"><span data-stu-id="89a3f-240">Navigation</span></span>
<span data-ttu-id="89a3f-241">Os gestos de navegação funcionam como um joystick virtual e podem ser usados para navegar por widgets de interface do usuário, como menus radiais.</span><span class="sxs-lookup"><span data-stu-id="89a3f-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="89a3f-242">Feche e abra os dedos indicador e polegar e mantenha para iniciar o gesto e, em seguida, mova a mão dentro de um cubo 3D normalizado, centralizado em torno do pressionamento inicial.</span><span class="sxs-lookup"><span data-stu-id="89a3f-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="89a3f-243">Você pode mover a mão ao longo do eixo X, Y ou Z de um valor -1 a 1, sendo 0 o ponto de partida.</span><span class="sxs-lookup"><span data-stu-id="89a3f-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="89a3f-244">A navegação pode ser usada para criar gestos de rolagem ou zoom contínuo baseados em velocidade, semelhante à rolagem de uma interface do usuário 2D com um clique no botão do meio do mouse e, em seguida, a movimentação do mouse para cima e para baixo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="89a3f-245">A navegação com trilhos refere-se à capacidade de reconhecer movimentos em determinado eixo até certo limite ser atingido nesse eixo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="89a3f-246">Isso só é útil quando o movimento em mais de um eixo é habilitado em um aplicativo pelo desenvolvedor, por exemplo, se um aplicativo é configurado para reconhecer gestos de navegação nos eixos X e Y, mas também no eixo X especificado com trilhos.</span><span class="sxs-lookup"><span data-stu-id="89a3f-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="89a3f-247">Nesse caso, o sistema reconhecerá os movimentos de mão no eixo X, desde que eles permaneçam dentro de um trilho imaginário (guia) no eixo, X caso o movimento de mão também ocorra no eixo Y.</span><span class="sxs-lookup"><span data-stu-id="89a3f-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="89a3f-248">Em aplicativos 2D, os usuários podem usar gestos de navegação vertical para rolagem, zoom ou operações de arrastar dentro do aplicativo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="89a3f-249">Isso injeta toques de dedo virtuais no aplicativo para simular gestos de toque do mesmo tipo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="89a3f-250">Os usuários podem selecionar quais dessas ações ocorrem alternando entre as ferramentas na barra acima do aplicativo, selecionando o botão ou falando 'Ferramenta de <Rolagem/Arrastar/Zoom>'.</span><span class="sxs-lookup"><span data-stu-id="89a3f-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="89a3f-251">Mais informações sobre gestos compostos</span><span class="sxs-lookup"><span data-stu-id="89a3f-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="89a3f-252">Reconhecedores de gestos</span><span class="sxs-lookup"><span data-stu-id="89a3f-252">Gesture recognizers</span></span>

<span data-ttu-id="89a3f-253">Uma vantagem do uso do reconhecimento de gestos é que você pode configurar um reconhecedor de gestos apenas para os gestos que o holograma direcionado atualmente pode aceitar.</span><span class="sxs-lookup"><span data-stu-id="89a3f-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="89a3f-254">A plataforma fará apenas a desambiguidade necessária para distinguir esses gestos compatíveis específicos.</span><span class="sxs-lookup"><span data-stu-id="89a3f-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="89a3f-255">Dessa forma, um holograma que só é compatível com o gesto de fechar e abrir dedos indicador e polegar pode aceitar qualquer período de tempo entre o pressionamento e a liberação, enquanto um holograma que é compatível com o gesto de fechar e abrir dedos indicador e polegar e manter pode promover o toque a um gesto de manter após o limite de tempo em que o toque é mantido.</span><span class="sxs-lookup"><span data-stu-id="89a3f-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="89a3f-256">Reconhecimento de mão</span><span class="sxs-lookup"><span data-stu-id="89a3f-256">Hand recognition</span></span>
<span data-ttu-id="89a3f-257">O HoloLens reconhece gestos de mão acompanhando a posição de uma ou das duas mãos visíveis para o dispositivo.</span><span class="sxs-lookup"><span data-stu-id="89a3f-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="89a3f-258">O HoloLens vê as mãos quando elas estão no estado pronto (parte posterior da mão voltada para você com o dedo indicador para cima) ou no estado pressionado (parte posterior da mão voltada para você com o dedo indicador para baixo).</span><span class="sxs-lookup"><span data-stu-id="89a3f-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="89a3f-259">Quando as mãos estiverem em outras poses, o HoloLens as ignorará.</span><span class="sxs-lookup"><span data-stu-id="89a3f-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="89a3f-260">Para cada mão detectada pelo HoloLens, você pode acessar sua posição (sem orientação) e seu estado pressionado.</span><span class="sxs-lookup"><span data-stu-id="89a3f-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="89a3f-261">Conforme a mão se aproxima da borda do quadro de gesto, você também recebe um vetor de direção, que você pode mostrar ao usuário para que ele saiba como mover a mão para retorná-la ao local em que o HoloLens possa vê-la.</span><span class="sxs-lookup"><span data-stu-id="89a3f-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="89a3f-262">Quadro de gesto</span><span class="sxs-lookup"><span data-stu-id="89a3f-262">Gesture frame</span></span>
<span data-ttu-id="89a3f-263">Para os gestos no HoloLens, a mão precisa estar em um “quadro de gesto”, em um alcance no qual as câmeras de detecção de gesto possam vê-la de forma adequada (muito aproximadamente, do nariz até a cintura e entre os ombros).</span><span class="sxs-lookup"><span data-stu-id="89a3f-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="89a3f-264">Os usuários precisam ser treinados nessa área de reconhecimento para o sucesso da ação e para seu próprio conforto (muitos usuários inicialmente presumirão que o quadro de gesto está dentro de sua visão por meio do HoloLens e manterão os braços levantados de forma desconfortável para interagir com ele).</span><span class="sxs-lookup"><span data-stu-id="89a3f-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="89a3f-265">Ao usar o HoloLens Clicker, suas mãos não precisam estar dentro do quadro de gesto.</span><span class="sxs-lookup"><span data-stu-id="89a3f-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="89a3f-266">No caso de gestos contínuos em particular, há algum risco de que os usuários movam as mãos para fora do quadro de gesto durante o gesto intermediário (ao mover um objeto holográfico, por exemplo) e percam seu resultado pretendido.</span><span class="sxs-lookup"><span data-stu-id="89a3f-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="89a3f-267">Há três coisas que você deve considerar:</span><span class="sxs-lookup"><span data-stu-id="89a3f-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="89a3f-268">Educação do usuário sobre a existência do quadro de gesto e os limites aproximados (isso é ensinado durante a instalação do HoloLens).</span><span class="sxs-lookup"><span data-stu-id="89a3f-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="89a3f-269">Notificação dos usuários quando seus gestos estiverem se aproximando ou saírem dos limites do quadro de gesto em um aplicativo, na medida em que um gesto perdido levará a resultados indesejados.</span><span class="sxs-lookup"><span data-stu-id="89a3f-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="89a3f-270">As pesquisas mostram as principais qualidades de um sistema de notificação como esse e o shell do HoloLens oferece um bom exemplo desse tipo de notificação (visual, no cursor central, indicando a direção na qual o limite está sendo ultrapassado).</span><span class="sxs-lookup"><span data-stu-id="89a3f-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="89a3f-271">As consequências de sair dos limites do quadro do gesto deverão ser minimizadas.</span><span class="sxs-lookup"><span data-stu-id="89a3f-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="89a3f-272">Em geral, isso significa que o resultado de um gesto deve ser interrompido no limite, mas não revertido.</span><span class="sxs-lookup"><span data-stu-id="89a3f-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="89a3f-273">Por exemplo, se um usuário estiver movendo algum objeto holográfico em uma sala, a movimentação deverá parar quando o quadro de gesto for ultrapassado, mas não retornar ao ponto de partida.</span><span class="sxs-lookup"><span data-stu-id="89a3f-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="89a3f-274">Assim, o usuário poderá se frustrar, mas poderá mais rapidamente entender os limites e não precisar reiniciar suas ações pretendidas completas sempre.</span><span class="sxs-lookup"><span data-stu-id="89a3f-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="89a3f-275">Consulte também</span><span class="sxs-lookup"><span data-stu-id="89a3f-275">See also</span></span>
* [<span data-ttu-id="89a3f-276">Manipulação direta com as mãos</span><span class="sxs-lookup"><span data-stu-id="89a3f-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="89a3f-277">Apontar e confirmar com as mãos</span><span class="sxs-lookup"><span data-stu-id="89a3f-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="89a3f-278">Interações instinctuais</span><span class="sxs-lookup"><span data-stu-id="89a3f-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="89a3f-279">Focar com a cabeça e esperar</span><span class="sxs-lookup"><span data-stu-id="89a3f-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="89a3f-280">Comando de voz</span><span class="sxs-lookup"><span data-stu-id="89a3f-280">Voice commanding</span></span>](voice-design.md)





