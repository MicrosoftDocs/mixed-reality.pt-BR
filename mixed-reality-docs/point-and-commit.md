---
title: Ponto e confirmar
description: Visão geral do modelo confirmação e de ponto de entrada
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
keywords: Misto realidade, interação, de design
ms.openlocfilehash: e0e9c97053734ac0125fce40be7ffe9afbd2dd68
ms.sourcegitcommit: f5c1dedb3b9e29f27f627025b9e7613931a7ce18
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 04/27/2019
ms.locfileid: "64581306"
---
# <a name="point-and-commit"></a><span data-ttu-id="5cfac-104">Ponto e confirmar</span><span class="sxs-lookup"><span data-stu-id="5cfac-104">Point and commit</span></span>
<span data-ttu-id="5cfac-105">Ponto e a confirmação é um modelo de entrada permite que os usuários de destino, selecione e manipular conteúdo 2D e 3D objetos em uma distância.</span><span class="sxs-lookup"><span data-stu-id="5cfac-105">Point and commit is an input model enables users to target, select and manipulate 2D contents and 3D objects in a distance.</span></span> <span data-ttu-id="5cfac-106">Essa técnica de interação do "Extremo" é uma experiência interativa de umbigo humano sendo não tinha realmente durante sua interação diária com o mundo real.</span><span class="sxs-lookup"><span data-stu-id="5cfac-106">This "Far" interaction technique is a navel interactive experience that human being didn't really have during their daily interaction with the real world.</span></span> <span data-ttu-id="5cfac-107">Por exemplo, um filme de super hero, Magneto é capaz de contatar e manipular um objeto distante via mãos em uma distância, mas humanos não é possível fazer isso em realidade.</span><span class="sxs-lookup"><span data-stu-id="5cfac-107">For example, in a super hero movie, Magneto is capable of reaching out and manipulating a far object via hands in a distance, but human can't do it in reality.</span></span> <span data-ttu-id="5cfac-108">No Microsoft HoloLens (AR) e realidade mista do Microsoft (VR), nós equipar os usuários esse poder mágica, quebrando a restrição física do mundo real não apenas para ter experiência e interessantes com conteúdo holográfica, mas para tornar a interação mais eficaz e eficiente.</span><span class="sxs-lookup"><span data-stu-id="5cfac-108">In both Microsoft HoloLens (AR) and Microsoft Mixed Reality (VR), we equip users this magical power, breaking the physical constraint of real world not only to have delightful experience with holographic contents but to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="5cfac-109">Suporte a dispositivos</span><span class="sxs-lookup"><span data-stu-id="5cfac-109">Device support</span></span>
<table>
    <colgroup>
    <col width="40%" />
    <col width="20%" />
    <col width="20%" />
    <col width="20%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="5cfac-110"><strong>Modelo de entrada</strong></span><span class="sxs-lookup"><span data-stu-id="5cfac-110"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="5cfac-111"><a href="hololens-hardware-details.md"><strong>HoloLens (1ª geração)</strong></a></span><span class="sxs-lookup"><span data-stu-id="5cfac-111"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="5cfac-112"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="5cfac-112"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="5cfac-113"><a href="immersive-headset-hardware-details.md"><strong>Fones imersivos em exposição</strong></a></span><span class="sxs-lookup"><span data-stu-id="5cfac-113"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="5cfac-114">Ponto e confirmação (interação mão distante)</span><span class="sxs-lookup"><span data-stu-id="5cfac-114">Point and commit (far hand interaction)</span></span></td>
        <td><span data-ttu-id="5cfac-115">❌ Não tem suportada</span><span class="sxs-lookup"><span data-stu-id="5cfac-115">❌ Not supported</span></span></td>
        <td><span data-ttu-id="5cfac-116">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="5cfac-116">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="5cfac-117">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="5cfac-117">✔️ Recommended</span></span></td>
    </tr>
</table>
<br>
<span data-ttu-id="5cfac-118">Ponto e confirmação tem sido um dos modelos de entrada primários em 2 HoloLens, utilizando a mão articulada novo sistema de controle.</span><span class="sxs-lookup"><span data-stu-id="5cfac-118">Point and commit has been one of the primary input models on HoloLens 2, utilizing the new articulated hand tracking system.</span></span> <span data-ttu-id="5cfac-119">Esse modelo de entrada também é o modelo de entrada primário em fones imersivos em exposição com o uso de controladores de movimento.</span><span class="sxs-lookup"><span data-stu-id="5cfac-119">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span> <span data-ttu-id="5cfac-120">Ponto e a confirmação é o modelo de entrada que sugerimos para substituir o cabeçalho olhares e confirmada no HoloLens (1º gen).</span><span class="sxs-lookup"><span data-stu-id="5cfac-120">Point and Commit is the input model that we suggest to replace the Head Gaze and Commit on HoloLens (1st gen).</span></span> 

## <a name="hand-rays"></a><span data-ttu-id="5cfac-121">Raios de mão</span><span class="sxs-lookup"><span data-stu-id="5cfac-121">Hand rays</span></span>
<span data-ttu-id="5cfac-122">Em 2 HoloLens, criamos um raio de mão de solução do Centro de um palm.</span><span class="sxs-lookup"><span data-stu-id="5cfac-122">On HoloLens 2, we create a hand ray shooting out from the center of a palm.</span></span> <span data-ttu-id="5cfac-123">O raio é tratado como uma extensão da mão.</span><span class="sxs-lookup"><span data-stu-id="5cfac-123">The ray is treated as an extension of the hand.</span></span> <span data-ttu-id="5cfac-124">Um cursor de forma de rosca é anexado ao final do raio implica, o local onde o raio cruza com um objeto hitted.</span><span class="sxs-lookup"><span data-stu-id="5cfac-124">A donut shape cursor is attached at the end of the ray to imply the location where the ray intersects with a hitted object.</span></span> <span data-ttu-id="5cfac-125">O objeto que o cursor chega receberá gestual comandos da mão.</span><span class="sxs-lookup"><span data-stu-id="5cfac-125">The object that the cursor lands will receive gestural commands from the hand.</span></span> 

<span data-ttu-id="5cfac-126">O comando gestual muito básico é acionado usando o polegar e o dedo para executar o gesto de ar.</span><span class="sxs-lookup"><span data-stu-id="5cfac-126">The very basic gestural command is triggered by using thumb and index finger to perform air tap gesture.</span></span> <span data-ttu-id="5cfac-127">Usando ray mão para apontar e polegar para confirmar, os usuários podem ativar um botão ou um hiperlink em um conteúdo da web.</span><span class="sxs-lookup"><span data-stu-id="5cfac-127">By using hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="5cfac-128">Com os gestos de composição mais, os usuários são capazes de navegar o conteúdo da web e manipular objetos 3D em uma distância.</span><span class="sxs-lookup"><span data-stu-id="5cfac-128">With more composite gestures, users are capable of navigating the web content and manipulating 3D objects in a distance.</span></span> <span data-ttu-id="5cfac-129">O design visual do raio mão também deve reagir para apontar e estados de confirmação:</span><span class="sxs-lookup"><span data-stu-id="5cfac-129">The visual design of the hand ray should also react to point and commit states:</span></span> <br>
* <span data-ttu-id="5cfac-130">No estado apontador, o raio é dash com linhas e o cursor é uma forma de rosca.</span><span class="sxs-lookup"><span data-stu-id="5cfac-130">In the pointing state, the ray is dash lined, and the cursor is a donut shape.</span></span>
* <span data-ttu-id="5cfac-131">no estado de confirmação, o raio se transforma em uma linha sólida e o cursor é reduzido para um ponto.</span><span class="sxs-lookup"><span data-stu-id="5cfac-131">in the committing state, the ray turns into a solid line, and the cursor shrinks to a dot.</span></span><br><br>
![](images/Hand-Rays-720px.jpg)<br>

## <a name="transition-between-near-and-far"></a><span data-ttu-id="5cfac-132">Faça a transição entre próximo e distante</span><span class="sxs-lookup"><span data-stu-id="5cfac-132">Transition between near and far</span></span>
<span data-ttu-id="5cfac-133">Em vez de usar gestos específicos, como apontá-lo com o dedo para direcionar o raio, criamos o raio saindo do centro do palm, liberando e reservar os cinco dedos para manipulações gestual mais.</span><span class="sxs-lookup"><span data-stu-id="5cfac-133">Instead of using specific gestures, such as pointing with index finger to direct the ray, we design the ray coming out from the center of the palm, releasing and reserving the five fingers for more gestural manipulations.</span></span> <span data-ttu-id="5cfac-134">Portanto, o HoloLens 2 oferece suporte a exatamente o mesmo conjunto de gestos de mão para interação próxima e distante.</span><span class="sxs-lookup"><span data-stu-id="5cfac-134">Therefore, HoloLens 2 supports exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="5cfac-135">Adicionais de aprendizado é necessária quando os usuários de trânsito de perto de interações mais distantes e vice-versa.</span><span class="sxs-lookup"><span data-stu-id="5cfac-135">No additional learning is needed when users transit from near to far interactions, and vice versa.</span></span> <span data-ttu-id="5cfac-136">Os usuários podem usar o mesmo gesto de captura para manipular objetos em distâncias diferentes.</span><span class="sxs-lookup"><span data-stu-id="5cfac-136">Users can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="5cfac-137">A invocação dos raios é automático e a proximidade com base em:</span><span class="sxs-lookup"><span data-stu-id="5cfac-137">The invocation of the rays is automatic and proximity based:</span></span> <br>
* <span data-ttu-id="5cfac-138">Quando um objeto está dentro do arm atingido distância (aproximadamente 50 cm), os raios são desativados automaticamente incentivando para interação com o próxima.</span><span class="sxs-lookup"><span data-stu-id="5cfac-138">when an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span> 
* <span data-ttu-id="5cfac-139">Quando o objeto está mais distante 50 cm, raios são ativados.</span><span class="sxs-lookup"><span data-stu-id="5cfac-139">When the object is farther than 50 cm, the rays are turned on.</span></span>

<span data-ttu-id="5cfac-140">Esse mecanismo faz a transição suave e sem problemas.</span><span class="sxs-lookup"><span data-stu-id="5cfac-140">This mechanism makes the transition smooth and seamless.</span></span><br>
![](images/Transition-Between-Near-And-Far-720px.jpg)<br>

## <a name="2d-slate-interaction"></a><span data-ttu-id="5cfac-141">Interação slate 2D</span><span class="sxs-lookup"><span data-stu-id="5cfac-141">2D slate interaction</span></span>
<span data-ttu-id="5cfac-142">Um slate 2D é um contêiner de holográfico hospedando conteúdo do aplicativo 2D, como o navegador da web.</span><span class="sxs-lookup"><span data-stu-id="5cfac-142">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="5cfac-143">O conceito de design para o momento interagir com um slate 2D é usar raios de mão para apontar e polegar para confirmar.</span><span class="sxs-lookup"><span data-stu-id="5cfac-143">The design concept for far interacting with a 2D slate is to use hand rays to point and air tap to commit.</span></span><br>

<span data-ttu-id="5cfac-144">Para interagir com da constante slate:</span><span class="sxs-lookup"><span data-stu-id="5cfac-144">For interacting with the slate contant:</span></span><br>

* <span data-ttu-id="5cfac-145">Os usuários podem apontar para um hiperlink ou um botão, em seguida, indicador e polegar para ativá-lo.</span><span class="sxs-lookup"><span data-stu-id="5cfac-145">Users can point at a hyperlink or a button, then air tap to activate it.</span></span> 
* <span data-ttu-id="5cfac-146">Os usuários podem usar uma mão para executar um gesto de navegação para rolar um slate conteúdo para cima para baixo.</span><span class="sxs-lookup"><span data-stu-id="5cfac-146">Users can use one hand to perform a navigation gesture to scroll a slate content up and down.</span></span> 
* <span data-ttu-id="5cfac-147">Os usuários podem usar duas mãos executar gestos de navegação para aumentar o zoom e o conteúdo de imagem fixa.</span><span class="sxs-lookup"><span data-stu-id="5cfac-147">Users can use two hands to perform navigation gestures to zoom in and out the slate content.</span></span><br><br>

![](images/2D-Slate-Interaction-Far-720px.jpg)<br>

<span data-ttu-id="5cfac-148">Para a manipulação de 2D de imagem fixa em si:</span><span class="sxs-lookup"><span data-stu-id="5cfac-148">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="5cfac-149">Os usuários apontam o raio de mão nos cantos ou bordas para revelar a funcionalidade de manipulação mais próximo.</span><span class="sxs-lookup"><span data-stu-id="5cfac-149">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="5cfac-150">Aplicando um gesto de manipulação de funcionalidade, os usuários podem executar a escala uniforme por meio da funcionalidade de canto e podem refluir o slate via a funcionalidade de borda.</span><span class="sxs-lookup"><span data-stu-id="5cfac-150">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="5cfac-151">Aplicando um gesto de manipulação de holobar na parte superior do slate 2D, os usuários podem mover o slate inteiro.</span><span class="sxs-lookup"><span data-stu-id="5cfac-151">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="5cfac-152">Manipulação de objetos 3D</span><span class="sxs-lookup"><span data-stu-id="5cfac-152">3D object manipulation</span></span>
<span data-ttu-id="5cfac-153">Na manipulação direta, há duas maneiras para os usuários manipular o objeto 3D, manipulação de com base em funcionalidade e não affordnace com base em manipulação.</span><span class="sxs-lookup"><span data-stu-id="5cfac-153">In direct manipulation, there are two ways for users to manipulate 3D object, Affordance Based Manipulation and Non-affordnace Based Manipulation.</span></span> <span data-ttu-id="5cfac-154">No modelo de ponto e a confirmação, os usuários são capazes de alcançar o exatamente as mesmas tarefas por meio de raios de mão.</span><span class="sxs-lookup"><span data-stu-id="5cfac-154">In point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="5cfac-155">Nenhum aprendizado adicional é necessária.</span><span class="sxs-lookup"><span data-stu-id="5cfac-155">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="5cfac-156">Manipulação de funcionalidade com base em</span><span class="sxs-lookup"><span data-stu-id="5cfac-156">Affordance based manipulation</span></span>
<span data-ttu-id="5cfac-157">Os usuários usar raios de mão para apontar e revelar a caixa delimitadora e capacidades de manipulação.</span><span class="sxs-lookup"><span data-stu-id="5cfac-157">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="5cfac-158">Os usuários podem aplicar o gesto de manipulação na caixa delimitadora para mover o objeto inteiro, nas capacidades de borda para girar e em coner de capacidades para dimensionar de maneira uniforme.</span><span class="sxs-lookup"><span data-stu-id="5cfac-158">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="5cfac-159">Funcionalidade não com base em manipulação</span><span class="sxs-lookup"><span data-stu-id="5cfac-159">Non-affordance based manipulation</span></span>
<span data-ttu-id="5cfac-160">Ponto de usuários com raios de mão para revelar a caixa delimitadora e em seguida, aplicar diretamente a gestos de manipulação nele.</span><span class="sxs-lookup"><span data-stu-id="5cfac-160">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="5cfac-161">Com um lado, a translação e rotação do objeto são associados ao movimento e a orientação da mão.</span><span class="sxs-lookup"><span data-stu-id="5cfac-161">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="5cfac-162">Com duas mãos, os usuários podem traduzir, dimensionar e girá-lo de acordo com os movimentos relativos de duas mãos.</span><span class="sxs-lookup"><span data-stu-id="5cfac-162">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="5cfac-163">Gesturers instinctual</span><span class="sxs-lookup"><span data-stu-id="5cfac-163">Instinctual gesturers</span></span>
<span data-ttu-id="5cfac-164">O conceito de gestos instinctual para ponto e confirmação está em sincronizado com isso para manipulação direta.</span><span class="sxs-lookup"><span data-stu-id="5cfac-164">The concept of instinctual gestures for point and commit is in sync with that for direct manipulation.</span></span> <span data-ttu-id="5cfac-165">Quais gestos os usuários suponha que para executar em um objeto 3D são orientados pelo design de capacidades de interface do usuário.</span><span class="sxs-lookup"><span data-stu-id="5cfac-165">What gestures users suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="5cfac-166">Um ponto de controle pequeno seria motivar os usuários aperto com o polegar e o dedo, enquanto um objeto grande faz com que os usuários para captar com dedo 5.</span><span class="sxs-lookup"><span data-stu-id="5cfac-166">A small control point would motivate users to pinch with thumb and index finger, while a large object makes users to grab with 5 finger.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="5cfac-167">Design simétrica entre mãos e controlador de DoF 6</span><span class="sxs-lookup"><span data-stu-id="5cfac-167">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="5cfac-168">O conceito de modelo de ponto e confirmação para interação mais distante em primeiro lugar é criado e definido para misto realidade Portal (MRP), onde os usuários wear um fone de ouvido envolvente e interagem com o objeto 3d por meio de controladores de movimento.</span><span class="sxs-lookup"><span data-stu-id="5cfac-168">The concept of point and commit model for far interaction is firstly created and defined for the Mixed Reality Portal (MRP), where users wear an immersive headset and interact with the 3d object via motion controllers.</span></span> <span data-ttu-id="5cfac-169">Os controladores de movimento envie out raios para apontando e manipular objetos distantes.</span><span class="sxs-lookup"><span data-stu-id="5cfac-169">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="5cfac-170">Existem botões nos controladores para confirmar ainda mais funcionalidades diferentes.</span><span class="sxs-lookup"><span data-stu-id="5cfac-170">There are buttons on the controllers for further committing different functionalities.</span></span> <span data-ttu-id="5cfac-171">Podemos aproveitar o modelo de interação de raios e anexá-los em ambas as mãos.</span><span class="sxs-lookup"><span data-stu-id="5cfac-171">We leverage the interaction model of rays and attach them on both hands.</span></span> <span data-ttu-id="5cfac-172">Com esse design simétrica, os usuários que estão familiarizados com MRP não precisarão aprender outro modelo de interação para o momento apontando e manipulação durante a primeira vez usando HoloLen 2 e vice-versa.</span><span class="sxs-lookup"><span data-stu-id="5cfac-172">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation while first time using HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>


## <a name="see-also"></a><span data-ttu-id="5cfac-173">Consulte também</span><span class="sxs-lookup"><span data-stu-id="5cfac-173">See also</span></span>
* [<span data-ttu-id="5cfac-174">Olhar e confirmar</span><span class="sxs-lookup"><span data-stu-id="5cfac-174">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="5cfac-175">Manipulação direta</span><span class="sxs-lookup"><span data-stu-id="5cfac-175">Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="5cfac-176">Conceitos básicos de interação</span><span class="sxs-lookup"><span data-stu-id="5cfac-176">Interaction fundamentals</span></span>](interaction-fundamentals.md)
