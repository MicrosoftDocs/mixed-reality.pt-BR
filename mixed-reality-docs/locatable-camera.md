---
title: Câmera localizáveis
description: Informações gerais sobre a câmera frontal HoloLens, como ele funciona e os perfis e as resoluções disponíveis para desenvolvedores.
author: cdedmonds
ms.author: wguyman, cdedmonds
ms.date: 06/12/2019
ms.topic: article
keywords: voltado para o front-câmera, hololens, câmera de cor
ms.openlocfilehash: f661fc82fbeab9a870e8ccf7044c9bb375bed7e3
ms.sourcegitcommit: 30246ab9b9be44a3c707061753e53d4bf401eb6b
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 06/22/2019
ms.locfileid: "67326286"
---
# <a name="locatable-camera"></a><span data-ttu-id="eb35f-104">Câmera localizáveis</span><span class="sxs-lookup"><span data-stu-id="eb35f-104">Locatable camera</span></span>

<span data-ttu-id="eb35f-105">HoloLens incluem uma câmera voltados para o mundo montada na parte frontal do dispositivo que permite que os aplicativos ver o que o usuário vê.</span><span class="sxs-lookup"><span data-stu-id="eb35f-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="eb35f-106">Os desenvolvedores têm acesso e controle da câmera, assim como fariam para câmeras de cor em smartphones, computadores portáteis ou áreas de trabalho.</span><span class="sxs-lookup"><span data-stu-id="eb35f-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="eb35f-107">O mesmo windows universal [captura de mídia](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) e funcionam de APIs que funcionam em dispositivos móveis e área de trabalho de base de mídia do windows em HoloLens.</span><span class="sxs-lookup"><span data-stu-id="eb35f-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="eb35f-108">Unity [também foi quebrada essa APIs do windows](locatable-camera-in-unity.md) abstrair o simple uso da câmera em HoloLens para tarefas como levando regulares fotos e vídeos (com ou sem hologramas) e localizar a posição da câmera no e perspectiva sobre o cena.</span><span class="sxs-lookup"><span data-stu-id="eb35f-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="eb35f-109">Informações de câmera do dispositivo</span><span class="sxs-lookup"><span data-stu-id="eb35f-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="eb35f-110">HoloLens (first-generation)</span><span class="sxs-lookup"><span data-stu-id="eb35f-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="eb35f-111">Câmera de foto/vídeo (PV) foco fixa, com o balanço automático branca, exposição automática e pipe de processamento de imagem completa</span><span class="sxs-lookup"><span data-stu-id="eb35f-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="eb35f-112">LED de privacidade em branco voltados para o mundo acenderá sempre que a câmera está ativa</span><span class="sxs-lookup"><span data-stu-id="eb35f-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="eb35f-113">A câmera suporta os seguintes modos (todos os modos são a taxa de proporção de 16:9) em 5 de fps, 24, 20, 15 e 30:</span><span class="sxs-lookup"><span data-stu-id="eb35f-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="eb35f-114">Vídeo</span><span class="sxs-lookup"><span data-stu-id="eb35f-114">Video</span></span>  |  <span data-ttu-id="eb35f-115">Visualizar</span><span class="sxs-lookup"><span data-stu-id="eb35f-115">Preview</span></span>  |  <span data-ttu-id="eb35f-116">Ainda</span><span class="sxs-lookup"><span data-stu-id="eb35f-116">Still</span></span>  |  <span data-ttu-id="eb35f-117">Campo de exibição horizontal (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="eb35f-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="eb35f-118">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="eb35f-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="eb35f-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="eb35f-119">1280x720</span></span> |  <span data-ttu-id="eb35f-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="eb35f-120">1280x720</span></span> |  <span data-ttu-id="eb35f-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="eb35f-121">1280x720</span></span> |  <span data-ttu-id="eb35f-122">45deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-122">45deg</span></span>  |  <span data-ttu-id="eb35f-123">(modo de padrão com estabilização do vídeo)</span><span class="sxs-lookup"><span data-stu-id="eb35f-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="eb35f-124">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-124">N/A</span></span> |  <span data-ttu-id="eb35f-125">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-125">N/A</span></span> |  <span data-ttu-id="eb35f-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="eb35f-126">2048x1152</span></span> |  <span data-ttu-id="eb35f-127">67deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-127">67deg</span></span> |  <span data-ttu-id="eb35f-128">Imagem estática de resolução mais alta</span><span class="sxs-lookup"><span data-stu-id="eb35f-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="eb35f-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="eb35f-129">1408x792</span></span> |  <span data-ttu-id="eb35f-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="eb35f-130">1408x792</span></span> |  <span data-ttu-id="eb35f-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="eb35f-131">1408x792</span></span> |  <span data-ttu-id="eb35f-132">48deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-132">48deg</span></span> |  <span data-ttu-id="eb35f-133">Excedem resolução (preenchimento) antes de estabilização do vídeo</span><span class="sxs-lookup"><span data-stu-id="eb35f-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="eb35f-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="eb35f-134">1344x756</span></span> |  <span data-ttu-id="eb35f-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="eb35f-135">1344x756</span></span> |  <span data-ttu-id="eb35f-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="eb35f-136">1344x756</span></span> |  <span data-ttu-id="eb35f-137">67deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-137">67deg</span></span> |  <span data-ttu-id="eb35f-138">Modo de vídeo de FOV grande com overscan</span><span class="sxs-lookup"><span data-stu-id="eb35f-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="eb35f-139">896x504</span><span class="sxs-lookup"><span data-stu-id="eb35f-139">896x504</span></span> |  <span data-ttu-id="eb35f-140">896x504</span><span class="sxs-lookup"><span data-stu-id="eb35f-140">896x504</span></span> |  <span data-ttu-id="eb35f-141">896x504</span><span class="sxs-lookup"><span data-stu-id="eb35f-141">896x504</span></span> |  <span data-ttu-id="eb35f-142">48deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-142">48deg</span></span> |  <span data-ttu-id="eb35f-143">Baixa energia / tarefas de processamento de modo de baixa resolução de imagem</span><span class="sxs-lookup"><span data-stu-id="eb35f-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="eb35f-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="eb35f-144">HoloLens 2</span></span>

* <span data-ttu-id="eb35f-145">Câmera de foto/vídeo (PV) foco automático, com o balanço automático branca, exposição automática e pipe de processamento de imagem completa</span><span class="sxs-lookup"><span data-stu-id="eb35f-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="eb35f-146">LED de privacidade em branco voltados para o mundo acenderá sempre que a câmera está ativa</span><span class="sxs-lookup"><span data-stu-id="eb35f-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="eb35f-147">A câmera dá suporte a modos a seguir (todos os modos de vídeos são a taxa de proporção de 16:9):</span><span class="sxs-lookup"><span data-stu-id="eb35f-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="eb35f-148">Esses modos estão sujeitos a alterações antes da disponibilidade geral do HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="eb35f-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="eb35f-149">Vídeo</span><span class="sxs-lookup"><span data-stu-id="eb35f-149">Video</span></span>  |  <span data-ttu-id="eb35f-150">Visualizar</span><span class="sxs-lookup"><span data-stu-id="eb35f-150">Preview</span></span>  |  <span data-ttu-id="eb35f-151">Ainda</span><span class="sxs-lookup"><span data-stu-id="eb35f-151">Still</span></span>  |  <span data-ttu-id="eb35f-152">Taxas de quadros</span><span class="sxs-lookup"><span data-stu-id="eb35f-152">Frame rates</span></span>  |  <span data-ttu-id="eb35f-153">Campo de exibição horizontal (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="eb35f-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="eb35f-154">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="eb35f-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="eb35f-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="eb35f-155">1920x1080</span></span> |  <span data-ttu-id="eb35f-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="eb35f-156">1920x1080</span></span> |  <span data-ttu-id="eb35f-157">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-157">N/A</span></span> |  <span data-ttu-id="eb35f-158">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="eb35f-158">30, 15 fps</span></span>  |  <span data-ttu-id="eb35f-159">54deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-159">54deg</span></span>  |  <span data-ttu-id="eb35f-160">(modo de padrão com estabilização do vídeo)</span><span class="sxs-lookup"><span data-stu-id="eb35f-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="eb35f-161">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-161">N/A</span></span> |  <span data-ttu-id="eb35f-162">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-162">N/A</span></span> |  <span data-ttu-id="eb35f-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="eb35f-163">3904X2196</span></span> |  <span data-ttu-id="eb35f-164">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-164">N/A</span></span>  |  <span data-ttu-id="eb35f-165">64deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-165">64deg</span></span> |  <span data-ttu-id="eb35f-166">Imagem estática de resolução mais alta</span><span class="sxs-lookup"><span data-stu-id="eb35f-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="eb35f-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="eb35f-167">2272x1278</span></span> |  <span data-ttu-id="eb35f-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="eb35f-168">2272x1278</span></span> |  <span data-ttu-id="eb35f-169">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-169">N/A</span></span> |  <span data-ttu-id="eb35f-170">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="eb35f-170">30, 15 fps</span></span>  |  <span data-ttu-id="eb35f-171">64deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-171">64deg</span></span> |  <span data-ttu-id="eb35f-172">Excedem resolução (preenchimento) antes de estabilização do vídeo</span><span class="sxs-lookup"><span data-stu-id="eb35f-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="eb35f-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb35f-173">1952x1100</span></span> |  <span data-ttu-id="eb35f-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb35f-174">1952x1100</span></span> |  <span data-ttu-id="eb35f-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb35f-175">1952x1100</span></span>  |  <span data-ttu-id="eb35f-176">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="eb35f-176">30, 15 fps</span></span>  |  <span data-ttu-id="eb35f-177">64deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-177">64deg</span></span> |  <span data-ttu-id="eb35f-178">Fluxo de alta qualidade</span><span class="sxs-lookup"><span data-stu-id="eb35f-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="eb35f-179">1280x720</span><span class="sxs-lookup"><span data-stu-id="eb35f-179">1280x720</span></span> |  <span data-ttu-id="eb35f-180">1280x720</span><span class="sxs-lookup"><span data-stu-id="eb35f-180">1280x720</span></span> |  <span data-ttu-id="eb35f-181">N/D</span><span class="sxs-lookup"><span data-stu-id="eb35f-181">N/A</span></span> |  <span data-ttu-id="eb35f-182">30, 15, 5 fps</span><span class="sxs-lookup"><span data-stu-id="eb35f-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="eb35f-183">64deg</span><span class="sxs-lookup"><span data-stu-id="eb35f-183">64deg</span></span> |  <span data-ttu-id="eb35f-184">Modo de baixa energia/resolução para streaming e tarefas de processamento de imagens</span><span class="sxs-lookup"><span data-stu-id="eb35f-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="eb35f-185">Localizando a câmera do dispositivo no mundo</span><span class="sxs-lookup"><span data-stu-id="eb35f-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="eb35f-186">Quando houver HoloLens fotos e vídeos, os quadros capturados incluem o local da câmera no mundo, bem como o modelo de lentes da câmera.</span><span class="sxs-lookup"><span data-stu-id="eb35f-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="eb35f-187">Isso permite que aplicativos raciocinar sobre a posição da câmera no mundo real para cenários de geração de imagens aumentados.</span><span class="sxs-lookup"><span data-stu-id="eb35f-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="eb35f-188">Os desenvolvedores poderão ser revertidas criativamente seus próprios cenários usando seu processamento de imagens favorito ou bibliotecas de visão personalizada do computador.</span><span class="sxs-lookup"><span data-stu-id="eb35f-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="eb35f-189">"Câmera" em outro lugar na documentação do HoloLens pode se referir a "jogo câmera virtual" (o aplicativo frustum renderiza o).</span><span class="sxs-lookup"><span data-stu-id="eb35f-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="eb35f-190">A menos que indicado o contrário, "câmera" nesta página refere-se a câmera de cor RGB do mundo real.</span><span class="sxs-lookup"><span data-stu-id="eb35f-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="eb35f-191">Os detalhes sobre essa cobertura da página usando o [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference) classe, no entanto, há também as APIs para intrínsecos de câmera de pull e locais usando [Media Foundation atributos](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx).</span><span class="sxs-lookup"><span data-stu-id="eb35f-191">The details on this page cover using the [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference) class, however there are also APIs to pull camera intrinsics and locations using [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx).</span></span> <span data-ttu-id="eb35f-192">Consulte a [holográfica face acompanhamento exemplo](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) para obter mais informações.</span><span class="sxs-lookup"><span data-stu-id="eb35f-192">Please refer to the [Holographic face tracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) for more information.</span></span>

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="eb35f-193">Imagens com sistemas de coordenadas</span><span class="sxs-lookup"><span data-stu-id="eb35f-193">Images with Coordinate Systems</span></span>

<span data-ttu-id="eb35f-194">Cada quadro da imagem (se foto ou vídeo) inclui um [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) enraizada na câmera no momento da captura que pode ser acessado usando o [CoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) propriedade de seu [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span><span class="sxs-lookup"><span data-stu-id="eb35f-194">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture which can be accessed using the [CoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="eb35f-195">Além disso, cada quadro contém uma descrição do modelo de Lente de câmera que pode ser encontrada na [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) propriedade.</span><span class="sxs-lookup"><span data-stu-id="eb35f-195">In addition, each frame contains a description of the camera lens model which can be found in the [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="eb35f-196">Juntas, essas transformações definem para cada pixel um raio no espaço 3D, que representa o caminho tomada pelos photons que produziu o pixel.</span><span class="sxs-lookup"><span data-stu-id="eb35f-196">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="eb35f-197">Esses raios podem estar relacionados a outro conteúdo no aplicativo Obtendo a transformação do sistema de coordenadas do quadro para algum outro sistema de coordenadas (por exemplo, de um [quadro estacionário de referência](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="eb35f-197">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="eb35f-198">Para resumir, cada quadro da imagem fornece o seguinte:</span><span class="sxs-lookup"><span data-stu-id="eb35f-198">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="eb35f-199">Dados de pixel (no formato RGB/NV12/JPEG/etc.)</span><span class="sxs-lookup"><span data-stu-id="eb35f-199">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="eb35f-200">Um [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) do local de captura</span><span class="sxs-lookup"><span data-stu-id="eb35f-200">A [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="eb35f-201">Um [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) classe que contém o modo de lentes da câmera</span><span class="sxs-lookup"><span data-stu-id="eb35f-201">A [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="eb35f-202">Câmera para o sistema de coordenadas especificado pelo aplicativo</span><span class="sxs-lookup"><span data-stu-id="eb35f-202">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="eb35f-203">Para ir do 'CameraIntrinsics' e 'CameraCoordinateSystem' para o seu sistema de coordenadas de mundo/aplicativo, você precisará do seguinte:</span><span class="sxs-lookup"><span data-stu-id="eb35f-203">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="eb35f-204">[Localizáveis câmera no Unity](locatable-camera-in-unity.md): CameraToWorldMatrix é fornecida automaticamente pela classe PhotoCaptureFrame (de modo que você não precisa se preocupar sobre as transformações CameraCoordinateSystem).</span><span class="sxs-lookup"><span data-stu-id="eb35f-204">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="eb35f-205">[Câmera localizáveis no DirectX](locatable-camera-in-directx.md): Mostra a maneira bastante simples de consulta para a transformação entre o sistema de coordenadas da câmera e coordinate system(s) seu próprio aplicativo.</span><span class="sxs-lookup"><span data-stu-id="eb35f-205">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="distortion-error"></a><span data-ttu-id="eb35f-206">Erro de distorção</span><span class="sxs-lookup"><span data-stu-id="eb35f-206">Distortion Error</span></span>

<span data-ttu-id="eb35f-207">Em HoloLens, o vídeo e os fluxos de imagem ainda estão sem distorção no pipeline de processamento de imagem do sistema antes dos quadros são disponibilizados para o aplicativo (o fluxo de visualização contém os quadros distorcidos originais).</span><span class="sxs-lookup"><span data-stu-id="eb35f-207">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="eb35f-208">Porque somente os CameraIntrinsics são disponibilizados, aplicativos devem assumir que representam de quadros de imagem uma câmera pinhole perfeito, no entanto o undistortion funcionar no processador de imagem pode ainda deixar um erro de até 10 pixels em HoloLens (primeira geração) ao usar o CameraIntrinsics nos metadados do quadro.</span><span class="sxs-lookup"><span data-stu-id="eb35f-208">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels on HoloLens (first-generation) when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="eb35f-209">Em muitos casos de uso, esse erro não será relevante, mas se alinhando hologramas para cartazes/marcadores do mundo real, por exemplo, e você notar um < 10px deslocamento (aproximadamente 11mm para hologramas posicionado 2 metros de distância) essa distorção erro poderia ser a causa.</span><span class="sxs-lookup"><span data-stu-id="eb35f-209">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="eb35f-210">Cenários de uso de câmera localizáveis</span><span class="sxs-lookup"><span data-stu-id="eb35f-210">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="eb35f-211">Mostrar uma foto ou vídeo no mundo em que ele foi capturado</span><span class="sxs-lookup"><span data-stu-id="eb35f-211">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="eb35f-212">Os quadros de câmera do dispositivo vem com uma transformação "Câmera para World", que pode ser usada para mostrar onde o dispositivo foi exatamente quando a imagem foi capturada.</span><span class="sxs-lookup"><span data-stu-id="eb35f-212">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="eb35f-213">Por exemplo, você pode posicionar um pequeno ícone holográfico neste local (CameraToWorld.MultiplyPoint(Vector3.zero)) e draw até mesmo uma pequena seta na direção que a câmera enfrentava (CameraToWorld.MultiplyVector(Vector3.forward)).</span><span class="sxs-lookup"><span data-stu-id="eb35f-213">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="eb35f-214">Marca / padrão / pôster / acompanhamento de objeto</span><span class="sxs-lookup"><span data-stu-id="eb35f-214">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="eb35f-215">Muitos aplicativos de realidade misturada usam uma imagem reconhecível ou padrão visual para criar um ponto controláveis no espaço.</span><span class="sxs-lookup"><span data-stu-id="eb35f-215">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="eb35f-216">Em seguida, isso é usado para processar objetos em relação ao que apontam ou criar um local conhecido.</span><span class="sxs-lookup"><span data-stu-id="eb35f-216">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="eb35f-217">Alguns usos para o HoloLens incluem Localizando um objeto do mundo real marcado com fiducials (por exemplo, um monitor de TV com um código QR), colocando hologramas sobre fiducials e visualmente emparelhamento com dispositivos não HoloLens, como tablets que foram configurados para se comunicar com o HoloLens por meio de Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="eb35f-217">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="eb35f-218">Para reconhecer um padrão visual e, em seguida, colocar esse objeto no espaço de mundo de aplicativos, você precisará de algumas coisas:</span><span class="sxs-lookup"><span data-stu-id="eb35f-218">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="eb35f-219">Uma imagem padrão reconhecimento Kit de ferramentas, como o código QR, marcas de AR, o localizador de face, rastreadores de círculo, OCR etc.</span><span class="sxs-lookup"><span data-stu-id="eb35f-219">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="eb35f-220">Colete os quadros de imagem em tempo de execução e passá-los para a camada de reconhecimento</span><span class="sxs-lookup"><span data-stu-id="eb35f-220">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="eb35f-221">Unproject suas imagens locais de volta ao posições do mundo ou raios do mundo provavelmente.</span><span class="sxs-lookup"><span data-stu-id="eb35f-221">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="eb35f-222">Consulte</span><span class="sxs-lookup"><span data-stu-id="eb35f-222">See</span></span>
4. <span data-ttu-id="eb35f-223">Posicione os modelos de virtuais sobre esses locais do mundo</span><span class="sxs-lookup"><span data-stu-id="eb35f-223">Position your virtual models over these world locations</span></span>

<span data-ttu-id="eb35f-224">Alguns links de processamento de imagem importantes:</span><span class="sxs-lookup"><span data-stu-id="eb35f-224">Some important image processing links:</span></span>
* [<span data-ttu-id="eb35f-225">OpenCV</span><span class="sxs-lookup"><span data-stu-id="eb35f-225">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="eb35f-226">QR marcas</span><span class="sxs-lookup"><span data-stu-id="eb35f-226">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="eb35f-227">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="eb35f-227">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="eb35f-228">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="eb35f-228">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="eb35f-229">Manter uma taxa de quadros do aplicativo interativo é fundamental, especialmente ao lidar com os algoritmos de reconhecimento de imagem de longa execução.</span><span class="sxs-lookup"><span data-stu-id="eb35f-229">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="eb35f-230">Por esse motivo que nós geralmente usamos o seguinte padrão:</span><span class="sxs-lookup"><span data-stu-id="eb35f-230">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="eb35f-231">Thread principal: gerencia o objeto de câmera</span><span class="sxs-lookup"><span data-stu-id="eb35f-231">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="eb35f-232">Thread principal: solicitações novos quadros (assíncrono)</span><span class="sxs-lookup"><span data-stu-id="eb35f-232">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="eb35f-233">Thread principal: passar novos quadros para controle de thread</span><span class="sxs-lookup"><span data-stu-id="eb35f-233">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="eb35f-234">Controle de Thread: imagem de processos coletar pontos-chave</span><span class="sxs-lookup"><span data-stu-id="eb35f-234">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="eb35f-235">Thread principal: move o modelo virtual para corresponder ao encontra pontos-chave</span><span class="sxs-lookup"><span data-stu-id="eb35f-235">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="eb35f-236">Thread principal: repita a etapa 2</span><span class="sxs-lookup"><span data-stu-id="eb35f-236">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="eb35f-237">Alguns sistemas de marcador da imagem apenas fornecem um local de pixel único (outros fornecem a transformação completa nesse caso, esta seção não será necessário), que é igual a um raio de possíveis locais.</span><span class="sxs-lookup"><span data-stu-id="eb35f-237">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="eb35f-238">Para obter uma única localização 3d podemos, em seguida, aproveitar vários raios e localizar o resultado final, a interseção entre elas aproximado.</span><span class="sxs-lookup"><span data-stu-id="eb35f-238">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="eb35f-239">Para fazer isso, você precisará:</span><span class="sxs-lookup"><span data-stu-id="eb35f-239">To do this you'll need to:</span></span>
1. <span data-ttu-id="eb35f-240">Obter um loop que irá coletar várias imagens da câmera</span><span class="sxs-lookup"><span data-stu-id="eb35f-240">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="eb35f-241">Localizar os pontos de recursos associado e seus raios do mundo</span><span class="sxs-lookup"><span data-stu-id="eb35f-241">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="eb35f-242">Quando você tem um dicionário de recursos, cada um com vários raios do mundo, você pode usar o código a seguir para resolver para a interseção dos raios:</span><span class="sxs-lookup"><span data-stu-id="eb35f-242">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="eb35f-243">Dois ou mais locais de marca controladas, você pode posicionar uma cena modelled de acordo com o cenário atual de usuários.</span><span class="sxs-lookup"><span data-stu-id="eb35f-243">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="eb35f-244">Se você não pode assumir a gravidade, em seguida, você precisará três locais de marca.</span><span class="sxs-lookup"><span data-stu-id="eb35f-244">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="eb35f-245">Em muitos casos, que podemos usar um esquema de cores simples onde esferas brancas representam em tempo real rastreadas locais de marca e esferas azuis representam os locais de marca modeladas, isso permite que o usuário visualmente a qualidade do alinhamento do medidor.</span><span class="sxs-lookup"><span data-stu-id="eb35f-245">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="eb35f-246">Vamos supor a seguinte configuração em todos os nossos aplicativos:</span><span class="sxs-lookup"><span data-stu-id="eb35f-246">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="eb35f-247">Dois ou mais locais de marca modeladas</span><span class="sxs-lookup"><span data-stu-id="eb35f-247">Two or more modelled tag locations</span></span>
* <span data-ttu-id="eb35f-248">Um 'espaço de calibragem', que é o pai das marcas na cena</span><span class="sxs-lookup"><span data-stu-id="eb35f-248">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="eb35f-249">Identificador de recurso de câmera</span><span class="sxs-lookup"><span data-stu-id="eb35f-249">Camera feature identifier</span></span>
* <span data-ttu-id="eb35f-250">Comportamento que move o espaço de calibração para alinhar as marcas modelled com as marcas em tempo real (estamos cuidadosos para mover o espaço do pai, não os marcadores modelled por conta própria, porque outros connect é posições relativas aos-los).</span><span class="sxs-lookup"><span data-stu-id="eb35f-250">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="eb35f-251">Faixa ou identificar marcado estático ou movendo reais objetos/faces usando LEDs ou outras bibliotecas do reconhecedor</span><span class="sxs-lookup"><span data-stu-id="eb35f-251">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="eb35f-252">Exemplos:</span><span class="sxs-lookup"><span data-stu-id="eb35f-252">Examples:</span></span>
* <span data-ttu-id="eb35f-253">Robôs industriais com LEDs (ou objetos de códigos QR para mover mais lenta)</span><span class="sxs-lookup"><span data-stu-id="eb35f-253">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="eb35f-254">Identificar e reconhecer os objetos na sala</span><span class="sxs-lookup"><span data-stu-id="eb35f-254">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="eb35f-255">Identificar e reconhecer pessoas na sala (por exemplo, coloque holográfica cartões de visita dos rostos)</span><span class="sxs-lookup"><span data-stu-id="eb35f-255">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="eb35f-256">Consulte também</span><span class="sxs-lookup"><span data-stu-id="eb35f-256">See also</span></span>
* [<span data-ttu-id="eb35f-257">Câmera localizável no DirectX</span><span class="sxs-lookup"><span data-stu-id="eb35f-257">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="eb35f-258">Câmera localizável no Unity</span><span class="sxs-lookup"><span data-stu-id="eb35f-258">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="eb35f-259">Captura de realidade misturada</span><span class="sxs-lookup"><span data-stu-id="eb35f-259">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="eb35f-260">Captura de realidade misturada para desenvolvedores</span><span class="sxs-lookup"><span data-stu-id="eb35f-260">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="eb35f-261">Introdução de captura de mídia</span><span class="sxs-lookup"><span data-stu-id="eb35f-261">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="eb35f-262">Exemplo de acompanhamento de face holográfica</span><span class="sxs-lookup"><span data-stu-id="eb35f-262">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
