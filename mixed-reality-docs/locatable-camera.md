---
title: Câmera localizáveis
description: Informações gerais sobre a câmera de voltado para o front-HoloLens.
author: wguyman
ms.author: wguyman
ms.date: 02/24/2019
ms.topic: article
keywords: voltado para o front-câmera, hololens, câmera de cor
ms.openlocfilehash: ffcd6faf15dd8556db393237d468a3cdf60e4bdb
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 04/12/2019
ms.locfileid: "59590694"
---
# <a name="locatable-camera"></a><span data-ttu-id="02d73-104">Câmera localizáveis</span><span class="sxs-lookup"><span data-stu-id="02d73-104">Locatable camera</span></span>

<span data-ttu-id="02d73-105">HoloLens incluem uma câmera voltados para o mundo montada na parte frontal do dispositivo que permite que os aplicativos ver o que o usuário vê.</span><span class="sxs-lookup"><span data-stu-id="02d73-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="02d73-106">Os desenvolvedores têm acesso e controle da câmera, assim como fariam para câmeras de cor em smartphones, computadores portáteis ou áreas de trabalho.</span><span class="sxs-lookup"><span data-stu-id="02d73-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="02d73-107">O mesmo windows universal [captura de mídia](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) e funcionam de APIs que funcionam em dispositivos móveis e área de trabalho de base de mídia do windows em HoloLens.</span><span class="sxs-lookup"><span data-stu-id="02d73-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="02d73-108">Unity [também foi quebrada essa APIs do windows](locatable-camera-in-unity.md) abstrair o simple uso da câmera em HoloLens para tarefas como levando regulares fotos e vídeos (com ou sem hologramas) e localizar a posição da câmera no e perspectiva sobre o cena.</span><span class="sxs-lookup"><span data-stu-id="02d73-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="02d73-109">Informações de câmera do dispositivo</span><span class="sxs-lookup"><span data-stu-id="02d73-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="02d73-110">HoloLens (first-generation)</span><span class="sxs-lookup"><span data-stu-id="02d73-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="02d73-111">Câmera de foto/vídeo (PV) foco fixa, com o balanço automático branca, exposição automática e pipe de processamento de imagem completa</span><span class="sxs-lookup"><span data-stu-id="02d73-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="02d73-112">LED de privacidade em branco voltados para o mundo acenderá sempre que a câmera está ativa</span><span class="sxs-lookup"><span data-stu-id="02d73-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="02d73-113">A câmera suporta os seguintes modos (todos os modos são a taxa de proporção de 16:9) em 5 de fps, 24, 20, 15 e 30:</span><span class="sxs-lookup"><span data-stu-id="02d73-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="02d73-114">Vídeo</span><span class="sxs-lookup"><span data-stu-id="02d73-114">Video</span></span>  |  <span data-ttu-id="02d73-115">Visualizar</span><span class="sxs-lookup"><span data-stu-id="02d73-115">Preview</span></span>  |  <span data-ttu-id="02d73-116">Ainda</span><span class="sxs-lookup"><span data-stu-id="02d73-116">Still</span></span>  |  <span data-ttu-id="02d73-117">Campo de exibição horizontal (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="02d73-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="02d73-118">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="02d73-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="02d73-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="02d73-119">1280x720</span></span> |  <span data-ttu-id="02d73-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="02d73-120">1280x720</span></span> |  <span data-ttu-id="02d73-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="02d73-121">1280x720</span></span> |  <span data-ttu-id="02d73-122">45deg</span><span class="sxs-lookup"><span data-stu-id="02d73-122">45deg</span></span>  |  <span data-ttu-id="02d73-123">(modo de padrão com estabilização do vídeo)</span><span class="sxs-lookup"><span data-stu-id="02d73-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="02d73-124">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-124">N/A</span></span> |  <span data-ttu-id="02d73-125">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-125">N/A</span></span> |  <span data-ttu-id="02d73-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="02d73-126">2048x1152</span></span> |  <span data-ttu-id="02d73-127">67deg</span><span class="sxs-lookup"><span data-stu-id="02d73-127">67deg</span></span> |  <span data-ttu-id="02d73-128">Imagem estática de resolução mais alta</span><span class="sxs-lookup"><span data-stu-id="02d73-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="02d73-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="02d73-129">1408x792</span></span> |  <span data-ttu-id="02d73-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="02d73-130">1408x792</span></span> |  <span data-ttu-id="02d73-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="02d73-131">1408x792</span></span> |  <span data-ttu-id="02d73-132">48deg</span><span class="sxs-lookup"><span data-stu-id="02d73-132">48deg</span></span> |  <span data-ttu-id="02d73-133">Excedem resolução (preenchimento) antes de estabilização do vídeo</span><span class="sxs-lookup"><span data-stu-id="02d73-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="02d73-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="02d73-134">1344x756</span></span> |  <span data-ttu-id="02d73-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="02d73-135">1344x756</span></span> |  <span data-ttu-id="02d73-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="02d73-136">1344x756</span></span> |  <span data-ttu-id="02d73-137">67deg</span><span class="sxs-lookup"><span data-stu-id="02d73-137">67deg</span></span> |  <span data-ttu-id="02d73-138">Modo de vídeo de FOV grande com overscan</span><span class="sxs-lookup"><span data-stu-id="02d73-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="02d73-139">896x504</span><span class="sxs-lookup"><span data-stu-id="02d73-139">896x504</span></span> |  <span data-ttu-id="02d73-140">896x504</span><span class="sxs-lookup"><span data-stu-id="02d73-140">896x504</span></span> |  <span data-ttu-id="02d73-141">896x504</span><span class="sxs-lookup"><span data-stu-id="02d73-141">896x504</span></span> |  <span data-ttu-id="02d73-142">48deg</span><span class="sxs-lookup"><span data-stu-id="02d73-142">48deg</span></span> |  <span data-ttu-id="02d73-143">Baixa energia / tarefas de processamento de modo de baixa resolução de imagem</span><span class="sxs-lookup"><span data-stu-id="02d73-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="02d73-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="02d73-144">HoloLens 2</span></span>

* <span data-ttu-id="02d73-145">Câmera de foto/vídeo (PV) foco automático, com o balanço automático branca, exposição automática e pipe de processamento de imagem completa</span><span class="sxs-lookup"><span data-stu-id="02d73-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="02d73-146">LED de privacidade em branco voltados para o mundo acenderá sempre que a câmera está ativa</span><span class="sxs-lookup"><span data-stu-id="02d73-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="02d73-147">A câmera dá suporte a modos a seguir (todos os modos de vídeos são a taxa de proporção de 16:9):</span><span class="sxs-lookup"><span data-stu-id="02d73-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="02d73-148">Esses modos estão sujeitos a alterações antes da disponibilidade geral do HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="02d73-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="02d73-149">Vídeo</span><span class="sxs-lookup"><span data-stu-id="02d73-149">Video</span></span>  |  <span data-ttu-id="02d73-150">Visualizar</span><span class="sxs-lookup"><span data-stu-id="02d73-150">Preview</span></span>  |  <span data-ttu-id="02d73-151">Ainda</span><span class="sxs-lookup"><span data-stu-id="02d73-151">Still</span></span>  |  <span data-ttu-id="02d73-152">Taxas de quadros</span><span class="sxs-lookup"><span data-stu-id="02d73-152">Frame rates</span></span>  |  <span data-ttu-id="02d73-153">Campo de exibição horizontal (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="02d73-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="02d73-154">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="02d73-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="02d73-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="02d73-155">1920x1080</span></span> |  <span data-ttu-id="02d73-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="02d73-156">1920x1080</span></span> |  <span data-ttu-id="02d73-157">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-157">N/A</span></span> |  <span data-ttu-id="02d73-158">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="02d73-158">30, 15 fps</span></span>  |  <span data-ttu-id="02d73-159">54deg</span><span class="sxs-lookup"><span data-stu-id="02d73-159">54deg</span></span>  |  <span data-ttu-id="02d73-160">(modo de padrão com estabilização do vídeo)</span><span class="sxs-lookup"><span data-stu-id="02d73-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="02d73-161">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-161">N/A</span></span> |  <span data-ttu-id="02d73-162">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-162">N/A</span></span> |  <span data-ttu-id="02d73-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="02d73-163">3904X2196</span></span> |  <span data-ttu-id="02d73-164">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-164">N/A</span></span>  |  <span data-ttu-id="02d73-165">64deg</span><span class="sxs-lookup"><span data-stu-id="02d73-165">64deg</span></span> |  <span data-ttu-id="02d73-166">Imagem estática de resolução mais alta</span><span class="sxs-lookup"><span data-stu-id="02d73-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="02d73-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="02d73-167">2272x1278</span></span> |  <span data-ttu-id="02d73-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="02d73-168">2272x1278</span></span> |  <span data-ttu-id="02d73-169">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-169">N/A</span></span> |  <span data-ttu-id="02d73-170">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="02d73-170">30, 15 fps</span></span>  |  <span data-ttu-id="02d73-171">64deg</span><span class="sxs-lookup"><span data-stu-id="02d73-171">64deg</span></span> |  <span data-ttu-id="02d73-172">Excedem resolução (preenchimento) antes de estabilização do vídeo</span><span class="sxs-lookup"><span data-stu-id="02d73-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="02d73-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="02d73-173">1952x1100</span></span> |  <span data-ttu-id="02d73-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="02d73-174">1952x1100</span></span> |  <span data-ttu-id="02d73-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="02d73-175">1952x1100</span></span>  |  <span data-ttu-id="02d73-176">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="02d73-176">30, 15 fps</span></span>  |  <span data-ttu-id="02d73-177">64deg</span><span class="sxs-lookup"><span data-stu-id="02d73-177">64deg</span></span> |  <span data-ttu-id="02d73-178">Fluxo de alta qualidade</span><span class="sxs-lookup"><span data-stu-id="02d73-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="02d73-179">1280x720</span><span class="sxs-lookup"><span data-stu-id="02d73-179">1280x720</span></span> |  <span data-ttu-id="02d73-180">1280x720</span><span class="sxs-lookup"><span data-stu-id="02d73-180">1280x720</span></span> |  <span data-ttu-id="02d73-181">N/D</span><span class="sxs-lookup"><span data-stu-id="02d73-181">N/A</span></span> |  <span data-ttu-id="02d73-182">30, 15, 5 fps</span><span class="sxs-lookup"><span data-stu-id="02d73-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="02d73-183">64deg</span><span class="sxs-lookup"><span data-stu-id="02d73-183">64deg</span></span> |  <span data-ttu-id="02d73-184">Modo de baixa energia/resolução para streaming e tarefas de processamento de imagens</span><span class="sxs-lookup"><span data-stu-id="02d73-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="02d73-185">Localizando a câmera do dispositivo no mundo</span><span class="sxs-lookup"><span data-stu-id="02d73-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="02d73-186">Quando houver HoloLens fotos e vídeos, os quadros capturados incluem o local da câmera no mundo, bem como a projeção de perspectiva da câmera.</span><span class="sxs-lookup"><span data-stu-id="02d73-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the perspective projection of the camera.</span></span> <span data-ttu-id="02d73-187">Isso permite que aplicativos raciocinar sobre a posição da câmera no mundo real para cenários de geração de imagens aumentados.</span><span class="sxs-lookup"><span data-stu-id="02d73-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="02d73-188">Os desenvolvedores poderão ser revertidas criativamente seus próprios cenários usando seu processamento de imagens favorito ou bibliotecas de visão personalizada do computador.</span><span class="sxs-lookup"><span data-stu-id="02d73-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="02d73-189">"Câmera" em outro lugar na documentação do HoloLens pode se referir a "jogo câmera virtual" (o aplicativo frustum renderiza o).</span><span class="sxs-lookup"><span data-stu-id="02d73-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="02d73-190">A menos que indicado o contrário, "câmera" nesta página refere-se a câmera de cor RGB do mundo real.</span><span class="sxs-lookup"><span data-stu-id="02d73-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="02d73-191">Os detalhes sobre esse rosto [atributos do Media Foundation](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), no entanto, há também as APIs para efetuar pull de uso de intrínsecos de câmera [APIs do WinRT](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span><span class="sxs-lookup"><span data-stu-id="02d73-191">The details on this page cover [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), however there are also APIs to pull camera intrinsics using [WinRT APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span></span>  

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="02d73-192">Imagens com sistemas de coordenadas</span><span class="sxs-lookup"><span data-stu-id="02d73-192">Images with Coordinate Systems</span></span>

<span data-ttu-id="02d73-193">Cada quadro da imagem (se foto ou vídeo) inclui um sistema de coordenadas, bem como duas transformações importantes.</span><span class="sxs-lookup"><span data-stu-id="02d73-193">Each image frame (whether photo or video) includes a coordinate system, as well as two important transforms.</span></span> <span data-ttu-id="02d73-194">O "modo de exibição" transforma mapas do sistema de coordenadas fornecido para a câmera e a "projeção" da câmera para pixels da imagem.</span><span class="sxs-lookup"><span data-stu-id="02d73-194">The "view" transform maps from the provided coordinate system to the camera, and the "projection" maps from the camera to pixels in the image.</span></span> <span data-ttu-id="02d73-195">Juntas, essas transformações definem para cada pixel um raio no espaço 3D, que representa o caminho tomada pelos photons que produziu o pixel.</span><span class="sxs-lookup"><span data-stu-id="02d73-195">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="02d73-196">Esses raios podem estar relacionados a outro conteúdo no aplicativo Obtendo a transformação do sistema de coordenadas do quadro para algum outro sistema de coordenadas (por exemplo, de um [quadro estacionário de referência](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="02d73-196">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="02d73-197">Para resumir, cada quadro da imagem fornece o seguinte:</span><span class="sxs-lookup"><span data-stu-id="02d73-197">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="02d73-198">Dados de pixel (no formato RGB/NV12/JPEG/etc.)</span><span class="sxs-lookup"><span data-stu-id="02d73-198">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="02d73-199">3 partes dos metadados (armazenado como [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) que fazem a cada quadro "localizáveis":</span><span class="sxs-lookup"><span data-stu-id="02d73-199">3 pieces of metadata (stored as [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) that make each frame "locatable":</span></span>

|  <span data-ttu-id="02d73-200">Nome do atributo</span><span class="sxs-lookup"><span data-stu-id="02d73-200">Attribute name</span></span>  |  <span data-ttu-id="02d73-201">Tipo</span><span class="sxs-lookup"><span data-stu-id="02d73-201">Type</span></span>  |  <span data-ttu-id="02d73-202">GUID</span><span class="sxs-lookup"><span data-stu-id="02d73-202">GUID</span></span>  |  <span data-ttu-id="02d73-203">Descrição</span><span class="sxs-lookup"><span data-stu-id="02d73-203">Description</span></span> | 
|----------|----------|----------|----------|
|  <span data-ttu-id="02d73-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span><span class="sxs-lookup"><span data-stu-id="02d73-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span></span>  |  <span data-ttu-id="02d73-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span><span class="sxs-lookup"><span data-stu-id="02d73-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span></span>  |  <span data-ttu-id="02d73-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span><span class="sxs-lookup"><span data-stu-id="02d73-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span></span>  |  <span data-ttu-id="02d73-207">Armazena o [sistema de coordenadas](coordinate-systems-in-directx.md) de quadro capturado</span><span class="sxs-lookup"><span data-stu-id="02d73-207">Stores the [coordinate system](coordinate-systems-in-directx.md) of the captured frame</span></span> | 
|  <span data-ttu-id="02d73-208">MFSampleExtension_Spatial_CameraViewTransform</span><span class="sxs-lookup"><span data-stu-id="02d73-208">MFSampleExtension_Spatial_CameraViewTransform</span></span>  |  <span data-ttu-id="02d73-209">BLOB ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="02d73-209">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="02d73-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span><span class="sxs-lookup"><span data-stu-id="02d73-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span></span>  |  <span data-ttu-id="02d73-211">Armazena a transformação de extrínsecos da câmera no sistema de coordenadas</span><span class="sxs-lookup"><span data-stu-id="02d73-211">Stores the camera's extrinsic transform in the coordinate system</span></span> | 
|  <span data-ttu-id="02d73-212">MFSampleExtension_Spatial_CameraProjectionTransform</span><span class="sxs-lookup"><span data-stu-id="02d73-212">MFSampleExtension_Spatial_CameraProjectionTransform</span></span>  |  <span data-ttu-id="02d73-213">BLOB ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="02d73-213">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="02d73-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span><span class="sxs-lookup"><span data-stu-id="02d73-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span></span>  |  <span data-ttu-id="02d73-215">Armazena a transformação de projeção da câmera</span><span class="sxs-lookup"><span data-stu-id="02d73-215">Stores the camera's projection transform</span></span> | 

<span data-ttu-id="02d73-216">A transformação de projeção representa as propriedades intrínsecas (comprimento focal, o Centro de projeção, distorção) da lente mapeada em um plano de imagem que se estende de -1 até + 1 no eixo X e Y de.</span><span class="sxs-lookup"><span data-stu-id="02d73-216">The projection transform represents the intrinsic properties (focal length, center of projection, skew) of the lens mapped onto an image plane that extends from -1 to +1 in both the X and Y axis.</span></span>

```
Matrix4x4 format          Terms
   m11 m12 m13 m14      fx    0   0   0
   m21 m22 m23 m24     skew  fy   0   0
   m31 m32 m33 m34      cx   cy   A  -1
   m41 m42 m43 m44       0    0   B   0
```

<span data-ttu-id="02d73-217">Aplicativos de diferentes terão diferentes sistemas de coordenadas.</span><span class="sxs-lookup"><span data-stu-id="02d73-217">Different applications will have different coordinate systems.</span></span> <span data-ttu-id="02d73-218">Aqui está uma visão geral do fluxo para localizar um pixel de câmera para um único aplicativo:</span><span class="sxs-lookup"><span data-stu-id="02d73-218">Here's an overview of the flow to locate a camera pixel for a single application:</span></span>

![Transformações aplicada a sistemas de coordenadas de câmera](images/pvcameratransform5-500px.png)

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="02d73-220">Câmera para o sistema de coordenadas especificado pelo aplicativo</span><span class="sxs-lookup"><span data-stu-id="02d73-220">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="02d73-221">Para ir do 'VisualizaçãoCâmera' e 'CameraCoordinateSystem' para o seu sistema de coordenadas de mundo/aplicativo, você precisará do seguinte:</span><span class="sxs-lookup"><span data-stu-id="02d73-221">To go from the 'CameraView' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="02d73-222">[Localizáveis câmera no Unity](locatable-camera-in-unity.md): CameraToWorldMatrix é fornecida automaticamente pela classe PhotoCaptureFrame (de modo que você não precisa se preocupar sobre as transformações CameraCoordinateSystem).</span><span class="sxs-lookup"><span data-stu-id="02d73-222">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="02d73-223">[Câmera localizáveis no DirectX](locatable-camera-in-directx.md): Mostra a maneira bastante simples de consulta para a transformação entre o sistema de coordenadas da câmera e coordinate system(s) seu próprio aplicativo.</span><span class="sxs-lookup"><span data-stu-id="02d73-223">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="application-specified-coordinate-system-to-pixel-coordinates"></a><span data-ttu-id="02d73-224">Sistema de coordenadas especificado pelo aplicativo para coordenadas de Pixel</span><span class="sxs-lookup"><span data-stu-id="02d73-224">Application-specified Coordinate System to Pixel Coordinates</span></span>

<span data-ttu-id="02d73-225">Digamos que você deseja localizar ou desenhar em um local específico de 3d em uma imagem de câmera:</span><span class="sxs-lookup"><span data-stu-id="02d73-225">Let's say you wanted to find or draw at a specific 3d location on a camera image:</span></span>

<span data-ttu-id="02d73-226">As transformações de projeção e exibição, enquanto as duas matrizes de 4 x 4, precisam ser utilizado de forma ligeiramente diferente.</span><span class="sxs-lookup"><span data-stu-id="02d73-226">The view and projection transforms, while both 4x4 matrices, need to be utilized slightly differently.</span></span> <span data-ttu-id="02d73-227">Ou seja, depois de executar a projeção, um 'normalizariam por w', essa etapa extra na projeção simula como vários locais diferentes de 3d podem acabar como o mesmo local de 2d em uma tela (ou seja, qualquer coisa ao longo de um determinado raio serão exibidos no mesmo pixel).</span><span class="sxs-lookup"><span data-stu-id="02d73-227">Namely after performing the Projection, one would 'normalize by w', this extra step in the projection simulates how multiple different 3d locations can end up as the same 2d location on a screen (i.e. anything along a certain ray will show up on the same pixel).</span></span> <span data-ttu-id="02d73-228">Portanto, os principais pontos (no código do sombreador):</span><span class="sxs-lookup"><span data-stu-id="02d73-228">So key points (in shader code):</span></span>

```
// Usual 3d math:
 float4x4 WorldToCamera = inverse( CameraToWorld );
 float4 CameraSpacePos = mul( WorldToCamera, float4( WorldSpacePos.xyz, 1 ) ); // use 1 as the W component
 // Projection math:
 float4 ImagePosUnnormalized = mul( CameraProjection, float4( CameraSpacePos.xyz, 1 ) ); // use 1 as the W component
 float2 ImagePosProjected = ImagePosUnnormalized.xy / ImagePosUnnormalized.w; // normalize by W, gives -1 to 1 space
 float2 ImagePosZeroToOne = ( ImagePosProjected * 0.5 ) + float2( 0.5, 0.5 ); // good for GPU textures
 int2 PixelPos = int2( ImagePosZeroToOne.x * ImageWidth, ( 1 - ImagePosZeroToOne.y ) * ImageHeight ); // good for CPU textures
```

### <a name="pixel-to-application-specified-coordinate-system"></a><span data-ttu-id="02d73-229">Pixel para o sistema de coordenadas especificado pelo aplicativo</span><span class="sxs-lookup"><span data-stu-id="02d73-229">Pixel to Application-specified Coordinate System</span></span>

<span data-ttu-id="02d73-230">Indo do pixel para coordenadas de mundo é um pouco mais complicado:</span><span class="sxs-lookup"><span data-stu-id="02d73-230">Going from pixel to world coordinates is a little trickier:</span></span>

```
float2 ImagePosZeroToOne = float2( PixelPos.x / ImageWidth, 1.0 - (PixelPos.y / ImageHeight ) );
 float2 ImagePosProjected = ( ( ImagePosZeroToOne * 2.0 ) - float2(1,1) ); // -1 to 1 space
 float3 CameraSpacePos = UnProjectVector( Projection, float3( ImagePosProjected, 1) );
 float3 WorldSpaceRayPoint1 = mul( CameraToWorld, float4(0,0,0,1) ); // camera location in world space
 float3 WorldSpaceRayPoint2 = mul( CameraToWorld, CameraSpacePos ); // ray point in world space
```

<span data-ttu-id="02d73-231">Onde definimos UnProject como:</span><span class="sxs-lookup"><span data-stu-id="02d73-231">Where we define UnProject as:</span></span>

```
public static Vector3 UnProjectVector(Matrix4x4 proj, Vector3 to)
 {
   Vector3 from = new Vector3(0, 0, 0);
   var axsX = proj.GetRow(0);
   var axsY = proj.GetRow(1);
   var axsZ = proj.GetRow(2);
   from.z = to.z / axsZ.z;
   from.y = (to.y - (from.z * axsY.z)) / axsY.y;
   from.x = (to.x - (from.z * axsX.z)) / axsX.x;
   return from;
 }
```

<span data-ttu-id="02d73-232">Para encontrar o local do mundo real de um ponto, você vai precisar: mundo dois raios e encontrar a interseção entre elas, ou um tamanho conhecido dos pontos.</span><span class="sxs-lookup"><span data-stu-id="02d73-232">To find the actual world location of a point, you'll need either: two world rays and find their intersection, or a known size of the points.</span></span>

### <a name="distortion-error"></a><span data-ttu-id="02d73-233">Erro de distorção</span><span class="sxs-lookup"><span data-stu-id="02d73-233">Distortion Error</span></span>

<span data-ttu-id="02d73-234">Em HoloLens, o vídeo e os fluxos de imagem ainda estão sem distorção no pipeline de processamento de imagem do sistema antes dos quadros são disponibilizados para o aplicativo (o fluxo de visualização contém os quadros distorcidos originais).</span><span class="sxs-lookup"><span data-stu-id="02d73-234">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="02d73-235">Como apenas a matriz de projeção for disponibilizada, aplicativos devem assumir que representam de quadros de imagem uma câmera pinhole perfeito, no entanto o undistortion funcionar no processador de imagem pode ainda deixar um erro de até 10 pixels ao usar a matriz de projeção em os metadados do quadro.</span><span class="sxs-lookup"><span data-stu-id="02d73-235">Because only the projection matrix is made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels when using the projection matrix in the frame metadata.</span></span> <span data-ttu-id="02d73-236">Em muitos casos de uso, esse erro não será relevante, mas se alinhando hologramas para cartazes/marcadores do mundo real, por exemplo, e você notar um < 10px deslocamento (aproximadamente 11mm para hologramas posicionado 2 metros de distância) essa distorção erro poderia ser a causa.</span><span class="sxs-lookup"><span data-stu-id="02d73-236">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span>

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="02d73-237">Cenários de uso de câmera localizáveis</span><span class="sxs-lookup"><span data-stu-id="02d73-237">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="02d73-238">Mostrar uma foto ou vídeo no mundo em que ele foi capturado</span><span class="sxs-lookup"><span data-stu-id="02d73-238">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="02d73-239">Os quadros de câmera do dispositivo vem com uma transformação "Câmera para World", que pode ser usada para mostrar onde o dispositivo foi exatamente quando a imagem foi capturada.</span><span class="sxs-lookup"><span data-stu-id="02d73-239">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="02d73-240">Por exemplo, você pode posicionar um pequeno ícone holográfico neste local (CameraToWorld.MultiplyPoint(Vector3.zero)) e draw até mesmo uma pequena seta na direção que a câmera enfrentava (CameraToWorld.MultiplyVector(Vector3.forward)).</span><span class="sxs-lookup"><span data-stu-id="02d73-240">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="painting-the-world-using-a-camera-shader"></a><span data-ttu-id="02d73-241">Pintando mundo usando um sombreador de câmera</span><span class="sxs-lookup"><span data-stu-id="02d73-241">Painting the world using a camera shader</span></span>

<span data-ttu-id="02d73-242">Nesta seção, criaremos um material 'sombreador de' que cores que o mundo com base em onde ele apareceu no modo de exibição da câmera do dispositivo.</span><span class="sxs-lookup"><span data-stu-id="02d73-242">In this section we'll create a material 'shader' that colors the world based on where it showed up in a device camera's view.</span></span> <span data-ttu-id="02d73-243">Efetivamente o que faremos é que cada vértice será descobrir seu local em relação à câmera e, em seguida, cada pixel utilizará a matriz de projeção' ' à figura fora qual imagem texel está associada.</span><span class="sxs-lookup"><span data-stu-id="02d73-243">Effectively what we'll do is that every vertex will figure out its location relative to the camera, and then every pixel will utilize the 'projection matrix' to figure out which image texel it is associated with.</span></span> <span data-ttu-id="02d73-244">Por fim e, opcionalmente, podemos irá esmaecer os cantos da imagem para que ele apareça mais como um sonho semelhante de memória:</span><span class="sxs-lookup"><span data-stu-id="02d73-244">Lastly, and optionally, we'll fade out the corners of the image to make it appear more as a dream-like memory:</span></span>

```
// In the vertex shader:
 float4 worldSpace = mul( ObjectToWorld, float4( vertexPos.xyz, 1));
 float4 cameraSpace = mul( CameraWorldToLocal, float4(worldSpace.xyz, 1));

 // In the pixel shader:
 float4 unprojectedTex = mul( CameraProjection, float4( cameraSpace .xyz, 1));
 float2 projectedTex = (unprojectedTex.xy / unprojectedTex.w);
 float2 unitTexcoord = ((projectedTex * 0.5) + float4(0.5, 0.5, 0, 0));
 float4 cameraTextureColor = tex2D(_CameraTex, unitTexcoord);
 // Fade out edges for better look:
 float pctInView = saturate((1.0 - length(projectedTex.xy)) * 3.0);
 float4 finalColor = float4( cameraTextureColor.rgb, pctInView );
```

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="02d73-245">Marca / padrão / pôster / acompanhamento de objeto</span><span class="sxs-lookup"><span data-stu-id="02d73-245">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="02d73-246">Muitos aplicativos de realidade misturada usam uma imagem reconhecível ou padrão visual para criar um ponto controláveis no espaço.</span><span class="sxs-lookup"><span data-stu-id="02d73-246">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="02d73-247">Em seguida, isso é usado para processar objetos em relação ao que apontam ou criar um local conhecido.</span><span class="sxs-lookup"><span data-stu-id="02d73-247">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="02d73-248">Alguns usos para o HoloLens incluem Localizando um objeto do mundo real marcado com fiducials (por exemplo, um monitor de TV com um código QR), colocando hologramas sobre fiducials e visualmente emparelhamento com dispositivos não HoloLens, como tablets que foram configurados para se comunicar com o HoloLens por meio de Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="02d73-248">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="02d73-249">Para reconhecer um padrão visual e, em seguida, colocar esse objeto no espaço de mundo de aplicativos, você precisará de algumas coisas:</span><span class="sxs-lookup"><span data-stu-id="02d73-249">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="02d73-250">Uma imagem padrão reconhecimento Kit de ferramentas, como o código QR, marcas de AR, o localizador de face, rastreadores de círculo, OCR etc.</span><span class="sxs-lookup"><span data-stu-id="02d73-250">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="02d73-251">Colete os quadros de imagem em tempo de execução e passá-los para a camada de reconhecimento</span><span class="sxs-lookup"><span data-stu-id="02d73-251">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="02d73-252">Unproject suas imagens locais de volta ao posições do mundo ou raios do mundo provavelmente.</span><span class="sxs-lookup"><span data-stu-id="02d73-252">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="02d73-253">Consulte</span><span class="sxs-lookup"><span data-stu-id="02d73-253">See</span></span>
4. <span data-ttu-id="02d73-254">Posicione os modelos de virtuais sobre esses locais do mundo</span><span class="sxs-lookup"><span data-stu-id="02d73-254">Position your virtual models over these world locations</span></span>

<span data-ttu-id="02d73-255">Alguns links de processamento de imagem importantes:</span><span class="sxs-lookup"><span data-stu-id="02d73-255">Some important image processing links:</span></span>
* [<span data-ttu-id="02d73-256">OpenCV</span><span class="sxs-lookup"><span data-stu-id="02d73-256">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="02d73-257">QR marcas</span><span class="sxs-lookup"><span data-stu-id="02d73-257">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="02d73-258">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="02d73-258">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="02d73-259">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="02d73-259">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="02d73-260">Manter uma taxa de quadros do aplicativo interativo é fundamental, especialmente ao lidar com os algoritmos de reconhecimento de imagem de longa execução.</span><span class="sxs-lookup"><span data-stu-id="02d73-260">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="02d73-261">Por esse motivo que nós geralmente usamos o seguinte padrão:</span><span class="sxs-lookup"><span data-stu-id="02d73-261">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="02d73-262">Thread principal: gerencia o objeto de câmera</span><span class="sxs-lookup"><span data-stu-id="02d73-262">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="02d73-263">Thread principal: solicitações novos quadros (assíncrono)</span><span class="sxs-lookup"><span data-stu-id="02d73-263">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="02d73-264">Thread principal: passar novos quadros para controle de thread</span><span class="sxs-lookup"><span data-stu-id="02d73-264">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="02d73-265">Controle de Thread: imagem de processos coletar pontos-chave</span><span class="sxs-lookup"><span data-stu-id="02d73-265">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="02d73-266">Thread principal: move o modelo virtual para corresponder ao encontra pontos-chave</span><span class="sxs-lookup"><span data-stu-id="02d73-266">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="02d73-267">Thread principal: repita a etapa 2</span><span class="sxs-lookup"><span data-stu-id="02d73-267">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="02d73-268">Alguns sistemas de marcador da imagem apenas fornecem um local de pixel único (outros fornecem a transformação completa nesse caso, esta seção não será necessário), que é igual a um raio de possíveis locais.</span><span class="sxs-lookup"><span data-stu-id="02d73-268">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="02d73-269">Para obter uma única localização 3d podemos, em seguida, aproveitar vários raios e localizar o resultado final, a interseção entre elas aproximado.</span><span class="sxs-lookup"><span data-stu-id="02d73-269">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="02d73-270">Para fazer isso, você precisará:</span><span class="sxs-lookup"><span data-stu-id="02d73-270">To do this you'll need to:</span></span>
1. <span data-ttu-id="02d73-271">Obter um loop que irá coletar várias imagens da câmera</span><span class="sxs-lookup"><span data-stu-id="02d73-271">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="02d73-272">Localizar o [pontos de recurso associados](#pixel-to-application-specified-coordinate-system)e seus raios do mundo</span><span class="sxs-lookup"><span data-stu-id="02d73-272">Find the [associated feature points](#pixel-to-application-specified-coordinate-system), and their world rays</span></span>
3. <span data-ttu-id="02d73-273">Quando você tem um dicionário de recursos, cada um com vários raios do mundo, você pode usar o código a seguir para resolver para a interseção dos raios:</span><span class="sxs-lookup"><span data-stu-id="02d73-273">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="02d73-274">Dois ou mais locais de marca controladas, você pode posicionar uma cena modelled de acordo com o cenário atual de usuários.</span><span class="sxs-lookup"><span data-stu-id="02d73-274">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="02d73-275">Se você não pode assumir a gravidade, em seguida, você precisará três locais de marca.</span><span class="sxs-lookup"><span data-stu-id="02d73-275">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="02d73-276">Em muitos casos, que podemos usar um esquema de cores simples onde esferas brancas representam em tempo real rastreadas locais de marca e esferas azuis representam os locais de marca modeladas, isso permite que o usuário visualmente a qualidade do alinhamento do medidor.</span><span class="sxs-lookup"><span data-stu-id="02d73-276">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="02d73-277">Vamos supor a seguinte configuração em todos os nossos aplicativos:</span><span class="sxs-lookup"><span data-stu-id="02d73-277">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="02d73-278">Dois ou mais locais de marca modeladas</span><span class="sxs-lookup"><span data-stu-id="02d73-278">Two or more modelled tag locations</span></span>
* <span data-ttu-id="02d73-279">Um 'espaço de calibragem', que é o pai das marcas na cena</span><span class="sxs-lookup"><span data-stu-id="02d73-279">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="02d73-280">Identificador de recurso de câmera</span><span class="sxs-lookup"><span data-stu-id="02d73-280">Camera feature identifier</span></span>
* <span data-ttu-id="02d73-281">Comportamento que move o espaço de calibração para alinhar as marcas modelled com as marcas em tempo real (estamos cuidadosos para mover o espaço do pai, não os marcadores modelled por conta própria, porque outros connect é posições relativas aos-los).</span><span class="sxs-lookup"><span data-stu-id="02d73-281">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="render-holograms-from-the-cameras-position"></a><span data-ttu-id="02d73-282">Renderizar hologramas da posição da câmera</span><span class="sxs-lookup"><span data-stu-id="02d73-282">Render holograms from the Camera's position</span></span>

<span data-ttu-id="02d73-283">Observação: Se você estiver tentando criar seus próprios [misto (MRC) de captura de realidade](mixed-reality-capture.md), que combina hologramas com o fluxo de câmera, você pode usar o [efeitos MRC](mixed-reality-capture-for-developers.md) ou habilitar a propriedade showHolograms em [ Localizáveis câmera no Unity](locatable-camera-in-unity.md).</span><span class="sxs-lookup"><span data-stu-id="02d73-283">Note: If you are trying to create your own [Mixed reality capture (MRC)](mixed-reality-capture.md), which blends holograms with the Camera stream, you can use the [MRC effects](mixed-reality-capture-for-developers.md) or enable the showHolograms property in [Locatable camera in Unity](locatable-camera-in-unity.md).</span></span>

<span data-ttu-id="02d73-284">Se você quiser fazer um processamento especial diretamente no fluxo de câmera RGB, é possível renderizar hologramas no espaço da posição da câmera em sincronia com um feed de vídeo para fornecer uma visualização de gravação/live holograma personalizado.</span><span class="sxs-lookup"><span data-stu-id="02d73-284">If you'd like to do a special render directly on the RGB Camera stream, it's possible to render holograms in space from the Camera's position in sync with a video feed in order to provide a custom hologram recording/live preview.</span></span>

<span data-ttu-id="02d73-285">No Skype, fazemos isso para mostrar o cliente remoto que esteja vendo o usuário HoloLens e permitir que eles interajam com as mesmas hologramas.</span><span class="sxs-lookup"><span data-stu-id="02d73-285">In Skype, we do this to show the remote client what the HoloLens user is seeing and allow them to interact with the same holograms.</span></span> <span data-ttu-id="02d73-286">Antes de enviar ao longo de cada quadro de vídeo por meio do serviço do Skype, capturamos dados correspondentes de câmera do cada quadro.</span><span class="sxs-lookup"><span data-stu-id="02d73-286">Before sending over each video frame through the Skype service, we grab each frame's corresponding camera data.</span></span> <span data-ttu-id="02d73-287">Podemos, em seguida, empacote metadados de intrínsecos e extrínsecos da câmera com o quadro de vídeo e, em seguida, enviá-lo sobre o serviço do Skype.</span><span class="sxs-lookup"><span data-stu-id="02d73-287">We then package the camera's extrinsic and intrinsic metadata with the video frame and then send it over the Skype service.</span></span>

<span data-ttu-id="02d73-288">No lado de recepção, usando o Unity, nós já já sincronizados todos as hologramas no espaço em HoloLens do usuário usando o mesmo sistema de coordenadas.</span><span class="sxs-lookup"><span data-stu-id="02d73-288">On the receiving side, using Unity, we've already synced all of the holograms in the HoloLens user's space using the same coordinate system.</span></span> <span data-ttu-id="02d73-289">Isso nos permite usar metadados de extrínsecos da câmera para colocar a câmera do Unity no local exato no mundo (relativo ao restante dos hologramas) que o usuário HoloLens apoiava quando esse quadro de vídeo foi capturado e use as informações de câmera intrínseco para Certifique-se de que o modo de exibição é o mesmo.</span><span class="sxs-lookup"><span data-stu-id="02d73-289">This allows us to use the camera's extrinsic metadata to place the Unity camera in the exact place in the world (relative to the rest of the holograms) that the HoloLens user was standing when that video frame was captured, and use the camera intrinsic information to ensure the view is the same.</span></span>

<span data-ttu-id="02d73-290">Assim que tivermos a câmera configurado corretamente, combinamos quais hologramas a câmera vê para o quadro que recebemos do Skype, criando uma exibição de realidade mista do que o usuário HoloLens vê ao usar Graphics.Blit.</span><span class="sxs-lookup"><span data-stu-id="02d73-290">Once we have the camera set up properly, we combine what holograms the camera sees onto the frame we received from Skype, creating a mixed reality view of what the HoloLens user sees using Graphics.Blit.</span></span>

```cs
private void OnFrameReceived(Texture frameTexture, Vector3 cameraPosition, Quaternion cameraRotation, Matrix4x4 cameraProjectionMatrix)
{
    //set material that will be blitted onto the RenderTexture
    this.compositeMaterial.SetTexture(CompositeRenderer.CameraTextureMaterialProperty, frameTexture);
    //set the camera to be that of the HoloLens's device camera
    this.Camera.transform.position = cameraPosition;
    this.Camera.transform.rotation = cameraRotation;
    this.Camera.projectionMatrix = cameraProjectionMatrix;
    //trigger the Graphics's Blit now that the frame and camera are set up
    this.TextureReady = false;
}
private void OnRenderImage(RenderTexture source, RenderTexture destination)
{
    if (!this.TextureReady)
    {
        Graphics.Blit(source, destination, this.compositeMaterial);
        this.TextureReady = true;
    }
}
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="02d73-291">Faixa ou identificar marcado estático ou movendo reais objetos/faces usando LEDs ou outras bibliotecas do reconhecedor</span><span class="sxs-lookup"><span data-stu-id="02d73-291">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="02d73-292">Exemplos:</span><span class="sxs-lookup"><span data-stu-id="02d73-292">Examples:</span></span>
* <span data-ttu-id="02d73-293">Robôs industriais com LEDs (ou objetos de códigos QR para mover mais lenta)</span><span class="sxs-lookup"><span data-stu-id="02d73-293">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="02d73-294">Identificar e reconhecer os objetos na sala</span><span class="sxs-lookup"><span data-stu-id="02d73-294">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="02d73-295">Identificar e reconhecer pessoas na sala (por exemplo, coloque holográfica cartões de visita dos rostos)</span><span class="sxs-lookup"><span data-stu-id="02d73-295">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="02d73-296">Consulte também</span><span class="sxs-lookup"><span data-stu-id="02d73-296">See also</span></span>
* [<span data-ttu-id="02d73-297">Câmera localizáveis no DirectX</span><span class="sxs-lookup"><span data-stu-id="02d73-297">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="02d73-298">Localizáveis câmera no Unity</span><span class="sxs-lookup"><span data-stu-id="02d73-298">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="02d73-299">Captura de realidade misturada</span><span class="sxs-lookup"><span data-stu-id="02d73-299">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="02d73-300">Misto captura realidade para desenvolvedores</span><span class="sxs-lookup"><span data-stu-id="02d73-300">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="02d73-301">Introdução de captura de mídia</span><span class="sxs-lookup"><span data-stu-id="02d73-301">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
