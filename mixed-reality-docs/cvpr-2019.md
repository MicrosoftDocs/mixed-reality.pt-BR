---
title: Aplicativos de visão do computador para workshop de fones de ouvido de realidade mista na CVPR 2019
description: Visão geral e o cronograma dos aplicativos de visão do computador para workshop de fones de ouvido de realidade misturada, sejam entregues na conferência CVPR em junho de 2019.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: evento, o modo de pesquisa, cvpr, pesquisa Visual computacional, pesquisa, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148707"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="2836a-104">Aplicativos de visão do computador para realidade misturada Headsets</span><span class="sxs-lookup"><span data-stu-id="2836a-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="2836a-105">Organizados em conjunto com [CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="2836a-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="2836a-106">Long Beach (CA)</span><span class="sxs-lookup"><span data-stu-id="2836a-106">Long Beach (CA)</span></span>

<span data-ttu-id="2836a-107">17 de junho, à tarde 2019) - Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="2836a-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="2836a-108">Organizadores</span><span class="sxs-lookup"><span data-stu-id="2836a-108">Organizers</span></span>
* <span data-ttu-id="2836a-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="2836a-109">Marc Pollefeys</span></span>
* <span data-ttu-id="2836a-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="2836a-110">Federica Bogo</span></span>
* <span data-ttu-id="2836a-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="2836a-111">Johannes Schönberger</span></span>
* <span data-ttu-id="2836a-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="2836a-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="2836a-113">Visão geral</span><span class="sxs-lookup"><span data-stu-id="2836a-113">Overview</span></span>

![Imagem de amostra](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="2836a-115">Realidade misturada headsets, como o Microsoft HoloLens estão se tornando plataformas poderosas para desenvolver aplicativos de visão do computador.</span><span class="sxs-lookup"><span data-stu-id="2836a-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="2836a-116">O modo de pesquisa do HoloLens permite que a pesquisa Visual computacional no dispositivo, fornecendo acesso a todos os fluxos de sensor da imagem bruta – incluindo profundidade e IR.</span><span class="sxs-lookup"><span data-stu-id="2836a-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="2836a-117">Como o modo de pesquisa está disponível desde maio de 2018, estamos começando a ver várias demonstrações interessantes e aplicativos que estão sendo desenvolvidos para o HoloLens.</span><span class="sxs-lookup"><span data-stu-id="2836a-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="2836a-118">O objetivo deste workshop é reunir todos os estudantes e pesquisadores interessados em pesquisa Visual computacional para aplicativos de realidade misturada.</span><span class="sxs-lookup"><span data-stu-id="2836a-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="2836a-119">O workshop fornecerá um local para compartilhar aplicativos e demonstrações e aprender umas das outras para criar ou portar aplicativos para misto realidade.</span><span class="sxs-lookup"><span data-stu-id="2836a-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="2836a-120">É recomendável que os envios sobre os tópicos de reconhecimento de objeto (centrado em ego), mão e controle do usuário, reconhecimento de atividade, mais, reconstrução 3D, compreensão da cena, localização com base em sensor, navegação e muito mais.</span><span class="sxs-lookup"><span data-stu-id="2836a-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="2836a-121">Envio de papel</span><span class="sxs-lookup"><span data-stu-id="2836a-121">Paper Submission</span></span>
* <span data-ttu-id="2836a-122">Prazo de envio de papel: 17 de maio</span><span class="sxs-lookup"><span data-stu-id="2836a-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="2836a-123">Notificação para os autores de: 24 de maio</span><span class="sxs-lookup"><span data-stu-id="2836a-123">Notification to authors: May 24</span></span>

<span data-ttu-id="2836a-124">Envios de papel devem usar o modelo CVPR e são limitados a 4 páginas mais referências.</span><span class="sxs-lookup"><span data-stu-id="2836a-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="2836a-125">Além disso, é recomendável que os autores para enviar um vídeo demonstrando o seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="2836a-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="2836a-126">Observe que os envios de trabalho publicado anteriormente são permitidos (incluindo trabalho aceito para a conferência de 2019 CVPR principal).</span><span class="sxs-lookup"><span data-stu-id="2836a-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="2836a-127">Envios podem ser carregados para o CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="2836a-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="2836a-128">Um subconjunto de documentos será selecionado para apresentação oral no workshop.</span><span class="sxs-lookup"><span data-stu-id="2836a-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="2836a-129">No entanto, recomendamos que todos os autores apresentar seu trabalho durante a sessão de demonstração.</span><span class="sxs-lookup"><span data-stu-id="2836a-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="2836a-130">Agendamento</span><span class="sxs-lookup"><span data-stu-id="2836a-130">Schedule</span></span>
* <span data-ttu-id="2836a-131">13:30-13:45: Comentários de abertura e de boas-vindos.</span><span class="sxs-lookup"><span data-stu-id="2836a-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="2836a-132">13:45-14:15: **Palestra palestra**: Prof Marc Pollefeys, ETH Zurique/Microsoft.</span><span class="sxs-lookup"><span data-stu-id="2836a-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="2836a-133">Título: Visão do computador egocentric HoloLens.</span><span class="sxs-lookup"><span data-stu-id="2836a-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="2836a-134">14:15-14:45: **Palestra palestra**: Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="2836a-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="2836a-135">Título: Atividade egocentric e Pose de previsão.</span><span class="sxs-lookup"><span data-stu-id="2836a-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="2836a-136">14:45-15:15: **Palestra palestra**: Recuperação de desastre. Yang Liu, California Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="2836a-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="2836a-137">Título: Ligando um assistente cognitivo for the Blind com realidade aumentada.</span><span class="sxs-lookup"><span data-stu-id="2836a-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="2836a-138">15:15-16:15: Intervalo para o café e demonstrações.</span><span class="sxs-lookup"><span data-stu-id="2836a-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="2836a-139">16:15-16:45: **Palestra palestra**: Prof Kristen Grauman, Universidade do Texas em Austin/Facebook AI Research.</span><span class="sxs-lookup"><span data-stu-id="2836a-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="2836a-140">Título: Interação humana-object no vídeo de primeira pessoa.</span><span class="sxs-lookup"><span data-stu-id="2836a-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="2836a-141">16:45-17:15: Apresentações orais:</span><span class="sxs-lookup"><span data-stu-id="2836a-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="2836a-142">Registro ficou mais fácil - a navegação orthopedic autônomo com o HoloLens.</span><span class="sxs-lookup"><span data-stu-id="2836a-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="2836a-143">F.</span><span class="sxs-lookup"><span data-stu-id="2836a-143">F.</span></span> <span data-ttu-id="2836a-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span><span class="sxs-lookup"><span data-stu-id="2836a-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="2836a-145">Aprendizado estéreo por andando com um HoloLens.</span><span class="sxs-lookup"><span data-stu-id="2836a-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="2836a-146">H.</span><span class="sxs-lookup"><span data-stu-id="2836a-146">H.</span></span> <span data-ttu-id="2836a-147">Zhan, Y. Pekelny, O. Ulusoy.</span><span class="sxs-lookup"><span data-stu-id="2836a-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="2836a-148">17:15-17:30: Comentários de finais.</span><span class="sxs-lookup"><span data-stu-id="2836a-148">17:15-17:30: Final Remarks.</span></span>
