---
title: Ponto e o modo de confirmação com mãos
description: Visão geral do modelo confirmação e de ponto de entrada
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Misto realidade, interação, design, hololens, mãos, agora, aponte e confirmar
ms.openlocfilehash: e69c8ff2091beff7d8fbbde4e6f24d909302290a
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730812"
---
# <a name="point-and-commit-with-hands"></a><span data-ttu-id="ba911-104">Ponto e o modo de confirmação com mãos</span><span class="sxs-lookup"><span data-stu-id="ba911-104">Point and commit with hands</span></span>
<span data-ttu-id="ba911-105">Ponto e o modo de confirmação com mãos é um modelo de entrada que permite aos usuários de destino, selecione e manipular objetos 3D e conteúdos 2D na distância.</span><span class="sxs-lookup"><span data-stu-id="ba911-105">Point and commit with hands is an input model that enables users to target, select and manipulate 2D content and 3D objects in the distance.</span></span> <span data-ttu-id="ba911-106">Essa técnica de interação "agora" é exclusiva para a realidade misturada e não é um humanos de maneira naturalmente intereact com o mundo real.</span><span class="sxs-lookup"><span data-stu-id="ba911-106">This "far" interaction technique is unique to mixed reality and is not a way humans naturally intereact with the real world.</span></span> <span data-ttu-id="ba911-107">Por exemplo, no filme super hero *X-homens*, o caractere [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) é capaz de contatar e manipular um objeto mais distante na distância com suas mãos.</span><span class="sxs-lookup"><span data-stu-id="ba911-107">For example, in the super hero movie *X-Men*, the character [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) is capable of reaching out and manipulating a far object in the distance with his hands.</span></span> <span data-ttu-id="ba911-108">Isso não é algo que os humanos podem fazer na realidade.</span><span class="sxs-lookup"><span data-stu-id="ba911-108">This is not something humans can do in reality.</span></span> <span data-ttu-id="ba911-109">No HoloLens (AR) e realidade mista (VR), nós equipar os usuários com esse poder mágica, quebrando a restrição física do mundo real não apenas para ter uma experiência e interessantes com conteúdo holográfica, mas também para tornar a interação mais eficaz e eficiente.</span><span class="sxs-lookup"><span data-stu-id="ba911-109">In both HoloLens (AR) and Mixed Reality (VR), we equip users with this magical power, breaking the physical constraint of the real world not only to have a delightful experience with holographic contents but also to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="ba911-110">Suporte a dispositivos</span><span class="sxs-lookup"><span data-stu-id="ba911-110">Device support</span></span>

<span data-ttu-id="ba911-111">Modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="ba911-111">Input model</span></span> | [<span data-ttu-id="ba911-112">HoloLens (1ª geração)</span><span class="sxs-lookup"><span data-stu-id="ba911-112">HoloLens (1st gen)</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/hololens-hardware-details) | <span data-ttu-id="ba911-113">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="ba911-113">HoloLens 2</span></span> | [<span data-ttu-id="ba911-114">Fones imersivos em exposição</span><span class="sxs-lookup"><span data-stu-id="ba911-114">Immersive headsets</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/immersive-headset-hardware-details) |
| ---------| -----| ----- | ---------|
<span data-ttu-id="ba911-115">Ponto e confirmação (interação mão distante)</span><span class="sxs-lookup"><span data-stu-id="ba911-115">Point and commit (far hand interaction)</span></span> | <span data-ttu-id="ba911-116">❌ Não tem suportada</span><span class="sxs-lookup"><span data-stu-id="ba911-116">❌ Not supported</span></span> | <span data-ttu-id="ba911-117">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="ba911-117">✔️ Recommended</span></span> | <span data-ttu-id="ba911-118">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="ba911-118">✔️ Recommended</span></span>

<span data-ttu-id="ba911-119">Ponto e a confirmação, também conhecido como mãos agora, é um dos novos recursos que utiliza o novo sistema de controle de mão articulado.</span><span class="sxs-lookup"><span data-stu-id="ba911-119">Point and commit, also known as hands far, is one of the new features that utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="ba911-120">Esse modelo de entrada também é o modelo de entrada primário em fones imersivos em exposição com o uso de controladores de movimento.</span><span class="sxs-lookup"><span data-stu-id="ba911-120">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span>

## <a name="hand-rays"></a><span data-ttu-id="ba911-121">Raios de mão</span><span class="sxs-lookup"><span data-stu-id="ba911-121">Hand rays</span></span>

<span data-ttu-id="ba911-122">Em 2 HoloLens, criamos um raio de mão Atira do Centro de um palm.</span><span class="sxs-lookup"><span data-stu-id="ba911-122">On HoloLens 2, we created a hand ray that shoots out from the center of a palm.</span></span> <span data-ttu-id="ba911-123">Este ray é tratado como uma extensão da mão.</span><span class="sxs-lookup"><span data-stu-id="ba911-123">This ray is treated as an extension of the hand.</span></span> <span data-ttu-id="ba911-124">Um cursor em forma de rosca é anexado ao final do raio para indicar o local onde o raio cruza com um objeto de destino.</span><span class="sxs-lookup"><span data-stu-id="ba911-124">A donut-shaped cursor is attached to the end of the ray to indicate the location where the ray intersects with a target object.</span></span> <span data-ttu-id="ba911-125">O objeto que o cursor chega à, em seguida, pode receber comandos gestual de mão.</span><span class="sxs-lookup"><span data-stu-id="ba911-125">The object that the cursor lands on can then receive gestural commands from the hand.</span></span>

<span data-ttu-id="ba911-126">Esse comando gestual básico é disparado, usando o polegar e o dedo para executar a ação de toque de ar.</span><span class="sxs-lookup"><span data-stu-id="ba911-126">This basic gestural command is triggered by using the thumb and index finger to perform the air-tap action.</span></span> <span data-ttu-id="ba911-127">Usando o raio de mão para apontar e polegar para confirmar, os usuários podem ativar um botão ou um hiperlink em um conteúdo da web.</span><span class="sxs-lookup"><span data-stu-id="ba911-127">By using the hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="ba911-128">Com os gestos de composição mais, os usuários são capazes de navegar o conteúdo da web e manipular objetos 3D à distância.</span><span class="sxs-lookup"><span data-stu-id="ba911-128">With more composite gestures, users are capable of navigating web content and manipulating 3D objects from a distance.</span></span> <span data-ttu-id="ba911-129">O design visual do raio mão também deve reagir a esses estados de confirmação e de ponto, como descrito e mostrado abaixo:</span><span class="sxs-lookup"><span data-stu-id="ba911-129">The visual design of the hand ray should also react to these point and commit states, as described and shown below:</span></span> 

* <span data-ttu-id="ba911-130">No *apontando* de estado, o raio é uma linha de traço e o cursor é uma forma de rosca.</span><span class="sxs-lookup"><span data-stu-id="ba911-130">In the *pointing* state, the ray is a dash line and the cursor is a donut shape.</span></span>
* <span data-ttu-id="ba911-131">No *confirmação* de estado, o raio se transforma em uma linha sólida e reduz o cursor para um ponto.</span><span class="sxs-lookup"><span data-stu-id="ba911-131">In the *commit* state, the ray turns into a solid line and the cursor shrinks to a dot.</span></span>

![](images/Hand-Rays-720px.jpg)

## <a name="transition-between-near-and-far"></a><span data-ttu-id="ba911-132">Faça a transição entre próximo e distante</span><span class="sxs-lookup"><span data-stu-id="ba911-132">Transition between near and far</span></span>

<span data-ttu-id="ba911-133">Em vez de usar o gesto específico, como "apontando com dedo indicador" para direcionar o raio, projetamos o raio provenientes de fora do centro do palm, liberando e reservar os cinco dedos para gestos manipulative mais, como aperto e pegar.</span><span class="sxs-lookup"><span data-stu-id="ba911-133">Instead of using specific gesture, such as "pointing with index finger" to direct the ray, we designed the ray coming out from the center of the palm, releasing and reserving the five fingers for more manipulative gestures, such as pinch and grab.</span></span> <span data-ttu-id="ba911-134">Com esse design, podemos criar apenas um modelo mental, que dão suporte a exatamente o mesmo conjunto de gestos de mão para interação próxima e distante.</span><span class="sxs-lookup"><span data-stu-id="ba911-134">With this design, we create only one mental model, supporting exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="ba911-135">Você pode usar o mesmo gesto de captura para manipular objetos em distâncias diferentes.</span><span class="sxs-lookup"><span data-stu-id="ba911-135">You can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="ba911-136">A invocação dos raios é automático e a proximidade com base em:</span><span class="sxs-lookup"><span data-stu-id="ba911-136">The invocation of the rays is automatic and proximity based:</span></span>

*  <span data-ttu-id="ba911-137">Quando um objeto está dentro do arm atingido distância (aproximadamente 50 cm), os raios são desativados automaticamente incentivando para interação com o próxima.</span><span class="sxs-lookup"><span data-stu-id="ba911-137">When an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span>
*  <span data-ttu-id="ba911-138">Quando o objeto está mais distante 50 cm, raios são ativados.</span><span class="sxs-lookup"><span data-stu-id="ba911-138">When the object is farther than 50 cm, the rays are turned on.</span></span> <span data-ttu-id="ba911-139">A transição deve ser simples e direta.</span><span class="sxs-lookup"><span data-stu-id="ba911-139">The transition should be smooth and seamless.</span></span>

![](images/Transition-Between-Near-And-Far-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="ba911-140">Interação slate 2D</span><span class="sxs-lookup"><span data-stu-id="ba911-140">2D slate interaction</span></span>

<span data-ttu-id="ba911-141">Um Slate 2D é um contêiner de holográfico hospedando conteúdo do aplicativo 2D, como o navegador da web.</span><span class="sxs-lookup"><span data-stu-id="ba911-141">A 2D Slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="ba911-142">O conceito de design para o momento interagir com um slate 2D é usar os raios de mão para tap de destino e ar para selecionar.</span><span class="sxs-lookup"><span data-stu-id="ba911-142">The design concept for far interacting with a 2D slate is to use hand rays to target and air tap to select.</span></span> <span data-ttu-id="ba911-143">Após o direcionamento com um raio de mão, os usuários podem polegar para disparar um hiperlink ou um botão.</span><span class="sxs-lookup"><span data-stu-id="ba911-143">After targeting with a hand ray, users can air tap to trigger a hyperlink or a button.</span></span> <span data-ttu-id="ba911-144">Eles podem usar uma mão para "ar tocar e arrastar" rolar um slate conteúdo para cima para baixo.</span><span class="sxs-lookup"><span data-stu-id="ba911-144">They can use one hand to "air tap and drag" to scroll a slate content up and down.</span></span> <span data-ttu-id="ba911-145">O movimento relativo da usando duas mãos para tocar e arrastar de ar pode aplicar zoom e o conteúdo de imagem fixa.</span><span class="sxs-lookup"><span data-stu-id="ba911-145">The relative motion of using two hands to air tap and drag can zoom in and out the slate content.</span></span>

<span data-ttu-id="ba911-146">Direcionar o raio de mão nos cantos e bordas revela a funcionalidade de manipulação mais próximo.</span><span class="sxs-lookup"><span data-stu-id="ba911-146">Targeting the hand ray at the corners and edges reveals the closest manipulation affordance.</span></span> <span data-ttu-id="ba911-147">Por "captura e arrastar" as capacidades de manipulação, os usuários podem executar uniforme de dimensionamento por meio de capacidades de canto e pode refluir o slate por meio de capacidades de borda.</span><span class="sxs-lookup"><span data-stu-id="ba911-147">By "grab and drag" the manipulation affordances, users can perform uniform scaling through the corner affordances and can reflow the slate via the edge affordances.</span></span> <span data-ttu-id="ba911-148">Pegando e arrastando o holobar na parte superior do slate 2D a usuários podem mover o slate inteiro.</span><span class="sxs-lookup"><span data-stu-id="ba911-148">Grabbing and dragging the holobar at the top of the 2D slate can users move the whole slate.</span></span>

![](images/2D-Slate-Interaction-Far-720px.jpg)

<span data-ttu-id="ba911-149">Para a manipulação de 2D de imagem fixa em si:</span><span class="sxs-lookup"><span data-stu-id="ba911-149">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="ba911-150">Os usuários apontam o raio de mão nos cantos ou bordas para revelar a funcionalidade de manipulação mais próximo.</span><span class="sxs-lookup"><span data-stu-id="ba911-150">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="ba911-151">Aplicando um gesto de manipulação de funcionalidade, os usuários podem executar a escala uniforme por meio da funcionalidade de canto e podem refluir o slate via a funcionalidade de borda.</span><span class="sxs-lookup"><span data-stu-id="ba911-151">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="ba911-152">Aplicando um gesto de manipulação de holobar na parte superior do slate 2D, os usuários podem mover o slate inteiro.</span><span class="sxs-lookup"><span data-stu-id="ba911-152">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="ba911-153">Manipulação de objetos 3D</span><span class="sxs-lookup"><span data-stu-id="ba911-153">3D object manipulation</span></span>

<span data-ttu-id="ba911-154">Na manipulação direta, há duas maneiras para os usuários manipular o objeto 3D, manipulação de funcionalidade e manipulação de não-funcionalidade com base.</span><span class="sxs-lookup"><span data-stu-id="ba911-154">In direct manipulation, there are two ways for users to manipulate 3D object, affordance-based manipulation and non-affordance based manipulation.</span></span> <span data-ttu-id="ba911-155">No modelo de ponto e a confirmação, os usuários são capazes de alcançar o exatamente as mesmas tarefas por meio de raios de mão.</span><span class="sxs-lookup"><span data-stu-id="ba911-155">In the point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="ba911-156">Nenhum aprendizado adicional é necessária.</span><span class="sxs-lookup"><span data-stu-id="ba911-156">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="ba911-157">Manipulação de funcionalidade</span><span class="sxs-lookup"><span data-stu-id="ba911-157">Affordance-based manipulation</span></span>
<span data-ttu-id="ba911-158">Os usuários usar raios de mão para apontar e revelar a caixa delimitadora e capacidades de manipulação.</span><span class="sxs-lookup"><span data-stu-id="ba911-158">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="ba911-159">Os usuários podem aplicar o gesto de manipulação na caixa delimitadora para mover o objeto inteiro, nas capacidades de borda para girar e em coner de capacidades para dimensionar de maneira uniforme.</span><span class="sxs-lookup"><span data-stu-id="ba911-159">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="ba911-160">Funcionalidade não com base em manipulação</span><span class="sxs-lookup"><span data-stu-id="ba911-160">Non-affordance based manipulation</span></span>
<span data-ttu-id="ba911-161">Ponto de usuários com raios de mão para revelar a caixa delimitadora e em seguida, aplicar diretamente a gestos de manipulação nele.</span><span class="sxs-lookup"><span data-stu-id="ba911-161">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="ba911-162">Com um lado, a translação e rotação do objeto são associados ao movimento e a orientação da mão.</span><span class="sxs-lookup"><span data-stu-id="ba911-162">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="ba911-163">Com duas mãos, os usuários podem traduzir, dimensionar e girá-lo de acordo com os movimentos relativos de duas mãos.</span><span class="sxs-lookup"><span data-stu-id="ba911-163">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="ba911-164">Gesturers instinctual</span><span class="sxs-lookup"><span data-stu-id="ba911-164">Instinctual gesturers</span></span>
<span data-ttu-id="ba911-165">O conceito de gestos instinctual para ponto e a confirmação é semelhante de manipulação direta.</span><span class="sxs-lookup"><span data-stu-id="ba911-165">The concept of instinctual gestures for point and commit is similar to that for direct manipulation.</span></span> <span data-ttu-id="ba911-166">Os gestos os usuários são suponha que para executar em um objeto 3D são orientados pelo design de capacidades de interface do usuário.</span><span class="sxs-lookup"><span data-stu-id="ba911-166">The gestures users are suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="ba911-167">Por exemplo, um ponto de controle pequeno pode motivar usuários aperto com seus polegar e o dedo, enquanto um usuário pode querer obter um objeto maior usando todos os 5 dedos.</span><span class="sxs-lookup"><span data-stu-id="ba911-167">For example, a small control point might motivate users to pinch with their thumb and index finger, while a user might want to grab a larger object using all 5 fingers.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="ba911-168">Design simétrica entre mãos e controlador de DoF 6</span><span class="sxs-lookup"><span data-stu-id="ba911-168">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="ba911-169">O conceito de ponto e confirmação de interação mais distante foi inicialmente criado e definido para misto realidade Portal (MRP), onde um usuário executa um fone de ouvido envolvente e interage com objetos 3D por meio de controladores de movimento.</span><span class="sxs-lookup"><span data-stu-id="ba911-169">The concept of point and commit for far interaction was initially created and defined for the Mixed Reality Portal (MRP), where a user wears an immersive headset and interacts with 3D objects via motion controllers.</span></span> <span data-ttu-id="ba911-170">Os controladores de movimento envie out raios para apontando e manipular objetos distantes.</span><span class="sxs-lookup"><span data-stu-id="ba911-170">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="ba911-171">Existem botões nos controladores para confirmar ainda mais ações diferentes.</span><span class="sxs-lookup"><span data-stu-id="ba911-171">There are buttons on the controllers for further committing different actions.</span></span> <span data-ttu-id="ba911-172">Podemos aproveitar o modelo de interação de raios e anexados-los para ambas as mãos.</span><span class="sxs-lookup"><span data-stu-id="ba911-172">We leverage the interaction model of rays and attached them to both hands.</span></span> <span data-ttu-id="ba911-173">Com esse design simétrica, o que os usuários que estão familiarizados com MRP não precisarão aprender outro modelo de interação que aponta para o momento e a manipulação de quando eles usam HoloLen 2 e vice-versa.</span><span class="sxs-lookup"><span data-stu-id="ba911-173">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation when they use HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>

## <a name="instinctual-gestures"></a><span data-ttu-id="ba911-174">Gestos instinctual</span><span class="sxs-lookup"><span data-stu-id="ba911-174">Instinctual gestures</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)

## <a name="see-also"></a><span data-ttu-id="ba911-175">Consulte também</span><span class="sxs-lookup"><span data-stu-id="ba911-175">See also</span></span>
* [<span data-ttu-id="ba911-176">Focar com a cabeça e confirmar</span><span class="sxs-lookup"><span data-stu-id="ba911-176">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="ba911-177">Manipulação direta com mãos</span><span class="sxs-lookup"><span data-stu-id="ba911-177">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="ba911-178">Interações instinctuais</span><span class="sxs-lookup"><span data-stu-id="ba911-178">Instinctual interactions</span></span>](interaction-fundamentals.md)

