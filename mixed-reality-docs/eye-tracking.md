---
title: Acompanhamento ocular
description: O HoloLens 2 permite um nível novo de contexto e entendimento humano dentro da experiência holográfica, fornecendo aos desenvolvedores a capacidade de usar as informações sobre o que os usuários estão vendo.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Acompanhamento de olho, realidade misturada, entrada, olho-olhar, calibragem
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441111"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="a4f9e-104">Acompanhamento ocular no HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="a4f9e-104">Eye tracking on HoloLens 2</span></span>

![Demonstração de controle de olho no MRTK](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="a4f9e-106">O HoloLens 2 permite um nível novo de contexto e entendimento humano dentro da experiência holográfica, fornecendo aos desenvolvedores a capacidade de usar as informações sobre o que os usuários estão vendo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="a4f9e-107">Esta página fornece uma visão geral dessa nova funcionalidade para desenvolvedores e designers sobre como eles podem se beneficiar do controle de olho para vários casos de uso e diretrizes básicas para desenvolvedores.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-107">This page provides an overview of this new capability to developers and designers on how they can benefit from eye tracking for various use cases and basic developer guidance.</span></span> 


## <a name="calibration"></a><span data-ttu-id="a4f9e-108">Calibragem</span><span class="sxs-lookup"><span data-stu-id="a4f9e-108">Calibration</span></span> 
<span data-ttu-id="a4f9e-109">Para que o acompanhamento de olho funcione com precisão, cada usuário precisa passar por uma [calibragem do usuário com acompanhamento de olho](calibration.md) para o qual o usuário precisa examinar um conjunto de destinos Holographic.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-109">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="a4f9e-110">Isso permite que o dispositivo ajuste o sistema para uma experiência de exibição de qualidade mais confortável e mais segura para o usuário e para garantir o acompanhamento preciso do controle de olho ao mesmo tempo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-110">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="a4f9e-111">O controle de olhos deve funcionar para a maioria dos usuários, mas há casos raros em que um usuário pode não conseguir calibrar com êxito.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-111">Eye tracking should work for most users, but there are rare cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="a4f9e-112">Para saber mais sobre a calibração e sobre como garantir uma experiência tranqüila, consulte nossa página de [calibragem do usuário de acompanhamento de olho](calibration.md) .</span><span class="sxs-lookup"><span data-stu-id="a4f9e-112">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>


## <a name="device-support"></a><span data-ttu-id="a4f9e-113">Suporte a dispositivos</span><span class="sxs-lookup"><span data-stu-id="a4f9e-113">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="a4f9e-114"><strong>Recurso</strong></span><span class="sxs-lookup"><span data-stu-id="a4f9e-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="a4f9e-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1ª geração)</strong></a></span><span class="sxs-lookup"><span data-stu-id="a4f9e-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="a4f9e-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="a4f9e-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="a4f9e-117"><a href="immersive-headset-hardware-details.md"><strong>Headsets imersivos</strong></a></span><span class="sxs-lookup"><span data-stu-id="a4f9e-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="a4f9e-118">Olho-olhar</span><span class="sxs-lookup"><span data-stu-id="a4f9e-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="a4f9e-119">✔️</span><span class="sxs-lookup"><span data-stu-id="a4f9e-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="a4f9e-120">Dados de acompanhamento de olho disponíveis</span><span class="sxs-lookup"><span data-stu-id="a4f9e-120">Available eye tracking data</span></span>
<span data-ttu-id="a4f9e-121">Antes de entrar em detalhes sobre os casos de uso específicos para a entrada olhar, queremos destacar rapidamente os recursos fornecidos pela [API de acompanhamento ocular](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) do HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-121">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="a4f9e-122">Os desenvolvedores obtêm acesso a um único olhar Ray (olhar e direção) a aproximadamente _30 fps (30 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="a4f9e-122">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="a4f9e-123">Para obter informações mais detalhadas sobre como acessar dados de controle de olho, consulte nossos guias de desenvolvedor sobre como usar [olhar no DirectX](gaze-in-directx.md) e [olho-olhar no Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-123">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="a4f9e-124">O olho previsto-olhar é aproximadamente de 1,5 graus no ângulo visual em torno do destino real (consulte a ilustração abaixo).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-124">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="a4f9e-125">À medida que pequenas imprecisãos são esperadas, os desenvolvedores devem planejar uma margem em relação a esse valor de limite inferior (por exemplo, os graus do 2.0-3.0 podem resultar em uma experiência muito mais confortável).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-125">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="a4f9e-126">Discutiremos como abordar a seleção de destinos pequenos em mais detalhes abaixo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-126">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="a4f9e-127">Para que o acompanhamento ocular funcione com precisão, cada usuário deve passar por uma calibração de usuário de acompanhamento ocular.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-127">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="a4f9e-128">![Tamanho ideal do alvo em uma distância de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="a4f9e-128">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="a4f9e-129">*Tamanho de destino ideal em uma distância de 2 medidores*</span><span class="sxs-lookup"><span data-stu-id="a4f9e-129">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="a4f9e-130">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="a4f9e-130">Use cases</span></span>
<span data-ttu-id="a4f9e-131">O acompanhamento ocular permite que os aplicativos acompanhem para que local o usuário está olhando em tempo real.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-131">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="a4f9e-132">Os casos de uso a seguir descrevem algumas interações que são possíveis com o acompanhamento de olho no HoloLens 2 em realidade misturada.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-132">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="a4f9e-133">Observe que esses casos de uso ainda não fazem parte da experiência de shell Holographic (ou seja, a interface que você vê quando inicia o seu HoloLens 2).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-133">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="a4f9e-134">Você pode experimentar alguns deles no [Kit de ferramentas da realidade misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) que fornece vários exemplos interessantes e eficientes para usar o acompanhamento de olho, como seleções de destino com suporte rápido e fácil, bem como a rolagem automática por texto com base sobre o que o usuário observa.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-134">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="a4f9e-135">Intenção do usuário</span><span class="sxs-lookup"><span data-stu-id="a4f9e-135">User intent</span></span>    
<span data-ttu-id="a4f9e-136">As informações sobre onde e o que um usuário observa fornecem um **contexto poderoso para outras entradas**, como voz, mãos e controladores.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-136">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="a4f9e-137">Isso pode ser usado para várias tarefas.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-137">This can be used for various tasks.</span></span>
<span data-ttu-id="a4f9e-138">Por exemplo, isso pode variar de um **direcionamento** rápido e sem esforço na cena simplesmente observando um holograma e dizendo *"Select"* (também Confira [olhar e commit](gaze-and-commit.md)) ou dizendo *"Put this..."* e, em seguida, procurando onde o usuário deseja posicionar o holograma e dizer *"... lá "* .</span><span class="sxs-lookup"><span data-stu-id="a4f9e-138">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="a4f9e-139">Exemplos para esse caso podem ser encontrados em [Kit de Ferramentas de Realidade Misturada – Seleção de alvo com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Kit de Ferramentas de Realidade Misturada – Posicionamento de alvo com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-139">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="a4f9e-140">Além disso, um exemplo de intenção de usuário pode incluir o uso de informações sobre o que os usuários examinam para aprimorar o envolvimento com os agentes virtuais e os hologramas interativos.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-140">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="a4f9e-141">Por exemplo, os agentes virtuais podem adaptar as opções disponíveis e seu comportamento com base no conteúdo exibido atualmente.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-141">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="a4f9e-142">Ações implícitas</span><span class="sxs-lookup"><span data-stu-id="a4f9e-142">Implicit actions</span></span>
<span data-ttu-id="a4f9e-143">A categoria de ações implícitas está intimamente relacionada à intenção do usuário.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-143">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="a4f9e-144">A ideia é que os hologramas ou os elementos da interface do usuário reagem de uma maneira instinctual que talvez nem pareça que o usuário esteja interagindo com o sistema, mas que o sistema e o usuário estejam em sincronia. Um exemplo é a **rolagem automática baseada em olhar de olho** em que o usuário pode ler um texto longo que inicia automaticamente a rolagem quando o usuário chega à parte inferior da caixa de texto para manter o usuário no fluxo de leitura sem levantar um dedo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-144">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="a4f9e-145">Um aspecto fundamental disso é que a velocidade da rolagem se adapta à velocidade de leitura do usuário.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-145">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="a4f9e-146">Outro exemplo é o **zoom e a panorâmica com suporte,** em que o usuário pode se sentir como mergulhar exatamente em relação ao que ele está concentrado.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-146">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="a4f9e-147">O disparo de zoom e controle da velocidade de zoom pode ser controlado por entrada de voz ou por mão, o que é importante para fornecer ao usuário a sensação de controle, evitando que seja sobrecarregado.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-147">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="a4f9e-148">Falaremos sobre essas considerações de design em mais detalhes abaixo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-148">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="a4f9e-149">Uma vez ampliado, o usuário pode seguir, por exemplo, o curso de uma rua para explorar sua vizinhança simplesmente usando seus olhos olhars.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-149">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="a4f9e-150">Exemplos de demonstração para esses tipos de interações podem ser encontrados na amostra do [Kit de Ferramentas de Realidade Misturada – Navegação com suporte ocular](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-150">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="a4f9e-151">Casos de uso adicionais para _ações implícitas_ podem incluir:</span><span class="sxs-lookup"><span data-stu-id="a4f9e-151">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="a4f9e-152">**Notificações inteligentes:** Nunca se incomodar pelas notificações que aparecem logo onde você está olhando?</span><span class="sxs-lookup"><span data-stu-id="a4f9e-152">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="a4f9e-153">Levando em conta o que um usuário está prestando a atenção, você pode melhorar a experiência com notificações de compensação de onde o usuário está nuvens no momento.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-153">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="a4f9e-154">Isso limita distrações e os descarta automaticamente quando o usuário termina de ler.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-154">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="a4f9e-155">**Hologramas de cuidadosa:** Hologramas que reagem sutilmente ao serem gazeddos.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-155">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="a4f9e-156">Isso pode variar de elementos de interface do usuário ligeiramente brilhantes, uma flor de intratação mais lenta para um cachorro virtual começando a olhar de volta para a usuária e wagging sua parte final.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-156">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="a4f9e-157">Essa interação pode fornecer uma noção interessante de conectividade e satisfação em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-157">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="a4f9e-158">Acompanhamento de atenção</span><span class="sxs-lookup"><span data-stu-id="a4f9e-158">Attention tracking</span></span>   
<span data-ttu-id="a4f9e-159">As informações sobre onde ou o que os usuários examinam é uma ferramenta extremamente poderosa para avaliar a usabilidade de designs e identificar problemas em fluxos de trabalho eficientes.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-159">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="a4f9e-160">A visualização e a análise de controle de olho são uma prática comum em várias áreas de aplicativo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-160">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="a4f9e-161">Com o HoloLens 2, fornecemos uma nova dimensão para essa compreensão, pois os hologramas de 3D podem ser colocados em contextos reais e avaliados de acordo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-161">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="a4f9e-162">O [Kit de ferramentas de realidade misturada](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fornece exemplos básicos para registrar e carregar dados de acompanhamento de olho e como visualizá-los.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-162">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>

<span data-ttu-id="a4f9e-163">Outros aplicativos nessa área podem incluir:</span><span class="sxs-lookup"><span data-stu-id="a4f9e-163">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="a4f9e-164">**Visualização de olhar de olho remoto:** Visualize o que os colaboradores remotos estão vendo para aumentar a compreensão compartilhada.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-164">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to increase shared understanding.</span></span>
-   <span data-ttu-id="a4f9e-165">**Estudos de pesquisa do usuário:** O controle de atenção pode ajudar a entender melhor como percebemos e envolvemos o nosso ambiente, o que pode ajudar em melhores modelos de intenção humana para mais instinctual interações de computadores humanos.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-165">**User research studies:** Attention tracking can help better understanding how we perceive and engage with our environment which may help in better human intent models for more instinctual human-computer-interactions.</span></span> 
-   <span data-ttu-id="a4f9e-166">**Treinamento:** Melhor treinamento de iniciantes ao entender melhor os padrões de pesquisa visual de especialistas e sua coordenação de olhos para tarefas complexas, como para a análise de dados médicos ou durante a operação de máquinas operacionais.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-166">**Training:** Improved training of novices by better understanding experts' visual search patterns and their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="a4f9e-167">**Avaliações de design e pesquisa de mercado:** O controle de olhos é uma ferramenta comum para pesquisa de mercado ao avaliar designs de sites e produtos.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-167">**Design evaluations and market research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span> <span data-ttu-id="a4f9e-168">Com o HoloLens 2, podemos estender isso para espaços 3D mesclando variantes de design de produto digital com o ambiente físico.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-168">With HoloLens 2, we can extend this to 3D spaces by merging digital product design variants with the physical environment.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="a4f9e-169">Casos de uso adicionais</span><span class="sxs-lookup"><span data-stu-id="a4f9e-169">Additional use cases</span></span>
- <span data-ttu-id="a4f9e-170">**Jogos:** Já quis ter superpotências?</span><span class="sxs-lookup"><span data-stu-id="a4f9e-170">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="a4f9e-171">Esta é a sua chance!</span><span class="sxs-lookup"><span data-stu-id="a4f9e-171">Here's your chance!</span></span> <span data-ttu-id="a4f9e-172">Você pode levitater os hologramas por estrelas.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-172">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="a4f9e-173">Ressaltar as emissões de laser dos seus olhos-Experimente no [RoboRaid para o HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-173">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="a4f9e-174">Transforme inimigos em pedra ou congele-os.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-174">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="a4f9e-175">Use sua visão de raios X para explorar prédios.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-175">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="a4f9e-176">O limite é sua imaginação.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-176">Your imagination is the limit!</span></span>
<span data-ttu-id="a4f9e-177">Fique atento ao fato de não sobrecarregar o usuário – para saber mais, confira nossas [diretrizes de design de entrada com base no olhar](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-177">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="a4f9e-178">**Avatars expressivos:** Controle de olho ajuda em avatars 3D mais expressivos usando dados de acompanhamento de olho ao vivo para animar os olhos do avatar que indicam o que o usuário está olhando.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-178">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="a4f9e-179">**Entrada de texto:** O controle de olho pode ser usado como uma alternativa para a entrada de texto de baixo esforço, especialmente quando a fala ou as mãos são inconvenientes de usar.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-179">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="a4f9e-180">Usando olho-olhar para interação</span><span class="sxs-lookup"><span data-stu-id="a4f9e-180">Using eye-gaze for interaction</span></span>
<span data-ttu-id="a4f9e-181">A criação de uma interação que aproveita o direcionamento de olho rápido pode ser desafiadora.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-181">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="a4f9e-182">Por um lado, os olhos se movem tão rapidamente que você precisa ter cuidado ao usar a entrada olhar, pois o usuário pode achar a experiência difícil ou atrapalhar.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-182">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise user may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="a4f9e-183">Por outro lado, você também pode criar experiências verdadeiramente mágicos que vão para seus usuários!</span><span class="sxs-lookup"><span data-stu-id="a4f9e-183">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="a4f9e-184">Para ajudá-lo, Confira nossa visão geral das principais vantagens, desafios e recomendações de design para [olhar de interação](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-184">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="a4f9e-185">Diretrizes de desenvolvimento: e se o acompanhamento de olho não estiver disponível?</span><span class="sxs-lookup"><span data-stu-id="a4f9e-185">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="a4f9e-186">Pode haver situações em que seu aplicativo não receberá nenhum dado de controle de olho devido a vários motivos, incluindo, mas não limitado a:</span><span class="sxs-lookup"><span data-stu-id="a4f9e-186">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="a4f9e-187">O usuário ignorou a calibragem de acompanhamento ocular.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-187">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="a4f9e-188">O usuário foi calibrado, mas decidiu não conceder permissão ao seu aplicativo para usar seus dados de controle de olho.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-188">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="a4f9e-189">O usuário tem óculos exclusivo ou alguma condição de olho que ainda não dá suporte ao sistema.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-189">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="a4f9e-190">Fatores externos que impedem o acompanhamento de olho confiável, como manchas no visor ou óculos do HoloLens, luz de sol direta intensa e occlusions devido ao cabelo na frente dos olhos.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-190">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="a4f9e-191">Para você como desenvolvedor de aplicativos, isso significa que você precisa considerar como dar suporte a usuários para os quais os dados de acompanhamento de olho podem não estar disponíveis.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-191">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="a4f9e-192">Abaixo, explicamos primeiro como detectar se o acompanhamento de olhos está disponível e como abordar quando ele não está disponível para aplicativos diferentes.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-192">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="a4f9e-193">1. como detectar se o acompanhamento de olho está disponível</span><span class="sxs-lookup"><span data-stu-id="a4f9e-193">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="a4f9e-194">Há algumas verificações para determinar se os dados de acompanhamento de olho estão disponíveis.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-194">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="a4f9e-195">Verifique se...</span><span class="sxs-lookup"><span data-stu-id="a4f9e-195">Check whether...</span></span>
* <span data-ttu-id="a4f9e-196">... o sistema dá suporte a acompanhamento de olho.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-196">... the system supports eye tracking at all.</span></span> <span data-ttu-id="a4f9e-197">Chame o seguinte *método*: [Windows. percepção. Peoples. EyesPose. IsSupported ()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="a4f9e-197">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="a4f9e-198">... o usuário é calibrado.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-198">... the user is calibrated.</span></span> <span data-ttu-id="a4f9e-199">Chame a seguinte *Propriedade*: [Windows. percepção. People. EyesPose. IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="a4f9e-199">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="a4f9e-200">... o usuário recebeu a permissão do seu aplicativo para usar seus dados de acompanhamento de olho: recuperar o _' GazeInputAccessStatus '_ atual.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-200">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="a4f9e-201">Um exemplo de como fazer isso é explicado em [solicitando acesso à entrada olhar](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-201">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="a4f9e-202">Além disso, talvez você queira verificar se os dados de acompanhamento de olho não estão obsoletos adicionando um tempo limite entre atualizações de dados de acompanhamento de olho recebido e, caso contrário, fallback para o Head-olhar, conforme discutido abaixo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-202">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="a4f9e-203">Conforme descrito acima, há várias razões pelas quais os dados de acompanhamento de olho podem não estar disponíveis.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-203">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="a4f9e-204">Embora alguns usuários possam ter decidido a revogar o acesso aos seus dados de controle de olho e estão ok com a compensação de uma experiência de usuário inferior à privacidade de não fornecer acesso aos seus dados de controle de olho, em alguns casos isso pode não ser intencional.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-204">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="a4f9e-205">Portanto, se seu aplicativo usar o acompanhamento de olho, e essa for uma parte importante da experiência, recomendamos que você se comunique claramente com o usuário.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-205">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="a4f9e-206">Informando, de maneira adequada, o usuário por que o acompanhamento de olho é essencial para seu aplicativo (talvez até mesmo listar alguns recursos avançados) para experimentar todo o potencial do seu aplicativo pode ajudar o usuário a entender melhor o que está desistindo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-206">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="a4f9e-207">Ajudar o usuário a identificar por que o controle de olhos pode não estar funcionando (com base nas verificações acima) e oferecer algumas sugestões para solucionar problemas em potencial rapidamente.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-207">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="a4f9e-208">Por exemplo, se você puder detectar que o sistema dá suporte ao controle de olho, o usuário é calibrado e até mesmo recebeu sua permissão, mas nenhum dado de acompanhamento de olho é recebido, isso pode apontar para alguns outros problemas, como manchas ou olhos sendo obstruído.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-208">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="a4f9e-209">Observe que há casos raros de usuários para os quais o acompanhamento de olho pode simplesmente não funcionar.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-209">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="a4f9e-210">Portanto, seja obedientes disso, permitindo descartar ou até mesmo desabilitar lembretes para habilitar o acompanhamento de olho em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-210">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="a4f9e-211">2. fallback para aplicativos usando olho-olhar como um ponteiro de entrada primário</span><span class="sxs-lookup"><span data-stu-id="a4f9e-211">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="a4f9e-212">Se seu aplicativo usa olhar como uma entrada de ponteiro para selecionar rapidamente os hologramas em toda a cena, mas os dados de acompanhamento de olho não estão disponíveis, é recomendável fazer o fallback para Head-olhar e começar a mostrar o cursor Head-olhar.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-212">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="a4f9e-213">É recomendável usar um tempo limite (por exemplo, 500 – 1500 MS) para determinar se deseja ou não alternar.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-213">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="a4f9e-214">Isso é para evitar o pop-up de um cursor toda vez que o sistema pode perder o controle rapidamente devido a movimentos ou winks de olhos rápidos e cintilações.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-214">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="a4f9e-215">Se você for um desenvolvedor do Unity, o fallback automático para Head-olhar já será tratado no kit de ferramentas da realidade misturada.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-215">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="a4f9e-216">Se você for um desenvolvedor do DirectX, precisará lidar com esse comutador por conta própria.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-216">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="a4f9e-217">3. fallback para outros aplicativos específicos de controle de olho</span><span class="sxs-lookup"><span data-stu-id="a4f9e-217">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="a4f9e-218">Seu aplicativo pode usar olhar de olho de forma exclusiva, especificamente para os olhos, por exemplo, para animar os olhos de um avatar ou para a atenção com base nos olhos, calor a depender de informações precisas sobre a atenção Visual.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-218">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="a4f9e-219">Nesse caso, não há nenhum fallback claro.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-219">In this case, there is no clear fallback.</span></span> <span data-ttu-id="a4f9e-220">Se o acompanhamento de olho não estiver disponível, esses recursos podem simplesmente ser desabilitados.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-220">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="a4f9e-221">Novamente, é recomendável comunicar claramente isso com o usuário que talvez não esteja ciente de que a funcionalidade não está funcionando.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-221">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="a4f9e-222">Essa página espero que você tenha uma boa visão geral para começar a entender a função de acompanhamento de olho e a entrada olhar para o HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="a4f9e-222">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="a4f9e-223">Para começar a desenvolver, confira nossas informações sobre a função de [olhar para interagir com hologramas](eye-gaze-interaction.md), [olhar de olho no Unity](https://aka.ms/mrtk-eyes) e [nos olhos-olhar no DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="a4f9e-223">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="a4f9e-224">Consulte também</span><span class="sxs-lookup"><span data-stu-id="a4f9e-224">See also</span></span>
* [<span data-ttu-id="a4f9e-225">Calibragem</span><span class="sxs-lookup"><span data-stu-id="a4f9e-225">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="a4f9e-226">Conforto</span><span class="sxs-lookup"><span data-stu-id="a4f9e-226">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="a4f9e-227">Interação com base nos olhos olhar</span><span class="sxs-lookup"><span data-stu-id="a4f9e-227">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="a4f9e-228">Olho-olhar no DirectX</span><span class="sxs-lookup"><span data-stu-id="a4f9e-228">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="a4f9e-229">Olho-olhar no Unity (Kit de ferramentas de realidade misturada)</span><span class="sxs-lookup"><span data-stu-id="a4f9e-229">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="a4f9e-230">Olhar e confirmar</span><span class="sxs-lookup"><span data-stu-id="a4f9e-230">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="a4f9e-231">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="a4f9e-231">Voice input</span></span>](voice-design.md)


